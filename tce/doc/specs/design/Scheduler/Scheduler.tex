\documentclass[a4paper,twoside]{tce}
\usepackage{pslatex}

\usepackage{algorithmic}
\usepackage{algorithm}

\begin{document}
\author{Andrea Cilio, Ari Mets\"ahalme, Vladim\'ir Guzma}
\title{TTA Instruction Scheduler}
\ver{0.33.1}
\firstday{21.02.2005}
\lastday{16.04.2007}
% id number in S- sequence
\docnum{026}
% draft/complete/committed
\state{draft}

\maketitle

% highlighted style for parameters/variables or otherwise non-fixed parts
% of a command syntax or of lines of text displayed by the application
\newcommand{\parm}[1]{\textsl{#1\/}}



\chapter*{Document History}

\begin{HistoryTable}

  0.1    & 21.02.2005 & V. Guzma       &
  Initial version.\\
  0.2    & 21.02.2005 & A. Cilio       &
  Document reorganisation, added module chapters.\\
  0.3    & 19.08.2005 & A. Cilio       &
  Added material from other documents. Added few interfaces and register
  allocation chapter.\\
  0.4    & 05.09.2005 & A. Cilio       &
  Major revision. Standard sections. Program representation and
  resource allocation. Many pending issues.\\
  0.5    & 08.09.2005 & A. Cilio       &
  Major revision and extension of resource model and resource manager. Added
  tables of resource types.\\
  0.6    & 09.09.2005 & A. Cilio       &
  Major revision. Node types. Resource manager helper classes. Added
  diagrams and main allocation algorithm.\\
  0.7    & 19.09.2005 & A. Cilio       &
  Interim revision. Added resource construction (incomplete). Extended
  resource interface. Smaller extensions.\\
  0.8    & 20.09.2005 & A. Cilio       &
  Completed and thoroughly revised resource construction.\\
  0.8.1  & 20.09.2005 & A. Cilio       &
  Clarified that brokers have a state.\\
  0.9    & 22.09.2005 & A. Cilio       &
  Dumped pre-assignment class. Eliminated nonsensical part in 5.3.5
  (constraint maps). Other minor changes.\\
  0.10   & 23.09.2005 & A. Cilio       &
  Adjusted broker (extended strategy), assignment plan.\\
  0.11   & 25.09.2005 & A. Cilio       &
  Added: scheduling unit, specific brokers (bus, FU input).
  Operation-related scheduling constraints. Other changes.\\
  0.11.1 & 29.09.2005 & A. Cilio       &
  Added diagram of program representation.\\
  0.12   & 30.09.2005 & A. Cilio       &
  Added allocation graph. Minor corrections.\\
  0.13   & 30.09.2005 & A. Mets\"ahalme  &
  Added front-end and scheduler options.\\
  0.14   & 03.10.2005 & A. Cilio  &
  Corrections to front-end. Added maintenance, 16.\\
  0.15   & 04.10.2005 & A. Mets\"ahalme  &
  Extended description of base plug-in interfaces.\\
  0.16   & 04.10.2005 & A. Cilio  &
  Extended: constructor of pass modules, front-end responsibilities. Minor
  changes and corrections.\\
  0.17   & 20.10.2005 & A. Cilio  &
  Revised front-end, options design (A. Mets\"ahalme's idea).
  Added logging design. Removed empty chapters 11, 12.\\
  0.18   & 25.10.2005 & A. Cilio  &
  Partial revision following discussion with V.~Guzma.\\
  0.19   & 30.10.2005 & A. Cilio  &
  Simplified logging system.\\
  0.20   & 02.11.2005 & A. Cilio  &
  Complete revision following discussion with V.~Guzma.\\
  0.21   & 08.11.2005 & A. Cilio  &
  Corrections to resource model. Revised and completed pipeline resource
  design.\\
  0.21.1 & 09.11.2005 & A. Cilio  &
  Corrections to pipeline allocation, 5.3.8.\\
  0.22   & 14.11.2005 & A. Cilio  &
  Reintroduced plug-in layer. Extended maintenance and error handling of
  pass modules and front end. Other changes.\\
  0.23   & 15.10.2005 & A. Mets\"ahalme  &
  Various updates to chapters 9 and 10.\\
  0.23.1 & 15.11.2005 & A. Cilio  &
  Minor cleanup. Added scheduling plan.\\
  0.24   & 16.10.2005 & A. Mets\"ahalme  &
  Added scheduling plan and scheduler configuration serializer interfaces.\\
  0.25   & 16.11.2005 & A. Cilio  &
  Added extension for triggering operand moves.\\
  0.26   & 20.11.2005 & A. Cilio  &
  Revision of program representation, 3.\\
  0.27   & 22.11.2005 & A. Cilio  &
  Redesigned \emph{ProgramOperation}.\\
  0.27.1 & 01.12.2005 & A. Cilio  &
  Document title! Revised triggering operand issue, 14.6.\\
  0.28   & 03.12.2005 & A. Cilio  &
  Revision of resource model.\\
  0.29   & 13.02.2006 & A. Cilio  &
  Revision of chapter on program representation, 3.\\
  0.29.1 & 27.02.2006 & V. Guzma &
  Minor cleanup in chapter 3.\\
  0.29.2 & 01.03.2006 & A. Cilio &
  Minor cleanup. Corrections in resource model, chapter 4 (V.~Guzma's
  review).\\
  0.29.3 & 02.03.2006 & A. Cilio &
  Minor. No ``power'' here. \\
  0.29.4 & 08.03.2006 & A. Cilio &
  \emph{SchedulingResource} now can throw \emph{OutOfRange}. \\
  0.29.5 & 13.03.2006 & V. Guzma &
  Minor changes to Resource Manager chapter. Added methods for bottom-up
  scheduling.\\
  0.29.6 & 15.03.2006 & A. Cilio &
  Correction to resource broker, removed method.\\
  0.30   & 27.03.2006 & A. Cilio &
  V.~Guzma's review if chapters 4, 5. Revised chapter 5. Solved pending
  issue: inserting cycles.\\
  0.31   & 29.03.2006 & A. Cilio &
  Revised \emph{Node} (not complete yet), node placement.\\
  0.31.1 & 31.03.2006 & A. Cilio &
  Minor revision, forgotten \emph{Node} methods.\\
  0.32   & 13.04.2006 & A. Cilio &
  Renamed \emph{Node}, now \emph{MoveNode}. Revised \emph{Edge}.
  Revised resource model and resource manager. Changed dependent resources
  of p-sockets and FU inputs.\\
  0.32.1 & 12.07.2006 & V. Guzma &
  Added forgoten method \emph{hasInputNode}.\\
  0.32.2 & 13.07.2006 & V. Guzma &
  Modified MoveNodeSet design, added \emph{copy} for MoveNode.\\
  0.32.3 & 20.07.2006 & V. Guzma&
  Added methods to test is given resource is present in related and dependent
  groups.\\
  0.33   & 22.01.2007 & J. M\"antyneva &
  Made some refactoring to SchedulerFrontend and updated the class
  interfaces.\\
  0.33.1 & 16.04.2007 & V. Guzma &
  Added description of new methods in SimpleResourceManager.
\end{HistoryTable}


\tableofcontents



\chapter{INTRODUCTION}

\section{Purpose and Scope}

This document describes in detail the design of the software framework and
the default scheduling modules that make up the TTA instruction scheduler of
the TCE toolset (Scheduler).

Intended readers of this documents are primarily the developers of the
Schedulers or developers of new plug-in modules. The level of detail
and the completeness of the design description is sufficient to make
implementation straightforward.

For a complete, implementation-level description of the API of the classes
of the Scheduler the reader is referred to the automatically-generated API
reference document.

This document is based on the function specifications defined
in~\cite{SchedulerSpecs} and on the software architecture described
in~\cite{SchedulerArchitecture}.

\section{Definitions}

\begin{description}
\item[Allocation (of a resource)]%
  The task of finding out whether there exists a resource (of a given type)
  available for an assignment in a given interval of cycles, or,
  extensively, whether there exists a combination of simultaneous
  assignments for each piece of program code that requires a given type of
  resource.
\item[Assignment (of a resource)]%
  Reserving a given resource (marking it as in use) for a given activity for
  a given interval of cycles.
\item[(scheduling) Hot spot]%
  In operation-based list scheduling, the finite interval of instructions
  where a move can be scheduled. Usually, the interval where a move can be
  scheduled is unbounded, and there is no hot spot.
\item[Move]%
  Programmed data transport on a transport triggered architecture.
\item[Node]%
  The minimum program element in the program representation (a move, in case
  of a bus-programed TTA) that the Scheduler handles as an atomic unit.
\item[Resource]%
  A hardware component of the target TTA processor that can be used to carry
  out part of the program's activity.
\item[Resource Allocation]%
  Determining whether a resource can be assigned to a program element.
\item[Resource Assignment]%
  Reserving a resource to a program element (move, variable, operation,
  \ldots) for a given number of cycles.
\item[Result Move]%
  Move that reads the result of an operation from a port of a function unit.
\item[Scheduler]%
  The retargetable TTA instruction scheduler of the TTA templated
  architecture.
\item[Scheduling (general)]%
  The overall process of mapping a program to a given target architecture.
\item[Scheduling (proper)]%
  Placing instruction elements (in a bus-programmed TTA, moves) into
  instruction slots.
\item[(scheduling) Scope]%
  A part of the program whose moves are evaluated, processed and scheduled
  in the same phase. During scheduling, moves are not moved across scope
  boundaries.
\item[Scheduling Unit]%
  The minimum part of the program that a scheduling algorithm processes
  completely independently from other parts of the program.
\item[Trigger Move]%
  Move that writes a port of a function unit and thereby initiates a
  new operation on that unit.
\end{description}

\section{Acronyms and Abbreviations}

\begin{center}
\begin{longtable}{p{0.10\textwidth}p{0.85\textwidth}}
  DDG   & Data Dependence Graph. \\
  FU    & Function Unit.\\
  ILP   & Instruction Level Parallelism.\\
  IU    & Immediate Unit.\\
  MAU   & Minimum Addressable Unit (of memory address space).\\
  PDG   & Program Dependence graph.\\
  RF    & Register File.\\
  SSA   & Static Single Assignment.\\
  TCE   & TTA Codesign Environment.\\
  TPEF  & TTA Program Exchange Format.\\
  TTA   & Transport Triggered Architectures.\\
  UFU   & Universal Function Unit.\\
  UM    & Universal Machine.\\
\end{longtable}
\end{center}



\chapter{SYSTEM OVERVIEW}

See~\cite{SchedulerArchitecture} for a high-level description of
the Scheduler architecture and the scheduling framework, and for a
motivation of the framework design.



\chapter{Program Representation}
\label{ch:ProgramRepresentation}

This module provides the ``default'' object model that describes the target
program within the scheduler framework. While some passes could directly
analyse and modify the POM representation of the program, or use their own
internal object model, most passes that exploit the framework infrastructure
should need this object model.

\section{Overview}

\begin{figure}[tb]
\centerline{[[to do]]}
\caption{Graph-based program representation.}
  \label{fig:program-overview}
\end{figure}
The program representation module implements a class hierarchy that
represents the program at a level of abstraction suitable for list-based
instruction scheduling. This hierarchy has \emph{ProgramRepresentation}
interface as main handle and is rooted at the concrete class
\emph{ProgramGraph}. Figure~\ref{fig:program-overview} depicts the main
classes that make up the graph-based program representation and their
associations.

In addition to this hierarchy, the module provides a number of helper
classes that perform useful tasks or model useful concepts in the context of
instruction scheduling, such as the scheduling scope and the group of nodes
that are candidates for scheduling.

\subsection{ProgramGraph}

\emph{ProgramGraph} is the standard program representation available for any
pass of the Scheduler framework. It is a Program Dependence Graph (PDG),
essentially a Data Dependence Graph (DDG) with additional edges and nodes
representing the control dependencies of the program (the control dependence
subgraph, see~\cite{Ferrante87} for details).

The details of the representation may change during scheduling process (for
example, translation between SSA form and non-SSA form, see pending issues
in Section~\ref{ch:pending:ssa}).

\subsection{MoveNode}
\label{ssec:MoveNode}

The \emph{MoveNode} class represents a move at a level of abstraction more
suitable for instruction scheduling. Typically, but not necessarily, nodes
belong to the graph-based program representation implemented by
\emph{ProgramGraph}. The resource manager interface expects \emph{MoveNode}
objects. Even if a scheduling pass does not use a graph-based program
representation, it needs to create nodes from moves of POM in order to
communicate with the resource manager of the scheduling framework.

Thanks to this minimal, graph-independent \emph{MoveNode} interface, a
resource manager (and even simple scheduling algorithms) can work
indifferently with a graph-based program representation or with a plain
sequence of moves.

Here are the main differences between node and move abstractions:
\begin{enumerate}
\item %
  A move object represents a data transport at level of instruction
  sequence, whereas the node is independent of it.
\item %
  In a move object, the cycle in which the data transport takes place is
  implied (by the position of its parent instruction). In a node, the cycle
  is an independent parameter.
\item %
  A node may be augmented with explicit dependences with other nodes.
\item %
  A node keeps a reference to the scheduling scope it belongs to.
\end{enumerate}

\subsection{Move-Level Abstraction for Program Representation}

The smallest unit of the program representation is the single move, not the
operation. The reasons to prefer a move-level abstraction are:
\begin{enumerate}
\item%
 Simpler and more uniform nodes.
\item%
 Duplicate moves and shared moves are handled more easily.
\end{enumerate}

While the framework focuses on the move level abstraction for the program
representation, the operation is by no means an insignificant concept for
the Scheduler. The framework provides helper class \emph{ProgramOperation}
to ease manipulation of the program at level of operations (that is, at
level of moves that, taken together, perform an operation) and class
\emph{NodeGroup} to group together candidate nodes.

\subsection{Types of Nodes and Scheduling}
\label{ssec:node-types}

The source and destination of a node define its type, which affects the
scheduler and the way resources are assigned. The following table summarises
all types of unassigned node terminals, their allowed positions (input or
output), their type after resource assignment and their defining properties.
\begin{flushleft}
\begin{tabular}[h]{|l|c|c|l|c|c|c|c|}
  \hline
  \emph{unassigned} &           &            & \emph{assigned} &
                   & \emph{operation} & \emph{variable} &              \\
  \emph{terminal}   & \emph{in} & \emph{out} & \emph{terminal} &
  \emph{operation} & \emph{index}     & \emph{index}    & \emph{value} \\
  \hline
  operation-in  & x &   & FU-in     & x & x &   &   \\
  operation-out &   & x & FU-out    & x & x &   &   \\
  constant      &   & x & IImm/Ireg &   &   &   & x \\
  variable      & x & x & GPR       &   &   & x &   \\
  \hline
\end{tabular}
\end{flushleft}

All types of terminals have an additional property: the bit width of the
data word. In operations, this property is embedded in the universal
function unit~\cite{UM-design}; in constants, it is implied by the
value\footnote{
%
  After the immediate is assigned, the bit width is determined by the
  in-line immediate width or by the IU output socket bit width.};
%
in variables it is embedded in the UM RF. In simple implementations of the
Scheduler, the bit width can be ignored in almost all cases, because assumed
fixed and equal for all. Exceptions are the Boolean variables and
double-precision floating-point operations and register files.

The scheduler expects 6 different types of completely unassigned moves,
listed in the following table:
\begin{flushleft}
\begin{tabular}[h]{|r@{\extracolsep{\fill} $\rightarrow$ }l|l|}
  \hline
  \multicolumn{2}{|c|}{\emph{node type}} &
  \multicolumn{1}{c|}{\emph{description}} \\
  \hline
  operation-out  & operation-in   & bypass\\
  operation-out  & variable       & result move\\
  variable       & operation-in   & input (operand) move\\
  variable       & variable       & register copy\\
  constant       & operation-in   & constant input move\\
  constant       & variable       & register initialisation\\
  \hline
\end{tabular}
\end{flushleft}

A scheduling pass that works with pre-assigned registers (such as the
default one provided with the toolset) expects GPR's instead of program
variables. The types of nodes remain 6, but variables are replaced by GPR's
of the target processor. The only resource that remains to be assigned to
such terminals is the RF port.

An integrated scheduling and register allocation pass, instead, will have to
deal with 12 types of nodes. In addition to those of sequential code, shown
in above table, and the variants with GPR's instead of variables (4 more
types), the following two combinations are possible:
\begin{flushleft}
\begin{tabular}[h]{|r@{\extracolsep{\fill} $\rightarrow$ }l|l|}
  \hline
  \multicolumn{2}{|c|}{\emph{node type}} &
  \multicolumn{1}{c|}{\emph{description}} \\
  \hline
  variable       & GPR           & register copy with unassigned source\\
  GPR            & variable      & register copy with unassigned destination\\
  \hline
\end{tabular}
\end{flushleft}

\subsection{Edge}
\label{ssec:edge}

An edge models
%
\note{PENDING: \ref{ch:pending:edges}}
%
an ordering constraint between two nodes of the program graph.
%
The program representation has several types of edges, each with its
specific properties, each modelling an ordering constraint of different
nature.

All edges share the same base class \emph{Edge}. Edges do not provide
methods to access the head and the tail node. All topological information is
kept by the (program) graph class.
%
The program graph is a \emph{multigraph}: several edges of different types
may exist between two nodes.

\subsection{Scheduling Scope and Scheduling Unit}
\label{ssec:scope-and-unit}

\begin{figure}[tb]
\centerline{\psfig{figure=eps/ProgramRepresentationHierarchy.eps,%
    clip,trim=0 740 0 30,scale=0.5}}
\caption{Program representation hierarchy.}
  \label{fig:program-representation}
\end{figure}
%
The nodes of the program representation are organised in a two-level
hierarchy: scheduling scope and scheduling unit, as depicted in
Figure~\ref{fig:program-representation}.

The scheduling scope is an auxiliary structure that contains a set of nodes.
Reordering of nodes in a scope is constrained by dataflow, control
dependencies, resource conflicts, heuristic criteria and possible
limitations of the scheduler implementation. The important point is that
these restrictions apply equally to all nodes of the scope. On the contrary,
nodes that belong to different scheduling scopes are always scheduled at
different times and can never cross the scope boundary.

The scheduling unit is a larger grouping. It contains a set scopes that can
be scheduled independently from other parts of the target program, as if
they were not in the same program at all. In principle, no part of a program
can be scheduled without considering the rest of the program. Due to
dataflow, memory and possibly state dependencies, every piece of a program
can potentially affect any other piece.
%
Usually, however, scheduling an entire program as a single entity is not
practical. A scheduler divides the program in scheduling units, and
organises scheduling so that the dependencies across scheduling units are
avoided or can be ignored.

A typical scheduling unit is the procedure. The code in a procedure can
disregard data dependencies with other parts of the program thanks to call
conventions. Memory dependencies, similarly, can be safely ignored if the
calls to procedures are treated as ``scheduling barriers'' for operations
that modify memory. The procedure is by no means the only sensible
scheduling unit; for example, inter-procedural \emph{regions} have been
proposed~\cite{Hank96}.

The scheduling unit defines a unique, sequential numbering
%
\note{the name ``cycle'' for this number, used in this document, is
  misleading}
%
of the TTA instructions it contains. During scheduling, a node is placed by
simply assigning one such number to it. The same number is used as an index
to identify the state of scheduling resources in a given instruction (see
Section~\ref{ssec:resource-extent}).

Both scheduling scope and scheduling unit base classes can be refined with
capabilities specific for a given scheduling pass.

\subsection{Program Operation}

Class \emph{ProgramOperation} represents an instance of operation in the
program, and should hold a reference to each node that belongs to an
operation.

In its simplest form,
%
\note{only simplest form implemented initially}
%
a \emph{complete} program operation contains one and only one reference to
the appropriate node for each input and each output of the operation
instance it represents.
%
Program operation objects are not built automatically. Immediately after
construction, a program operation is \emph{empty}. It contains no references
to nodes. During initialisation, a program operation is in a \emph{partial},
or incomplete, state. This state is detected by the fact that the object
does not have a node registered corresponding to one of the operation
inputs.
%
More states are possible for a fully constructed program operation object.
%
\begin{figure}[tb]
  \centerline{\psfig{figure=eps/ProgramOpStates.eps,%
    clip,trim=0 575 0 30,scale=0.80}}
  \caption{Possible states of a program operation.}
  \label{fig:program-operation-states}
\end{figure}
%
Figure~\ref{fig:program-operation-states} shows all the possible states of a
program operation. The main states are listed below.
\begin{enumerate}
\item %
  Incomplete but \emph{ready}: the program operation does not have all its
  output nodes\footnote{
%
    Output nodes of operations may be missing for various reasons.
    Misspeculation: the scheduler eliminates the result of an operation that
    has been started in a previous block. Unused result: the operation has
    optional results (and has state or side-effects), which sometimes are
    not used.},
%
  but all existing nodes are recorded into the program operation.
\item %
  \emph{Multi}: at least one of the inputs (or outputs) of the operation
  refers to more than one node. These cases occur as a result of scheduling
  operations across control flow transfers. There are three variants of
  multi-state (multi-incomplete, multi-ready or multi-complete).
\end{enumerate}

\begin{figure}[tb]
\centerline{\psfig{figure=eps/SharedProgramOp.eps,scale=0.70}}
\caption{Example of moves shared by multiple program operations.}
  \label{fig:shared-prog-op}
\end{figure}

In addition, a program operation may have \emph{shared nodes}. This happens
when at least one of the nodes of the operation belongs also to other
program operations and is an effect of operand sharing or scheduling
operations across control merge points. Figure~\ref{fig:shared-prog-op}
depicts the program operations sharing the same node in the following piece
of code:
\begin{verbatim}
    r1 -> Ua.add.1, 1 -> Ua.add.2;
    La -> C.jump.1;
    r2 -> Ua.add.1, 1 -> Ua.add.2;
La: r4 -> Ub.mul.1;
    Ua.add.3 -> Ub.mul.2;
    Ua.add.3 -> Ua.neg.1;
    Ua.neg.2 -> r3;
    Ub.mul.3 -> r4;
\end{verbatim}
Node 5, which represents move \verb|Ua.add.3 -> Ua.neg.1|, is shared by 3
program operations: two \emph{add}, triggered in different incoming basic
blocks, and the \emph{neg} operation. Similarly, node 7 is shared by the two
\emph{add} and the \emph{mul} operation.

\subsection{MoveNodeGroup}

\emph{MoveNodeGroup} is a helper class of the node selector.
%
An instance of this class represents a group of candidate nodes that are
expected to be scheduled as a whole, in a single attempt. There is no
guarantee that all nodes in a group can be successfully scheduled. A
scheduling algorithm may sometime fail and require scheduling another group
before trying again, or may schedule only some nodes in the group, ignore
the others and ask the selector for another group. See
Section~\ref{ssec:scope-overview} for details on usage constraints of node
groups and selector.

A node group has a leader node (which is data-ready) and, possibly, several
other nodes. All nodes of a group should be connected by a dependence or
should belong to the same program operation (see
Section~\ref{ssec:ProgramOperation-if}). Usually, but not necessarily, a
group consists of all nodes that form a program operation. Operation-based
selection is convenient, because it eliminates the possibility of deadlocks
due to data dependences and resource contention.

The leader of the node group is characterised by a minimum cycle (in case of
bottom-up scheduling, maximum cycle). This is the earliest (latest) cycle in
which the scheduler should try to place the node. If no resource constraint
forbids it, scheduling the node in the given cycle will not alter the correct
program behaviour.

The minimum cycle is a reference for the remaining nodes of the
group as well. For example, if the leader node writes an opcode-setting port,
the nontriggering operand nodes of the same operation cannot be scheduled in
later cycles.

\section{Interfaces}

\subsection{ProgramGraph}

\begin{description}
\item[ProgramGraph(program : Program\&)]%
  Constructor. Create a program graph by converting the given program object
  model.
\item[generateProgram() : Program\&]%
  Convert the program representation back to a program object model and
  return the newly created instance.
\item[nodeOf(move : const Move) : MoveNode\&]%
  Return the node of the program representation corresponding to the given
  move of the input POM. Signal error condition with exception
  [[objectnotfound?]] if the given move does not belong to the program
  representation.
\end{description}

\subsection{ScopeBuilder}

\begin{description}
\item[ScopeBuilder()]%
  Constructor. The builder, when created, is in a ``clean'' state: it
  contains no scope objects and no reference to input programs.
\item[build(program : const ProgramGraph\&)]%
  Subdivide the nodes of the given program into scopes.
\item[scopeCount() : int]%
  Return the number of scopes created.
\item[scope(index : int) : Scope\&]%
  Return the scope identified by the given index. The index must be a number
  between zero and the number of scopes returned by \emph{scopeCount} minus
  one, otherwise an \emph{OutOfRange} exception is thrown.
\item[reset()]%
  Clean up the scope structures created and the reference to the input
  program. This method brings the builder back to the clean state.
\end{description}

A \emph{ScopeBuilder} does not own the scope objects it creates. Clients are
responsible for deallocating the scopes. Misuse of \emph{reset} method can
lead to memory leaks.
%
\note{CHECK if this is advisable}

\subsection{MoveNode}

The \emph{MoveNode} class represents (and holds) a move. It differs from
\emph{Move} class of POM in three ways:
\begin{enumerate}
\item %
  It extends the \emph{Move} interface with new scheduler-specific methods.
\item %
  It adapts part of \emph{Move} interface.
\item %
  It restricts the \emph{Move} interface by hiding unwanted methods
\end{enumerate}

\begin{description}
\item[MoveNode(move : Move\&)]%
  Constructor. Creates a new node wrapped around given move. Notice, there
  is no reference safety: the same move can be erroneously used to construct
  multiple nodes.
\item[copy() : MoveNode*]%
  Returns copy of MoveNode.
\item[move() : Move\&]%
  Return the object model of the move.
\end{description}

The following interface adapts part of the \emph{Move} interface:
\begin{description}
\item[isSourceOperation() : bool]%
  Return true if the source of the node is an operation output.
\item[isSourceVariable() : bool]%
  Return true if the source of the node is a program variable.
\item[isSourceConstant() : bool]%
  Return true if the source of the node is a constant.
\item[isDestinationOperation() : bool]%
  Return true if the destination of the node is an operation input.
\item[isDestinationVariable() : bool]%
  Return true if the destination of the node is a program variable.
\item[isBypass() : bool]%
  Return true if the source of the node is an operation output and its
  destination is an operation input. Shortcut for testing
  \emph{isSourceOperation} and \emph{isDestinationOperation}.
\end{description}

The source and the destination of a node can be assigned or not. Different
resource types are assigned to different types of terminal, as described in
Section~\ref{ssec:nodes-assignment-requests}. The MOM components
corresponding to the hardware resources can be accessed through the
\emph{Move} object.

The following interface extends the move concept:
\begin{description}
\item[isPlaced() : bool]%
  Return true if the node has a cycle assigned to it.
\item[isAssigned() : bool]%
  Return true if all parts of the node are assigned to a suitable processor
  resource. Note: that a node is assigned does not mean that its
  assignments are valid for the given cycle!
\item[isScheduled() : bool]%
  Return true if the node is placed and assigned.
\item[cycle() : int]%
  Return the cycle assigned to this node.

  Throw exception \emph{InvalidObject} if the node is not placed.
\item[scope() : Scope\&]%
  Return the scheduling scope the node belongs to.
\item[sourceOperation() : ProgramOperation\&]%
  Return the program operation of the source of this node. The node reads
  one of the results of the operation.

  Return a special null program operation if no program operation is set up
  for this node, although the node source is an operation output.
%
  Throw \emph{InvalidObject} if the source is not an operation output.

\item[destinationOperation() : ProgramOperation\&]%
  Return the program operation of the destination of this node. The node
  writes one of the inputs of the operation.

  Return a special null program operation if no program operation is set up
  for this node, although the node destination is an operation output.
%
  Throw \emph{InvalidObject} if the destination is not an operation input.

\item[setCycle(cycle : int)]%
  Place the node into the given cycle.

  Throw exception \emph{InvalidObject} if the node is already placed in a
  cycle different from given cycle.

\item[unsetCycle()]%
  Undo placement of this node.

  Throw exception \emph{InvalidObject} if the node is not placed.
\item[setAssignment()]%
  Sets the assignment flag for a node, scheduler considers assignments ready.

\item[unsetAssignment()]%
  Undo the setting of assignment flag.

\end{description}

Nodes may be related to each other via dependences, thus forming a graph.
However, the \emph{MoveNode} class does not provide methods for navigating
through this graph. These methods reside in the program, on condition it is
implemented by a graph-based representation, such as \emph{ProgramGraph}.

\subsection{Edge}
\label{ssec:edge-if}

\begin{description}
\item[{[[to do]]}]
\end{description}

\subsection{Scope}

\begin{description}
\item[{[[to do]]}]
\end{description}

\subsection{SchedulingUnit}
\label{ssec:SchedulingUnit-if}

\begin{description}
\item[nodesIn(index : const int) : MoveNodeSet]%
  Return all nodes currently placed in the TTA instruction position
  identified by \emph{index}.
\end{description}

\subsection{ProgramOperation}
\label{ssec:ProgramOperation-if}

The \emph{ProgramOperation} class provides a convenient interface to access
and navigate through the nodes that belong to an operation in the program
and to test the state of the program operation object.

\begin{description}
\item[ProgramOperation(operation : Operation\&)]%
  Constructor. Create a program operation, that is, an instance of given
  operation in the target program.

\item[addNode(node : MoveNode\&)]%
  Add given node to the set of nodes that belong to this program operation.

  Throw [[IllegalParameter?]] is given node does not belong to the given
  operation. (That is, it reads or writes an output, respectively input, of
  another operation.)
%
  Throw [[IllegalParameter?]] also if the given node is a bypass.

\item[addInputNode(node : MoveNode\&)]%
  Add given node to the set of nodes that belong to this program operation.

  Throw [[IllegalParameter?]] is given node writes an input of another
  operation.

\item[addOutputNode(node : MoveNode\&)]%
  Add given node to the set of nodes that belong to this program operation.

  Throw [[IllegalParameter?]] is given node reads an output of another
  operation.

\item[isComplete() : bool]%
  Return true if each input and each output of the operation has a
  corresponding node reference in this program operation.

\item[isReady() : bool]%
  Return true if each input of the operation has a corresponding node
  reference in this program operation.

\item[isMultinode() : bool]%
  Return true if this program operation has more than one node reference for
  an input or an output of the operation.

\item[isAssigned() : bool]%
  Return true if the nodes of this program operation have a function unit
  assigned to their source or destination related to it.

\item[opcodeSettingNode() : MoveNode\&]%
  Return the node of the program operation that sets the opcode (and
  triggers operation execution). This node, usually an input node, is the
  only node that can never appear in multiple copies.

  Throw [[InvalidObject?]] if no function unit has been assigned to this
  program operation.

\item[inputNode(in : const int) : MoveNodeSet\&]%
  Return the nodes that write the input \emph{in} of the operation.

  Throw \emph{OutOfRange}
%
  \note{OutOfRange appropriate here?}
%
  if \emph{in} is smaller than 1 or greater than the number of operation
  inputs.

\item[outputNode(out : const int) : MoveNodeSet\&]%
  Return the nodes that read the output \emph{out} of the
  operation.

  Throw \emph{OutOfRange} if \emph{out} is smaller than 1 or greater than
  the number of operation outputs.
%
  Throw \emph{KeyNotFound} if this program operation has no result node for
  the output identified by \emph{index}.

\item[hasInputNode(out : const int) : bool]%
  Return true if the program operation has an input node registered for the
  input identified by index \emph{in}.

\item[hasOutputNode(out : const int) : bool]%
  Return true if the program operation has an output node registered for the
  output identified by index \emph{out}.

\item[operation() : Operation\&]%
  Return the operation (a handle object to the static properties defined by
  OSAL~\cite{OSAL-specs,OSALDesign}).
\end{description}

\subsection{MoveNodeSet}
\label{ssec:MoveNodeSet-if}

Specialised container and helper class for \emph{ProgramOperation}. Its
purpose is to let clients treat multi-node inputs and outputs as nodes.
%A \emph{Composite} design, the \emph{NodeSet} is derived from \emph{MoveNode}
%and forwards to all nodes of the set every method that is applicable.

%Clients that do not support multi-node program operations can ignore even
%the existence of this class and use \emph{MoveNode} objects instead. This
%class provides automatic conversion to \emph{MoveNode}.

Clients that support multi-node program operations use the specialised
\emph{MoveNodeSet} methods:
\begin{description}
\item[count() : int] %
  Return the number of nodes in this set. In multi-node program operations,
  there may be several copies of the same input or output node in different
  basic blocks.
\item[at(index: int) : MoveNode\&] %
  Return the copy of the node identified by \emph{index}.
\item[addMoveNode(newNode: MoveNode\&) ] %
  Add newNode to the MoveNodeSet. %

  Throw \emph{OutOfRange} if \emph{index} is smaller than 1 or greater than
  the node count for the given operation output.
\end{description}

\subsection{MoveNodeGroup}

\begin{description}
\item[earliestCycle() : int]%
  Return the earliest cycle in which dependences make it possible to try
  schedule the leader node.

  Throw \emph{NotAvailable} if this node group does not contain a valid
  earliest cycle.
\item[latestCycle() : int]%
  Return the latest cycle in which dependences make it possible to try
  schedule the leader node.

  Throw \emph{NotAvailable} if this node group does not contain a valid
  latest cycle.

\item[nodeCount() : int]%
  Return the number of candidate nodes in the group.

\item[node(index : const int) : MoveNode\&]%
  Return the node at position \emph{index} in the group. The position 0 is
  always occupied by the leader node, the other nodes are not ordered in any
  special way.

\item[isScheduled() : bool]%
  Return true if all moves in the group have been scheduled.
\end{description}

Note: clients of \emph{MoveNodeGroup} are supposed to know from the creator
of the group (usually, the selector, see Section~\ref{sec:Selector-if})
whether earliest cycle, latest cycle or both are available.

Since the order of nodes within a group is undefined, it follows that
clients of a node group should not rely on it. As a result, if a selector
implementation works on a program representation that does not contain
explicit dependencies between nodes, it is \emph{better} for it to return
node groups with just one node.
%
This guideline reduces the risk that clients rely on a specific
implementation's ordering of nodes and aims at enhancing inter-operability
between core modules.
%
For a possible alternative, see rejected design ``explicit ordering of node
groups''.

\section{Implementation}

\subsection{MoveNodeGroup}

Although earliest and latest cycles apply to the leader of a node group, the
cycle values may be computed taking also the other nodes into account. For
example, it does not make sense to return an earliest cycle 10 if the
creator of the node group knows that another input node cannot be scheduled
later than the leader node and at the same time cannot be scheduled earlier
than in cycle 12. A more restrictive (higher) earliest cycle can have a
noticeable effect on performance, because it avoids scheduling attempts in
cycles that will fail.

\subsection{ProgramOperation}
\label{ssec:ProgramOperation-imp}

\paragraph{Invariant:}
If the operation is assigned and the opcode-setting node is registered, then
method \emph{inputNodeCount} for the index of that node must always return
1. (No multiple opcode-setting nodes.)

\subsection{MoveNodeSet}
\label{ssec:MoveNodeSet-imp}

Design of this class changed. Since the MoveNodes are to be placed to
different cycles and can for example has different sources (registers) the
Composite design seems not the right thing to do. It is now simple container.
%For efficiency, method \emph{operation} could be reimplemented and cache a
%reference to the parent \emph{ProgramOperation} instance instead of
%delegating one of the nodes.

%Automatic conversion must be implemented by means of a conversion operator.
%\begin{description}
%\item[operator MoveNode()] %
%  Convert this node set into a single node if the set contains one node.

  %Throw [[InvalidObject?]] if the set contains several nodes or no node at
  %all.
%\end{description}



\chapter{Resource Model}

The resource model consists of a hierarchy of interdependent objects that
represent processor components or scheduling constraints. The resource model
defines only a base interface and design guidelines.

This chapter describes a concrete and complete implementation of a simple
resource model for the resource manager distributed with the toolset,
described in Chapter~\ref{ch:ResourceManager}.

\section{Overview}

\emph{SchedulingResource} is the base class for the hierarchy of objects
that model processor resources (hardware components) or scheduling
constraints.

Resources can be tested for availability, assigned or freed. Often,
assignment and availability may be dependent on the assignment request,
which is always represented as a part of a node (see
Section~\ref{ssec:MoveNode} for a description of class \emph{MoveNode}).

A resource object has a list of related resources. These resources are
compatible with it, that is, may be assigned in conjunction with it to carry
out the data transport specified by a node. These localised relations make
it possible to quickly lookup a complete set of resources for a node that
needs assignment.

Resource objects have no knowledge of the target processor and do not depend
on MOM objects (machine parts) they may represent.

\subsection{Extent of a Resource Object}
\label{ssec:resource-extent}

A resource object represents the utilisation state of a single instance of a
scheduling resource (for example, a socket) throughout a region of the
target program (more specifically, a scheduling unit, described in
Section~\ref{ssec:scope-and-unit}).
%
For each (partially) scheduled instruction of the scheduling unit there
corresponds a slot of each resource object. Each slot is identified by a
cycle number. The first slot is assigned cycle 1. The cycle number is the
same that characterises a placed node (see Section~\ref{ssec:MoveNode}).

Resource objects are automatically extended with new slots when clients
require an assignment in a cycle greater than the current last cycle.

%\begin{quote}\small
The motivation for not restricting cycle numbering to a smaller program
region (such as the scheduling scope) is that resource utilisation may
``spill over'' to cycles (and thus instructions) that do not belong to the
scope currently scheduled. Not keeping track of resource utilisation in
these instructions would reduce the quality of the schedule, if not
compromise it altogether.
%
Only instruction that are completely unaffected from the scheduling of the
current region (that is, instructions in another scheduling unit) can be
ignored.
%\end{quote}

\subsection{State of a Resource}
\label{ssec:resource-state}

In order to keep its utilisation state, some scheduling resources need to
keep track of which type of assignment request keeps the resource busy in a
given cycle. In other words, a resource in use needs to record something
that reminds it what is it being used for.

Recording assignment requests is necessary for reusable resources, since
reuse is often dependent on the type of assignment request.

Often, the resource request is identified by a machine component. For
example: an output socket resource can be reused in a given cycle only if
the move that needs the socket reads the same \emph{output port} that is
already read by the other move that already uses the socket.

\subsection{Resource Construction}

The resource model defines just an interface and a set of basic services. It
does not implement construction of the resource objects. The simplest
solution is to leave construction to concrete resource types. This is not
satisfactory for a number of reasons, as explained below. Instead,
construction is delegated to the objects that know the concrete type of a
resource instance. Typically, these objects are part of the resource manager
module. In a fully framework-compliant implementation of the resource
manager, detailed knowledge of the resource type is encapsulated in helper
objects of the resource manager called resource brokers
(Section~\ref{ssec:ResourceBroker}).

Resource construction requires a solution for several design requirements:
\begin{enumerate}
\item %
  A resource object can contain references to other resources (possibly of a
  different type).
\item %
  The builder of a specific type of resources should know only about its own
  type of resources.
\item %
  The builder of a specific type of resources should set up the references
  to other resources contained in the resource instances it creates.
\end{enumerate}

The problems related to these requirements and a possible solution are
described in Chapter~\ref{ch:ResourceManager}.

\section{Interfaces}

\subsection{SchedulingResource}

Class \emph{SchedulingResource} defines the following base interface, common
to all scheduling resources:
\begin{description}
\item[isInUse(cycle : const int) : bool]%
  Return true if this resource is used in given cycle.

\item[isAvailable(cycle : const int) : bool]%
  Return true if this resource is unused or used but still available for some
  other assignments in given cycle. This condition does not dependent on the
  request received.

\item[canAssign(cycle : const int, node : MoveNode) : bool]%
  Return true if this resource can be assigned to the given node starting
  from given cycle. If the resource assignment spans more than one cycle,
  this method takes into account the resource utilisation in following or
  previous cycles.

\item[assign(cycle : const int, node : MoveNode)]%
  Assign this resource to the given node starting from given cycle.

\item[unassign(cycle : const int, node : MoveNode)]%
  Undo assignment of this resource to given node in given cycle.
\end{description}

Resource that have related and dependent resources should implement the
following methods:
\begin{description}
\item[relatedResourceGroupCount() : int]%
  Return the number of independent groups of related resources.
\item[dependentResourceGroupCount() : int]%
  Return the number of independent groups of dependent resources.
\item[relatedResourceCount(group : const int) : int]%
  Return the number of related resources in the group of related resources
  identified by index \emph{group}.
\item[dependentResourceCount(group : const int) : int]%
  Return the number of dependent resources in the group of dependent
  resources identified by index \emph{group}. Each group often contains one
  resource only.
\item[addToRelatedGroup(group : const int, resource : SchedulingResource\&)]%
  Add \emph{resource} to the group of related resources identified by index
  \emph{group}.
\item[addToDependentGroup(group : const int, resource : SchedulingResource\&)]%
  Add \emph{resource} to the group of dependent resources identified by
  index \emph{group}.
\item[relatedResource(group : const int, i : const int) :
  SchedulingResource\&]%
  Return the resource at position \emph{i} in the group of related resources
  identified by index \emph{group}.

  Throw \emph{OutOfRange} if there is no group with given group index, or if
  the selected group does not contain a resource with given index.
\item[dependentResource(group : const int, i : const int) :
  SchedulingResource\&]%
  Return the resource at position \emph{i} in the group of related resources
  identified by index \emph{group}.

  Throw \emph{OutOfRange} if there is no group with given group index, or if
  the selected group does not contain a resource with given index.

\item[hasRelatedResource(sResource : SchedulingResource\&) : bool]%
  Helper method to tests if sResource is present in related resource group
\item[hasDependentResource(sResource : SchedulingResource\&) :
  bool]%
  Helper method to tests if sResource is present in dependent resource group
\end{description}

\section{Implementation}

\subsection{Properties of Concrete Resource Types}
\label{ssec:properties-resources}

The following tables define specific properties of concrete types of
scheduling resources. The ``canReuse'' predicate models the conditions under
which a resource already in use could be nevertheless assigned to another
request (resource sharing). Reuse normally depends on the new assignment
request.

\paragraph{Input PSocket Resource.}

Due to their straightforward dependency relation with sockets, ports are not
modelled as separate resources. Whenever a port is assigned, one and only
one socket is automatically assigned as well.
%
The ``input p-socket'' resource represents the combination of an input
socket and the input ports attached to it.

If an input p-socket includes a triggering FU port, then the inputs FU
resource that is responsible for it will have an additional dependent
resource: the execution pipeline.

\begin{flushleft}
\begin{tabular*}{\textwidth}[h]{|l|@{\extracolsep{\fill}}p{0.78\textwidth}|}
  \hline
  \texttt{isInUse} &
  Test counter $>$ 0.\\
  \texttt{isAvailable} &
  Test counter $=$ 0.\\
  \texttt{canReuse} &
  Always false.\footnotemark\\
  \texttt{assign} &
  Add one to the use counter and remember the requested port.\\
  \texttt{unassign} &
  Decrease the counter by one and clear the reference to the port.\\
  \texttt{dependencies} &
  None.\\
  \texttt{related} &
  (1) units (FU-inputs); (2) segments. \\
  \texttt{cycle} &
  1.\\
  \hline
\end{tabular*}
\end{flushleft}
%
\footnotetext{An input socket can be ``shared'' by means of multicast
  control codes that write two or more destination ports (all attached to
  the socket). This possibility is not considered in the toolset.}

\paragraph{Output PSocket Resource.}

The ``output p-socket'' resource represents the combination of an output
socket and the output ports attached to it. An output socket can write to
multiple buses, so it is reusable. The capability of a bus to support
in-line immediates is modelled by means of a special output socket that is
connected to the first segment of the bus. The ``first'' segment of a bus is
the segment that can (directly or indirectly) drive any other segment of the
bus.
%
If an output p-socket includes an opcode-setting FU port, then the outputs
FU resource that is responsible for it will have an additional dependent
resource: the execution pipeline triggered by that port.

\begin{flushleft}
\begin{tabular*}{\textwidth}[h]{|l|@{\extracolsep{\fill}}p{0.78\textwidth}|}
  \hline
  \texttt{isInUse} &
  Test counter $>$ 0.\\
  \texttt{isAvailable} &
  Always true.\footnotemark\\
  \texttt{canReuse} &
  True when the node terminal requires the same port connected to the socket
  that is already in use, and socket fan-out allows reuse.\\
  \texttt{assign} &
  Add one to the use counter and remember the port assigned to the terminal
  of the given node.\\
  \texttt{unassign} &
  Decrease the counter by one and clear the reference to the port if it
  reaches zero.\\
  \texttt{dependencies} &
  None.\\
  \texttt{related} &
  (1) units (IU, FU-outputs); (2) segments.\\
  \texttt{cycle} &
  1.\\
  \hline
\end{tabular*}
\end{flushleft}
\footnotetext{In theory, an output socket can always be shared. In practice,
  however, sharing may be limited by the hardware implementation, which
  restricts the socket fan-out. First implementation does not support sharing
  of IU and RF ports.}

\paragraph{Input/Output Function Unit Resource.}

Function units are complex resources that centralise allocation and
assignment of several ``sub-resources'': operation pipelines, opcode-setting
ports, p-sockets. Unlike register files and immediate units, function units
assign their ports and sockets automatically: given a unit and an operation
input or output, there is no allocation choice. When an assignment request
involves an operation input or output that is not mapped to a triggering
port, the operation pipeline resource is \emph{not} affected.

There are two types of function unit resources: input FU resources and
output FU resources. They represent the set of ports with the same direction
of a function unit. Any bidirectional FU port will appear as dependent
resource of an input FU resource and an output FU resource at the same time.

An assignment request directed to a function unit resource consists of an
operation and its terminal index (input or output). Both are used to find
out which FU p-socket is used (the port is determined by the operation-port
binding, the socket is implied by the port). If the port sets the operation
code, then the operation is also used to lookup the pipeline resources to
assign. If the port is only triggering, then the pipeline resources are
assigned based one the current state of the operation pipeline.

The following table defines the properties common to both types of function
unit resource.

\begin{flushleft}
\begin{tabular*}{\textwidth}[h]{|l|@{\extracolsep{\fill}}p{0.78\textwidth}|}
  \hline
  \texttt{isInUse} &
  True if any of the ports or any pipeline resource is in use in given
  cycle.\\
  \texttt{isAvailable} &
  True if not all p-sockets attached to the FU are in use.\\
  \texttt{canReuse} &
  True if the node terminal requires a port of the FU that can be reused.\\
  \texttt{assign} &
  Assign the execution pipeline if port is triggering.\\
  \texttt{unassign} &
  Unassign the execution pipeline if port is triggering.\\
  \texttt{dependencies} &
  (1) input or output p-sockets; (2) execution pipeline.\\
  \texttt{related} &
  None.\\
  \texttt{cycle} &
  1.\\
  \hline
\end{tabular*}
\end{flushleft}

\paragraph{Execution Pipeline Resource.}

An execution pipeline is assigned to operations, owned by an FU resource and
controlled by its triggering ports. A pipeline resource keeps track of the
state of the pipeline and models all conflicts due to contention of internal
hardware resources of the pipeline.

From the point of view of resources, an operation is equivalent to a profile
of (internal) pipeline resource usage. For each operation supported by its
function unit, the execution pipeline resource keeps a usage profile.
%
FU ports are modelled as internal pipeline resources, too.
%
In general, the operations implemented by a function unit share at least a
subset of the same internal resources of the pipeline model. At a minimum,
the opcode-setting port shared.

\begin{flushleft}
\begin{tabular*}{\textwidth}[h]{|l|@{\extracolsep{\fill}}p{0.78\textwidth}|}
  \hline
  \texttt{isInUse} &
  True if any of the internal resources of the pipeline is in use in given
  cycle. A pipeline is not in use if there are no pending operation.\\
  \texttt{isAvailable} &
  True if some operation can be started in given cycle without generating
  conflicts with operations already assigned to the pipeline
  resource.\footnotemark\\
  \texttt{canReuse} &
  True if at least one of the supported operations can be started in given
  cycle without generating conflicts with operations already in the
  pipeline.\\
  \texttt{assign} &
  Assign the internal pipeline resources corresponding to the usage profile
  of an operation starting from given cycle.\\
  \texttt{unassign} &
  Unassign the internal pipeline resources corresponding to the usage
  profile of an operation starting from given cycle.\\
  \texttt{dependencies} &
  Internal pipeline resources (not necessarily modelled as resource
  objects).\\
  \texttt{related} &
  The triggering p-sockets. \\
  \texttt{cycle} &
  Variable. As many as the latency of the triggered operation.\\
  \hline
\end{tabular*}
\end{flushleft}
%
\footnotetext{In practice, what matters is whether a pipeline is still
  available for any operation that might be started in this cycle. This
  condition is not trivially computed because it requires testing the usage
  profile of every supported operation.}

\paragraph{Bus Resource.}

A bus consists of one or more segments, which form an ordered, directed,
acyclic sequence. A bus has a set of related resources consisting of all the
sockets connected to its segments. Given an assignment to a related socket,
a bus can automatically determine which segment is in use.

\begin{flushleft}
\begin{tabular*}{\textwidth}[h]{|l|@{\extracolsep{\fill}}p{0.78\textwidth}|}
  \hline
  \texttt{isInUse} &
  True if any of its segments is in use.\\
  \texttt{isAvailable} &
  True if not all its segments are in use.\footnotemark\\
  \texttt{canReuse} &
  True if none of the segments required by the node is in use. True if at
  least one segment is not in use, if the node does not imply any segment
  request.\\
  \texttt{assign} &
  Assign all segments involved in the transport specified by the node (only
  input or output segment, if only one terminal is assigned to a socket).\\
  \texttt{unassign} &
  Free all segments involved in the transport specified by the node.\\
  \texttt{dependencies} &
  The bus segments.\\
  \texttt{related} &
  Sockets connected to the bus.\\
  \texttt{cycle} &
  1.\\
  \hline
\end{tabular*}
\end{flushleft}
%
\footnotetext{If multicast is supported, then this test must be extended to
  take into account availability of multicasts even when all segments are in
  use.}

\begin{figure}[tb]
\centerline{\psfig{figure=eps/SegmentModel.eps,scale=0.70}}
\caption{Resource model of segments and a possible equivalent
  microarchitecture.}
  \label{fig:segment-model}
\end{figure}

\paragraph{Segment Resource.}

A segment can carry a transport from its source to its destination or
through a piece of the bus chain. Figure~\ref{fig:segment-model} depicts a
simplified model of segmented buses, where p-sockets are shown as directed
connectors. A segment can satisfy multiple transport requests in a single
cycle, as long as each transport has the same source. However, this requires
multicasting or at least individual programming of each bus segment, and is
not supported by the resource model provided with the toolset.
%
\note{EXTENSION: support for multicasts and independent segment programming}

\begin{flushleft}
\begin{tabular*}{\textwidth}[h]{|l|@{\extracolsep{\fill}}p{0.78\textwidth}|}
  \hline
  \texttt{isInUse} &
  Test counter $>$ 0.\\
  \texttt{isAvailable} &
  Counter $=$ 0, if multicasts are not supported.\\
  \texttt{canReuse} &
  Always false.\\
  \texttt{assign} &
  Set use counter to one.\\
  \texttt{unassign} &
  Set the use counter to zero.\\
  \texttt{dependencies} &
  (1) source segment; (2) destination segment.\\
  \texttt{related} &
  (1) input sockets; (2) output sockets. \\
  \texttt{cycle} &
  1.\\
  \hline
\end{tabular*}
\end{flushleft}

\paragraph{Immediate Unit Resource.}

Unlike register files, which the resource manager assumes pre-assigned,
immediate units and immediate registers are allocated by the resource
manager. The immediate unit resource keeps track of each register it
contains.
%
Allocation of immediate registers is limited to simple dataflow: single
definition-use point and dependency not crossing basic blocks of code.
%
\note{EXTENSION: better immediate register allocation}
%
All cycles between the definition point of an immediate register and its
last use are marked ``in-use''. The resource assigned to the definition is
an instruction template, which is a resource dependent on the assigned
immediate unit.

\begin{flushleft}
\begin{tabular*}{\textwidth}[h]{|l|@{\extracolsep{\fill}}p{0.78\textwidth}|}
  \hline
  \texttt{isInUse} &
  True if any of the immediate registers is in use.\\
  \texttt{isAvailable} &
  True if not all immediate registers are in use.\\
  \texttt{canReuse} &
  True if at least one immediate register is not in use.\\
  \texttt{assign} &
  Mark all cycles between the definition and the cycle before the given
  cycle as in use for that register.\\
  \texttt{unassign} &
  Lookup the definition cycle. Mark the immediate register as free between
  the definition cycle and the cycle before the given one.\footnotemark\\
  \texttt{dependencies} &
  Registers.\\
  \texttt{related} &
  (1) instruction templates, (2) p-sockets. \\
  \texttt{cycle} &
  For a given immediate register, every cycle starting from its definition
  cycle up to this cycle.\\
  \hline
\end{tabular*}
\end{flushleft}

\footnotetext{This simple method does not work if the same immediate
  definition can be used multiple times.}

\paragraph{Instruction Template Resource.}

An instruction template represents an instruction encoding whereby one or
more instruction slots are reserved to storing immediate bits rather than
programming data transports. An instruction template specifies a set of move
slots for encoding immediate bits and a destination immediate unit. One of
the registers of the destination IU is assigned to the immediate.

\begin{flushleft}
\begin{tabular*}{\textwidth}[h]{|l|@{\extracolsep{\fill}}p{0.78\textwidth}|}
  \hline
  \texttt{isInUse} &
  Test counter $>$ 0.\\
  \texttt{isAvailable} &
  Test counter $=$ 0.\\
  \texttt{canReuse} &
  Always false.\\
  \texttt{assign} &
  Add one to the use counter.\\
  \texttt{unassign} &
  Decrease use the counter by one.\\
  \texttt{dependencies} &
  (1) units (IU); (2) buses (move slots).\\
  \texttt{related} &
  None. \\
  \texttt{cycle} &
  1.\\
  \hline
\end{tabular*}
\end{flushleft}

\subsection{Automatic (Dependence-Based) Assignments}

When a resource depends on another resource, it can be assigned
automatically whenever the latter is assigned. Automatic assignment makes
the resource manager more efficient, because it avoids calls to
resource-specific brokers (described in Section~\ref{ssec:ResourceBroker})
and tests for availability. The following resources are (given the necessary
context information) automatically assigned:
\begin{description}
\item[P-Socket.]%
  Context: Function unit (inputs and outputs), input or output index of
  operation. Note: the same p-socket can be attached also to a RF or an IU.
  When used for a RF or an IU, the p-socket is allocated as independent
  resource.
\item[Segment.]%
  Context: Bus, source and destination sockets or segments. Condition: the
  segment must be is in the path between the source and the destination of
  the requested transport.
\item[Busses.]%
  Context: Instruction template. Each slot of the template is univocally
  associated to a bus.
%
  \note{EXTENSION: support for TTA's that are not bus programmed}
\item[Operation Pipeline.]%
  Context: triggering P-socket. The internal resources of the pipeline that
  are assigned depend on the operation set by the p-socket (if
  opcode-setting) or by the union of every possible operation set as last
  (if triggering but not opcode-setting).
\item[Immediate Unit.]%
  Context: Instruction template. Note: the unit is assigned, but the
  destination register is not automatically determined. It is allocated
  independently, taking into account the IU resource state (the availability
  of its registers). Meaning, assignnemnt of Immediate Unit should return
  register index.
\end{description}

\subsection{Graph of the Resource Object Model}
\label{ssec:resource-graph}

Through their `dependent' and `related' links, resource objects form a
graph, shown in Figure~\ref{fig:resource-graph}.
%
This graph is the concrete implementation of a resource object model. The
implementation of the resource model provided with the toolset includes the
concrete types described in Section~\ref{ssec:properties-resources}.

\begin{figure}[tb]
\centerline{\psfig{figure=eps/ResourceGraph.eps,scale=0.55}}
\caption{Resources of the resource object model and their relations. Dashed
  and solid arrows indicate, respectively, ``related'' and ``dependent''
  links.}
  \label{fig:resource-graph}
\end{figure}


\subsection{Visibility of Methods for Adding Resource Links}

Methods for adding resource links (dependent or related resources) should be
provided as empty protected interfaces in base class. There should
be
%
\note{DISCUSS}
%
a base subclass inherited by all concrete resource types that need to handle
resource links. This subclass would promote the visibility of such methods
to public.

\subsection{Optimisation of Pipeline Resources}

It is not necessary that every operation supported by a function unit have
its own instance of resource usage profile. A pipeline resource can use the
same profile for several operations, on condition that the operations use,
cycle by cycle, exactly the same internal pipeline resources.

\subsection{Jump Delay Slot Model}
\label{ssec:delay-slots}

An important architectural constraint of TTA processors is that control
transfer operations cannot be placed in one of the delay slots of a previous
control transfer. This constraint is modelled by a fake internal pipeline
resource. The usage profile of this internal resource extends uninterrupted
for a number of cycles equal to the number of delay slots.

For example, a jump operation with 3 delay slots has the following usage
profile for the (fake) internal pipeline resource `R':
\begin{quote}
\begin{tabular}{|l|c|c|c|c|}
\hline
                & \multicolumn{4}{c|}{cycle} \\
\cline{2-5}
  \raisebox{1.5ex}[0ex]{resource} & 0  & 1 & 2  & 3 \\
\hline
  R                               &  - & x & x & x \\
\hline
\end{tabular}
\end{quote}
It is noteworthy that the pseudo-resource is \emph{not} busy in cycle zero,
when the operation is triggered. It is perfectly possible (other resource
constraints not barring) that two or more control transfer operations start
in the same cycle.\footnote{
%
  This model of constraints due to delay slots has nothing to do with the
  real hardware implementation. The delay slots are due to the global
  transport pipeline, and are unrelated to the jump execution pipeline. The
  delay slot constraint is an architectural limitation rather than a real
  hardware conflict.}

\subsection{Pipeline Availability Test}
\label{ssec:pipeline-available-test}

Checking whether a given execution pipeline resource is completely
unavailable is computationally expensive. Every usage profile of the
pipeline (in the worst case, one for each supported operation of the FU)
must be checked for resource conflicts.

It is possible to speedup this test at expense of accuracy. As long as the
result is conservative (that is, unavailable resource is never reported when
the pipeline is available for at least one operation), it cannot make a
client fail.
%
For example, the condition that no resource at all is free, even though
impossible to occur on some pipeline models, is conservative and easier to
compute.

\section{Error Handling}
\label{ssec:resource-model-errors}

\subsection{Adding Resource Links to Non-existing Groups}

The methods of \emph{SchedulingResource} that add resource links (dependent
or related resources) are highly error-tolerant: if a client requests to add
a resource to a non-existing group, the group is simply created. All groups
between the last existing group and this new group are created and left
empty.



\chapter{Resource Manager}
\label{ch:ResourceManager}

The Resource Manager is the main module responsible for the allocation and
assignment of processor resources and for the verification and validation of
the schedule with respect to scheduling constraints.

\section{Overview}

The scheduling framework defines a main interface, \emph{ResourceManager},
for modules that are responsible of resource allocation and assignment. This
interface defines only a basic set of operations, but can be freely extended
to provide clients with finer, centralised control over the allocation and
assignment process.

A resource manager based on resource objects (such as the default
implementation provided by Scheduler) decides (either directly or
indirectly, through a controlled object), the order in which resources are
tested for availability and assigned to a node. Resources of the same type
are managed by specialised objects called resource brokers. The resource
manager just defines the order in which brokers are invoked. It does not
coordinate resource brokers during allocation or assignments. This task is
entirely delegated to the broker director.

The broker invokes brokers and keeps track of the available resources found
by each broker for the given request.
%
Brokers exploit the internal knowledge of resource objects about related,
compatible resources (see Section~\ref{ssec:broker-allocation}) to speed up
allocation and assignment.

The resource manager takes advantage of the associations between resources
in the resource graph (see Section~\ref{ssec:resource-graph}). Following the
dependencies and the relations between resources, it can find a sequence of
resource types that minimise the number of tests performed to allocate
resources. For example, resource assignment of a completely unassigned node
can proceed starting from those resources that are limited by properties of
the node (see Section~\ref{ssec:node-types}), such as the operation and the
operatin index.
%
\begin{figure}[tb]
\centerline{\psfig{figure=eps/AllocationGraph.eps,scale=0.70}}
\caption{Graph of all possible allocation sequences.}
  \label{fig:allocation-graph}
\end{figure}
%
Figure~\ref{fig:allocation-graph} depicts all possible allocation paths
between different resource types and all resources that are constrained by
node properties.\footnote{
%
  Notice that the segment resource could be implemented as a resource
  completely hidden inside bus resource, since it has only direct
  dependencies with other resources.}
%
A relation link, shown as dashed line, implies a potential allocation
problem, that is, the selection of one of several candidates. A dependency
link, shown as a continuous line, implies automatic assignment.
%
In Figure~\ref{fig:allocation-graph} register files are treated like a node
property, because the implementation resource manager described here expects
GPR's to be already assigned.
%
The shown graph is not the only possible. For example, with a minimal
restriction to the architecture template (that is, no socket can be
connected to more than one IU), the association from p-socket to IU becomes
a dependency.
%
The relation from IU to instruction templates is a bit special, because it
can span several cycles.
%
The constant of a node can have two assignments: IU or in-line immediate.
The latter is modelled as a dedicated output p-socket that is always
connected to one bus, and so has a dependency association to a bus resource
instead of a relation association.

\subsection{Resource Manager}
\label{ssec:ResourceManager}

A resource manager is constructed from an object model of the target
processor (MOM). With it, it builds the necessary resource models and
resource brokers. Then, it prepares itself for operation.

If the \emph{ResourceManager} implementation delegates resource allocation
to several resource brokers (Section~\ref{ssec:ResourceBroker}), then
initialisation may include construction of an assignment plan
(Section~\ref{ssec:AssignmentPlan}).

Whenever the resource manager has to allocate (or assign) a node, it walks
through the brokers in the assignment plan and request each broker to assign
a resource of its type to the node.

Allocation requires to evaluate a potentially large number of combinations
of assignments of different types of resources.
%
The assignment plan must keep track of all valid assignments for a given
resource type, and record which of these assignments have been already
evaluated.
%
For this reason, an assignment plan holds the current (temporary) state of
brokers' activity as they try to allocate or assign resources to a node.

The resource manager affects only the node of the request. It can examine
the assignment state of other nodes (somehow related to the given node),
possibly using some external helper, but it can not change any nodes other
than the given input node.

\subsection{Broker Director}
\label{ssec:BrokerDirector}

The broker director controls the actual process of assigning or allocating
resources to a node. It has two responsibilities:
\begin{enumerate}
\item%
  Acting as a main controller, it decides the order in which single
  resource-specific brokers (see Section~\ref{ssec:ResourceBroker}) are
  invoked to perform their bit of the allocation or assignment.
\item%
  It keeps a record of the results returned by brokers and optimises their
  utilisation. For example: if, given an available resource \emph{R}
  tentatively assigned to the node, no resource of another type is
  available, the director does not even test availability of the remaining
  unassigned resources. Instead, it backtracks to the tentative assignment
  of \emph{R}, undoes it and tries another resource of the same type.
\end{enumerate}

\begin{figure}[tb]
\centerline{\psfig{figure=eps/BrokerDirector.eps,%
    clip,trim=0 420 0 30,scale=0.5}}
\caption{Broker director and its associations with the other classes of the
  resource manager module.}
  \label{fig:broker-director}
\end{figure}
%
The class diagram of Figure~\ref{fig:broker-director} depicts the broker
director and its main associations with the resource manager and the helper
classes that enable the process of assigning or allocating resources to a
node. The broker director and a concrete resource manager implement the same
basic resource manager interface. This is required because all base
assignment and allocation requests of a manager should be forwarded to the
broker director.

The broker director is loosely inspired by the
\emph{Mediator}~\cite{DesignPatterns} design pattern. The broker director
does not hard-code dependencies between resource brokers nor the invocation
sequence. Because of this, it is possible to replace a broker for a given
resource with an equivalent broker without changing the broker director.

Implementations of \emph{ResourceManager} without a separate broker director
object are possible. The motivation for having it is that, thanks to
extensive polymorphism, broker director is a rather stable class of the
framework. On the contrary, many resource managers, differing just by order
and type of brokers, could be devised, all equally compatible with a fixed
director.
%
Seen from another perspective, variation among resource managers is mostly
encapsulated in specific resource broker implementations and in the
assignment plan instance. Together, these objects implement a strategy for
allocation and assignment of nodes.

\subsection{Resource Brokers}
\label{ssec:ResourceBroker}

Usually, but not necessarily, a \emph{ResourceManager} implementation will
distribute its responsibility among several resource-specific sub-managers,
called resource brokers. Conventionally, a resource broker should be named
after the (main) resource it manages: \emph{OperationInputBroker},
\emph{BusBroker}, and so on.

Each broker works with a part of the resource model. Brokers do not
communicate directly with each other, but only through
\emph{BrokerDirector}, \emph{ResourceManager} and similar control classes.

An important responsibility of the resource brokers is to efficiently model
intrinsic capabilities of a resource and constraints between resources due
to the structure of the target processor. For example, a given FU supports
only a subset of operations, and a given socket is connected only to a
subset of busses. Constraints between resources are also modelled inside
single resource objects (as dependent and related resource sets), but a
broker could have its own equivalent, more efficient data structure.

Brokers are responsible to maintain the only link between resource objects
and processor components (MOM objects). The motivations for this are:
\begin{enumerate}
\item%
  Resource objects are pure abstractions, with no specialised, direct link
  with machine components.
\item%
  Often, resource-component associations can be managed more efficiently by
  a broker than by single resource objects. For example, looking up a
  resource object given a processor component is quicker.
\end{enumerate}

As described in Section~\ref{ssec:properties-resources}, different concrete
resource types have different behaviour and properties.
%
The following resource brokers are provided with the default resource
manager of the toolset:
\begin{enumerate}
\item%
  \emph{InputFUBroker}: maps operation inputs to p-sockets and, as side
  effect of assigning an opcode-setting p-socket, operations to execution
  pipelines. This broker is responsible for assigning function units,
  their input ports and the execution pipelines.
\item%
  \emph{OutputFUBroker}: maps operation outputs to p-sockets and, as side
  effect of assigning an opcode-setting p-socket\footnote{
%
    Only in case of trigger-on-result operations.},
%
  operations to execution pipelines. This broker is responsible for
  assigning function units, their output ports and, if trigger-on-result is
  supported, the execution pipelines.
\item%
  \emph{InputPSocketBroker}: maps a write access to a unit to one of its
  ports and the socket attached to it.
\item%
  \emph{OutputPSocketBroker}: maps a read access to a unit to one of its
  ports and the socket attached to it.
\item%
  \emph{IUBroker}: maps constants to registers of an IU.
%
  \note{PENDING: \ref{ch:pending:long-immediates}}
\item%
  \emph{BusBroker}: maps transports to buses.
\item%
  \emph{ITemplateBroker}: assigns instruction template for each cycle
\end{enumerate}

From the point of view of a single broker, there are three groups of
resource types:
\begin{enumerate}
\item %
  \emph{Primary}: the type of resource directly managed by this broker. For
  example, an \emph{InputPSocketBroker} allocates and assigned
  \emph{InputPSocketResource} objects.
\item %
  \emph{Secondary}: resource types allocated or assigned by this broker as
  side-effect (dependent resources). For example, an \emph{FUInputsBroker}
  allocates and assigns \emph{PipelineResource} objects.
\item %
  \emph{Other}: types of resources that are allocated or assigned by other
  brokers, but may be tested also by another broker for availability. For
  example, a \emph{BusBroker} can test \emph{InputPSocketResource} objects,
  which are related to \emph{BusResource} instances, but does not assign
  them.
\end{enumerate}

A resource broker can be replaced by another broker only if their resource
types are compatible (map to the same machine parts, have the same links to
other compatible resource types).

A broker may ignore dependent resource types it does not recognise, and
leave them to brokers.

\paragraph{Brokers and constraints to resource allocation.}

Brokers can be subdivided in two types:
\begin{enumerate}
\item %
  ``Action-resource'' brokers manage resources whose allocation is
  restricted by the properties of the given unassigned node. For example,
  the FU assignment of \emph{InputFUBroker} is restricted by the operation
  specified by the node destination; the bus and in-line immediate
  assignment is restricted by the bit width of the
  constant specified by the node source.
\item %
  ``Resource-resource'' brokers manage resources that are not directly
  related to the properties of unassigned nodes. For example, the assignment
  of output p-sockets is not restricted by the source of the given node.
\end{enumerate}

Both types of brokers are affected by assignments to other resources. For
example, the assignment of a bus or a source unit to the input node can
restrict the set of candidates to p-socket assignment. See
Section~\ref{ssec:broker-allocation} for details.

This distinction has little influence on the design. Allocation requests are
represented by unassigned or partly assigned nodes, so ``actions'' and
pre-assigned resources are encapsulated in a single object.
%x
However, action-resource resource brokers are better candidates to begin the
assignment process, because they can use the information contained in the
unassigned node to restrict the number of assignment candidates.

\subsection{Strategy Broker}
\label{ssec:strategy-broker}

A strategy broker is a special type of broker that does not manage directly
a resource. Instead, it delegates allocation and assignment to other
brokers. A strategy broker analyses the input node and, based on its
contents, decides which underlying broker to call.

A concrete example of strategy broker is the broker that manages constant
node sources. Although constants could be handled by the simple broker
sequence \emph{ImmediateBroker}, \emph{IUBroker}, the constant strategy
broker implements a more sophisticated (and effective) assignment strategy,
like for example Algorithm~\ref{alg:constant-broker}.

\begin{algorithm}[tb]
  \caption{Test allocation of a constant in cycle \emph{c}}
  \label{alg:constant-broker}
  \renewcommand{\algorithmiccomment}[1]{\hspace{4ex}// #1}
\begin{algorithmic}[1]
  \STATE find minimum-width \emph{w} in-line immediate in \emph{c}
  \IF{\emph{w} found and narrow}
      \STATE return \textbf{true}
  \ELSE
     \STATE\hspace{-4ex}\COMMENT{either no in-line immediate available or
       available but too wide}
     \STATE find available immediate unit \emph{iu} in \emph{c}
     \IF{\emph{iu} not found}
       \STATE return \textbf{false} \COMMENT{no assignment possible}
     \ELSE
       \STATE\hspace{-4ex}\COMMENT{IU and register found, now look for
         template}
       \STATE \emph{c}$'$ = \emph{c} \COMMENT{initialise cycle of immediate
         definition (template allocation)}
       \WHILE{\emph{c} - \emph{c}$'$ does not exceed maximum distance}
          \STATE find available move slots in \emph{c}$'$ to encode immediate
          \IF{slots available \textbf{and} immediate width $<$ \emph{w}}
             \STATE return \textbf{true} \COMMENT{found long immediate
               smaller than in-line immediate}
          \ENDIF
          \STATE $c' = c' +1$
       \ENDWHILE
       \STATE\hspace{-4ex}\COMMENT{\emph{iu} available, but no cycle for
         immediate definition found}
       \STATE return \textbf{false} \COMMENT{no assignment possible}
     \ENDIF
  \ENDIF
\end{algorithmic}
\end{algorithm}
%
The \emph{ImmediateBroker} is first used to figure out whether any in-line
immediate can be assigned to the constant (1). If an in-line slot is
available and its width is not too much greater than the bit width of the
constant (it does not waste too many bits), then allocation returns with
success (2,3). If in-line immediate encoding is impossible, then the
strategy broker tries immediate register allocation. \emph{IUBroker} is used
to find a free immediate register that can be assigned to the constant (6).
Finding the immediate register is not enough; the strategy broker must also
look for resources to assign the immediate (move slots and instruction
templates). Unlike other resources, the immediate definition does not have
to be assigned in the cycle of the input node, \emph{c}. The strategy broker
starts from \emph{c} and moves backwards (12--18) until it finds an
available instruction template (that is, unused move slots). If the
immediate register can't be defined in any cycle of a predefined interval,
then allocation to an immediate register fails.

Algorithm~\ref{alg:constant-broker} can be refined in many ways. For
example, if allocation of an immediate register fails (8), (20) the strategy
broker, instead of returning failure, could ``content'' with the in-line
immediate assignment previously found, even if it wastes bits. Also, the
algorithm could return failure when the instruction template found to define
the immediate wastes too many bits.

In summary, a strategy broker makes it possible to find balanced trade-offs
between partially conflicting goals such as resource utilisation (don't
waste bits, in this case) and aggressive scheduling (schedule as early or
as late as possible, don't risk to stretch the longest execution path).

A simple kind of strategy broker is the dispatch broker,
%
\note{dispatch broker should be useless thanks to the pruning of
  non-applicable resource brokers}
%
which, depending on the type of request invokes one of several, mutually
exclusive brokers.

\subsection{Assignment Plan}
\label{ssec:AssignmentPlan}

Class \emph{AssignmentPlan} is the central helper of the assignment and
allocation algorithm.
%
First of all, it keeps the order in which single resource-specific brokers
(see Section~\ref{ssec:ResourceBroker}) are invoked to perform their bit of
the allocation or assignment.
%
Second, the assignment plan records the current state of tentative and
potential assignments for each type of resource.

\emph{AssignmentPlan} contains an ordered sequence of pending assignments
(see Section~\ref{ssec:PendingAssignment}), and implements advancing and
backtracking of the tentative assignments as sketched in
Section~\ref{ssec:ResourceManager}.

The assignment plan may perform simple optimisations of the broker sequence
(see Section~\ref{ssec:AssignmentPlan-imp}).

\subsection{Temporary State of a Resource Assignment}
\label{ssec:PendingAssignment}

Class \emph{PendingAssignment} represents a piece of the ``working state''
of an assignment process. It consists of a set of possible assignments for a
given resource broker. There is a pending assignment object for each
resource broker involved in the allocation or assignment process (thus for
each type of unassigned resource).

\emph{PendingAssignment} has two responsibilities:
%
\begin{enumerate}
\item %
  Forward requests to its resource broker and handle the results. In this
  respect, \emph{PendingAssignment} is an adaptor.
\item %
  Manage the candidate assignments found by the resource broker, and keep
  track of which of these have been already evaluated.
\end{enumerate}

\subsection{Resource Construction}
\label{ssec:resource-construction}

The resource model is constructed by the only objects that know the concrete
type of each resource object and its mapping to parts of the target
processor (MOM objects): the resource brokers
(Section~\ref{ssec:ResourceBroker}).

Delegating resource construction to brokers is not free from design
challenges.
%
Brokers are independent (do not have any link to each other). Each broker
knows only the mapping between map machine parts and its primary resources.
%
Only a broker knows what are the dependencies and the relations of its
primary resources with other resources. However, a broker does not know how
to access other resource objects.

While it constructs instances of its primary resource type, a broker does
not know how to find the related and dependent resources. It just knows that
certain machine parts somehow related to primary resources must have a
mapping to instances of other resource types.
%
During construction, some of these resource instances do not exist at all.
This is the case of primary resources of a broker that has not yet been
requested to build its resources.

For all these reasons, resource construction must proceed in two phases.
%
\begin{enumerate}
\item%
  Each broker builds its primary resource objects. A broker knows about
  dependencies and relations between its resources and other machine parts,
  but has no way (yet) to find the resource objects corresponding to them.
\item%
  Each broker completes resource construction by setting up all references
  to dependent and related resources with the help of an external helper
  object that maps machine parts to resources as needed.
\end{enumerate}

The whole construction process needs a main class that coordinates the
brokers. This is \emph{ResourceBuildDirector}, described in
Section~\ref{ssec:ResourceBuildDirector-if}.
%
The second phase requires a helper object, an associative container to
quickly find the resource objects corresponding to machine parts:
\emph{ResourceMapper} (Section~\ref{ssec:ResourceMapper-if}).

\begin{figure}[tb]
  \centerline{\psfig{figure=eps/ResourceConstruction.eps,%
    clip,trim=0 620 0 30,scale=0.70}}
  \caption{Classes involved in resource construction and their main
    dependencies.}
  \label{fig:resource-construction}
\end{figure}
%
Figure~\ref{fig:resource-construction} depicts the relations between the
resource manager, the resource build director, the resource mapper, and the
resource brokers.
%
The resource manager constructs the resource build director and registers
empty brokers into it (not shown). Construction of the resource model begins
with a request from the resource manager to the build director. The director
forwards the request to each broker it holds. Each broker creates its own
resource instances.
%
After all resources have been created, the build director prepares the
resource mapper and then asks each broker to build the associations between
its resources and other resource instances. The brokers use the resource
mapper to find out which resource object corresponds to the machine parts
that depend or are related with its primary resources.

\begin{figure}[tb]
\centerline{\psfig{figure=eps/BrokerStates.eps,%
    clip,trim=0 660 0 30,scale=0.55}}
\caption{States of resource brokers.}
  \label{fig:BrokerStates}
\end{figure}
%
Given this resource construction design, resource brokers can take three
states, as Figure~\ref{fig:BrokerStates} shows. After construction, a
broker is empty. Any request to it except building resources results in an
error. After the first construction phase, the broker is ``initialised'': it
contains all resources it is responsible for. However, an initialised broker
is generally not yet ready for normal operation, because its resources lack
the references to dependent and related resources.\footnote{
%
  Only references to dependent resources, when applicable, are strictly
  needed. References to related resources are not. If a broker manages
  resources that have no links to other resources, then it is ready
  immediately after the first phase.}
%
Only after the second phase is completed the resource broker enters the
`ready' state and can accept any allocation, assign or free request from
clients. Generally, only the resource manager and the resource build
director ever see brokers in empty and initialised states. For normal
clients, brokers are always ready.

\subsection{Support for Partially Assigned Code}

Since resource allocation can be split into several separate passes, it may
be necessary to support code where only certain types of resources are
assigned (partially assigned code). A resource manager that supports
partially assigned instructions and moves should reinterpret the meaning of
resources that belong to the Universal Machine (described in detail
in~\cite{TCE-progTemplate}). When a move has one of its parts assigned to a
resource of the UM, the manager treats that part as unassigned. This means
that certain constraints of the sequential code are ignored by the resource
manager.
%
Even if passes that perform partial assignment are not supported, resource
managers usually profit from ignoring constraints related to sequential
code and UM temporarily, during resource assignment. Assignments to UM
resources are, mostly, no assignments at all, so ignoring them simplifies
the allocation task.

To support partially assigned TTA instructions, a resource manager must
ignore the UM resource constraints listed below. Otherwise, it will detect
spurious resource conflicts and report non-existing errors.
%
\begin{description}
\item[Busses.]%
  The UM has only one bus, so in valid sequential code at most one move can
  appear in each cycle. For resource managers, a cycle can contain more
  than one move assigned to the UM bus.

\item[General Purpose Registers.]%
  Registers of the UM are unlimited but, since a register represents a
  program value in all instructions covered its live range, assignment
  requires live range and dataflow analysis. So even UM registers cannot be
  assigned simply by looking at their availability in a given cycle.

  Because of this, the same constraints apply to UM registers, whether the
  code is treated as target TTA code for a sequential architecture or just
  as a temporary representation for the resource managers.

\item[Function Unit.]%
  The UM has only one function unit, the universal function unit (UFU). It
  supports any operation, but only one operation per cycle can be started.
  For resource managers, a cycle can contain any number of moves that start
  different operations (even different instances of the same operation).

\item[RF Ports.]%
  The UM has only one integer, one Boolean (1-bit) and one floating-point
  register file. Each needs only one input and one output port, because only
  one move per cycle is possible. For resource managers, a cycle can contain
  more than one move that reads or writes same UM RF. All these moves appear
  to use the same input or output port, so resource manager must ignore
  conflicting assignments to RF ports of the UM.

\item[FU Ports.]%
  The UM has only one function unit (UFU) and a limited\footnote{
%
    The number of UFU ports and their binding to operation inputs and
    outputs is left unspecified. Applications that work with TTA sequential
    code should be able to handle any binding, as long as it is correct from
    the point of view of TTA processor definition.}
%
  number of ports, because it allows only one move per cycle. During
  resource allocation, a cycle can contain more than one move that reads or
  writes the same UFU port. So, resource manager must ignore conflicting
  assignments to UFU ports.

\item[Sockets.]%
  The UM has a limited number of socket, since only one move per cycle can
  take place. In UM, ports do not share the same socket, so the same
  considerations made for RF and FU ports apply for sockets. For resource
  managers, a cycle can contain any number of moves that use the same UM
  socket. For example, concurrent moves that read or write the same UFU port
  will be assigned the same UM socket.
\end{description}

\paragraph{Partially assigned code and external files.}
While a resource manager could ignore, internally, most resource constraints
of the sequential code, some constraints have to be maintained if partially
assigned code is to be stored in regular TPEF files. For example, a plain
TPEF (without annotation or some other form of auxiliary information) cannot
track down single operations of a program if several moves in the same cycle
are part of different unassigned instances of the same operation.

\paragraph{Local resource constraint check.}
When working with partially assigned instructions, resource managers should
not worry about potential or even unavoidable resource conflicts that
concern resources for which they are not responsible.
%
For example, if a TTA instruction contains two or more moves that read
program variables assigned to registers of the same RF, but no RF ports are
assigned to the moves that read those registers, then the instruction is
always valid from the point of view of a resource manager that is not
responsible for RF ports, even if the RF in question should have only one
port.

\subsection{Assignment and Node Placement}
Resource assignment and the cycle where a node is placed are in principle
two independent properties of a node. In practice, however, they often go
hand in hand.

A client should not normally invoke \emph{setCycle} on a node, unless the
node is completely unscheduled. Usually, node placement takes place
automatically, as result of partial or complete assignment of resources
(\emph{assign} and \emph{updateAssignments} methods of resource manager).
%
Furthermore, a placed and partially assigned node cannot be moved to another
cycle with a simple \emph{setCycle} invocation. The correct sequence of
actions is the following: First, the assigned resources must be freed in
original cycle; then, the node (now completely unassigned) can be assigned
(or just placed) in the new cycle.

Similarly, a client should invoke \emph{unassign} method of resource
manager, rather than \emph{unsetCycle} on a node. Unlike in the case of
placement and assignment, the framework doesn't even provide a way to
unassign resources manually.

In short, when \emph{setCycle} is invoked by a client (not resource
manager), four cases can occur:
\begin{enumerate}
\item %
  The node is completely unassigned. Placement always succeeds (even if node
  was already placed).
\item %
  The node is already (partially) assigned to the same cycle. Useless but
  harmless invocation.
\item %
  The node is already (partially) assigned to another cycle. The method
  reports error.
\item %
  The node is (partially) assigned, but not yet placed (thus, the
  assignments are not registered in resource model). Placement succeeds, but
  the scheduler enters a corrupted condition, because the program
  representation and the state of the resource model are not ``in-sync''.
\end{enumerate}

When \emph{unsetCycle} is invoked by a client (not resource manager), three
cases can occur:
\begin{enumerate}
\item %
  The node is not placed. Useless but harmless invocation.
\item %
  The node is completely unassigned. Un-placement is always successful.
\item %
  The node is placed and (partially) assigned. Un-placement succeeds, but
  the scheduler enters a corrupted condition, because program
  representation and the state of the resource model are not ``in-sync''.
\end{enumerate}

There are no built-in protections from the cases that corrupt the scheduling
overall state.

\section{Interfaces}

\subsection{ResourceManager}

The \emph{ResourceManager} interface defines the minimum set of operations
that must be provided by any resource allocation module that complies with
the scheduling framework guidelines:
%
\begin{description}
\item[canAssign(cycle : const int, node : MoveNode) : bool]%
  Return true if given node can be assigned without resource conflicts in
  given cycle. For those parts of the node that have been already assigned
  to a resource, the manager simply keeps the assignment and verifies that
  the resource is available. For those parts that are not yet assigned, the
  resource manager looks for any compatible resource that could be assigned.

\item[assign(cycle : const int, node : MoveNode)]%
  Assign all resources needed by a given node starting from given cycle, and
  place the node in that cycle. The manager keeps any pre-existing
  assignment and verifies that assigned resource is available. For all
  unassigned parts of the node, the resource manager looks for and then
  assigns the necessary resources. If the node is not fully
  assigned\footnote{
%
    Here, ``fully'' is intended from the point of view of the resource
    manager. Resources that are not allocated by a given manager are not
    considered. For example, if a resource manager implementation does not
    handle GPR's, then a fully allocated node may still have no RF and GPR
    assigned to it.}
%
  after the invocation of this operation, it means the assignment attempt
  failed.

  Throw \emph{InvalidObject} exception if given node is already placed in a
  cycle different from given cycle.

\item[unassign(node : MoveNode)]%
  Free all resource assignments of a given node. If the node is only
  partially assigned, the resource manager ignores those parts of the node
  that are already unassigned.
%
  \note{PENDING: \ref{ch:pending:linked-assignments}}

  Throw exception if the given node is not placed in any cycle. Assigned but
  not placed nodes are not considered by the resource manager.

\item[earliestCycle(node: MoveNode) : int]%
  Return the earliest cycle in the scope where all required resources can be
  assigned to the given node. If the node is partially assigned, the manager
  keeps existing assignments. This means that a client can apply arbitrary
  constraints to resource allocation.

\item[earliestCycle(cycle : const int, node: MoveNode) : int]%
  Return the earliest cycle starting from the given cycle in which required
  resources can be assigned to given node. If the node is partially
  assigned, the manager keeps existing assignments. This means that a client
  can apply arbitrary constraints to resource allocation.

\item[latestCycle(node: MoveNode) : int]%
  Return the latest cycle in the scope where all required resources can be
  assigned to the given node. If the node is partially assigned, the manager
  keeps existing assignments. This means that a client can apply arbitrary
  constraints to resource allocation.

\item[latestCycle(cycle : const int, node: MoveNode) : int]%
  Return the latest cycle starting from the given cycle in which required
  resources can be assigned to given node. If the node is partially
  assigned, the manager keeps existing assignments. This means that a client
  can apply arbitrary constraints to resource allocation.
\end{description}

The following methods can be optionally provided by implementations of
\emph{ResourceManager} to let clients force assignments (and unassignment)
of resources.

\begin{description}
\item[supportsExternalAssignments() : bool]%
  Return true if this implementation can handle nodes with resources
  directly (un)assigned by clients. If the resource manager returns false,
  then methods \emph{validAssignments} and \emph{updateAssignments} cannot
  be called.x

\item[validAssignments(cycle : const int, node: MoveNode) : bool]%
  Return true if the resources assigned to the given node in given cycle are
  available and can be assigned. The node is assumed to be completely
  unassigned except for the assignments forced by the client.
%
  \note{PENDING ISSUE: \ref{ch:pending:ext-assignment}}
%
  Resource managers do not support external assignment forced upon nodes
  that are already partially assigned.

\item[updateAssignments(cycle :const int, node: MoveNode)]%
  Update the state of the resource model with all resources assignments
  specified by the given node and place the node in given cycle. The manager
  assumes that none of the assignments in the node is currently reflected in
  its resource model, so if one of the assigned resources is already in use,
  the manager signals an error condition (see
  Section~\ref{ssec:invalid-ext-assignment}). All unassigned parts of the
  node are left unassigned and do not affect the corresponding resources in
  the resource object model.

  Throw \emph{InvalidObject} exception if given node is already placed in a
  cycle different from given cycle.
\end{description}

In addition to above, \emph{SimpleResourceManager} distributed with TCE framework
also provides methods for assigning and unassigning of long immediates, method for
accessing an Instruction object with Moves assigned for given cycle, as well as
methods for testing if transport is possible and required guard exists.
\begin{description}
    \item [canAssignLongImmediate(defCycle: int, useCycle: int, node: MoveNode): bool]
	Return true if immediate constant in source of a node can be assigned into
	some immediate unit register in defCycle and read by node in useCycle.
    \item[assignLongImmediate(defCycle: int, useCycle: int, node: MoveNode)]
	Assigns immediate write to some register in immediate unit in defCycle. 
	Modifies node to read from given register.
    \item[unassignLongImmediate(defCycle: int, node: MoveNode)]
	Removes assignmend of immediate to immediate register. Restores original
	source in node.
    \item[canTransportImmediate(node: MoveNode)]
	Checks if Machine is capable of transporting immediate in source of a node
	using short immediate of some bus.
    \item[hasGuard(node: const MoveNode): bool]
	Checks if any of a buses of machine supports a guard which is used
	in node.
    \item[hasConnection(node: MoveNode): bool]
	Checks if move in a node is possible on given machine - without
	considering other possible moves in same cycle.
    \item[instructionCopy(cycle: int): TTAProgram::Instruction*]
	Returns Instruction for given cycle.
\end{description}

\subsection{BrokerDirector}
\label{ssec:BrokerDirector-if}

\begin{description}
\item[BrokerDirector(plan : AssignmentPlan\&)]%
  Constructor. Create a broker director with given assignment plan.
\end{description}

\emph{BrokerDirector} adapts a restricted subset of the interface
\emph{ResourceManager}.

\begin{description}
\item[canAssign(cycle : const int, node : MoveNode) : bool]%
\item[assign(cycle : const int, node : MoveNode)]%
\item[unassign(node : MoveNode)]%
\item[earliestCycle(node: MoveNode) : int]%
\item[earliestCycle(cycle : const int, node: MoveNode) : int]%
\item[latestCycle(node: MoveNode) : int]%
\item[latestCycle(cycle : const int, node: MoveNode) : int]%
\end{description}

Usually, a \emph{ResourceManager} implementation just forwards above listed
methods to its broker director.

\subsection{ResourceBroker}
\label{ssec:ResourceBroker-if}

The \emph{ResourceBroker} interface defines the basic operations expected
by resource manager from any resource broker.
\begin{description}
\item[isAnyResourceAvailable(cycle : const int, node : const MoveNode) : bool]%
  Return true if one of the resources managed by this broker is suitable for
  the request contained in the node and can be assigned to it in given
  cycle.
\item[availableResource(cycle : const int, node : const MoveNode) :
  SchedulingResource\&]%
  Return one (any) resource managed by this broker that can be assigned to
  the given node in the given cycle. If no change occurs to the state of the
  resources, the broker should always return the same object. If a resource
  of the type managed by this broker is already assigned to the node, it is
  returned.
\item[allAvailableResources(cycle : const int, node : const MoveNode) :
  SchedulingResourceSet]%
  Return all resources managed by this broker that can be assigned to the
  given node in the given cycle.
\item[earliestCycle(cycle : const int, node : const MoveNode) : int]%
  Return the earliest cycle, starting from given cycle, where a resource
  of the type managed by this broker can be assigned to the given node.
\item[earliestCyclesOfAllResources(cycle : const int, node : const MoveNode) :
  ResourceCyclePairList]%
  Return a list of all resources suitable for the request contained in the
  given node. Each resource is paired with the earliest cycle, starting from
  given cycle, in which it is available for the node.
\item[latestCycle(cycle : const int, node : const MoveNode) : int]%
  Return the latest cycle, starting from given cycle, where a resource
  of the type managed by this broker can be assigned to the given node.
\item[latestCyclesOfAllResources(cycle : const int, node : const MoveNode) :
  ResourceCyclePairList]%
  Return a list of all resources suitable for the request contained in the
  given node. Each resource is paired with the latest cycle, starting from
  given cycle, in which it is available for the node.
\item[isAlreadyAssigned(cycle : const int, node : const MoveNode) : bool]%
  Return true if the given node is already assigned a resource of the type
  managed by this broker, and the assignment appears valid (that is, the
  broker has marked that resource as in use in the given cycle).
\item[isApplicable(node : const MoveNode) : bool]%
  Return true if the given node needs a resource of the type managed by this
  broker, false otherwise.
\item[assign(cycle : const int, node : MoveNode, resource :
  SchedulingResource\&)]%
  Mark given resource as in use for the given node, and assign the
  corresponding machine part (if applicable) to the node's move.

  Throw \emph{WrongSubclass} if this broker does not recognise the given
  type of resource.
%
  Throw \emph{InvalidData} if the given resource cannot be assigned to given
  node.
%
  If the node is already assigned to given resource, this method does
  nothing.
\item[unassign(node : MoveNode)]%
  Free the resource type managed by this broker and unassign it from given
  node.

  If this broker is not applicable to the given node, or the node is not
  assigned a resource of the managed type, this method does nothing.
\end{description}

Each broker implements the methods for constructing the part of the resource
model it controls:
\begin{description}
\item[buildResources(target : const Machine\&)]%
  Build all resource objects of the controlled type required to model
  scheduling resources of the given target processor.

  Normally, this method cannot set up the resource links (dependent and
  related resources) of the constructed resource objects.
\item[setupResourceLinks(mapper : const ResourceMapper\&)]%
  Complete resource initialisation by creating the references to other
  resources due to a dependency or a relation. Use the given resource mapper
  to lookup dependent and related resources using machine parts as keys.
\end{description}

Internally, a resource broker keeps an associative mapping between each
machine part of the input target processor and the resource object that
models it. The following interface makes it possible to retrieve one using
the other as key:
\begin{description}
\item[resourceOf(mp : const MachinePart\&) : SchedulingResource\&]%
  Return the resource instance that models the given machine part.

  Throw \emph{WrongSubclass} exception if \emph{mp} is not one of the
  machine parts modelled by the primary resources of this broker.
\item[machinePartOf(r : const SchedulingResource\&) : MachinePart\&]%
  Return the machine part that models the given resource.

  Throw \emph{WrongSubclass} exception if \emph{r} is not one of the primary
  resources of this broker.
\item[hasResourceOf(mp : const MachinePart\&) : bool]%
  Return true if this broker holds a resource instance that models given
  machine part.
\item[hasResource(r : const SchedulingResource\&) : bool]%
  Return true if this broker holds given resource instance.
\end{description}

\subsection{AssignmentPlan}
\label{ssec:AssignmentPlan-if}

The following operations are provided for clients that construct the
assignment plan. These operations are used mostly by the resource manager.
\begin{description}
\item[insertBroker(broker : Broker\&, where : const Broker\&)]%
  Insert the resource broker \emph{broker} in the sequence of brokers before
  the resource broker \emph{where}. If the second parameter is omitted, then
  the resource broker is appended at the end of the sequence.
\item[removeBroker(broker : Broker\&)]%
  Remove the resource broker \emph{broker} from the sequence of brokers.
\end{description}

Before starting allocation or assignment, the assignment plan receives input
data: the node and the requested cycle:
\begin{description}
\item[setRequest(node : MoveNode\&, cycle : int)]%
  Record the input node to which resources have to be assigned or allocated,
  and the cycle in which the node should be placed.
\end{description}

The following operations provide the service for which \emph{AssignmentPlan}
is designed: allocation or assignment of resources to a node. The client of
these operations is usually the broker director.
\begin{description}
\item[firstBroker() : ResourceBroker\&]%
  Return the first broker to be evaluated during an assignment process.
\item[lastBroker() : ResourceBroker\&]%
  Return the last broker to be evaluated during an assignment process.
\item[currentBroker() : ResourceBroker\&]%
  Return the current broker, that is, the broker whose resources are being
  evaluated during an assignment process.
\item[advance()]%
  Move to next resource broker in the sequence. This usually requires that a
  valid resource of current broker has been found and (tentatively) assigned
  to the node.
\item[backtrack()]%
  Unassign (if needed) the resource of current broker from the node and then
  move to previous resource broker in the sequence. The pending assignments
  of the current node are forgotten.
\item[tryNextAssignment()]%
  Unassign (if needed) the resource of current broker from the node and then
  assign the next resource from the same list of pending assignments.
\item[isTestedAssignmentPossible() : bool]%
  Return true if no tentative assignments are possible with the current
  broker and the tentative assignments currently applied from the preceding
  resource brokers. There are two reasons why no possible assignments are
  left with the current broker: (1) because all pending assignments have
  been tried; (2) because no valid assignment at all is possible.
\item[resetAssignments()]%
  Unassign as needed all the resources tentatively assigned starting from
  current resource broker back to the first one. Reset the current broker
  position to the first one.
\item[unsetRequest()]%
  Bring the assignment plan back to initial state. Re-enable any broker that
  was disabled for a given request; reset the request data (node, cycle).
\end{description}

\subsection{PendingAssignment}
\label{ssec:PendingAssignment-if}

\begin{description}
\item[tryNext()]%
  Try to assign the next possible assignment found by current broker. Aborts
  with error if this \emph{PendingAssignment} has run out of possible
  assignments (see Section~\ref{ssec:no-possible-assignments}).
\item[forget()]%
  Clear out the record of the possible resource assignments of the current
  broker that have been already tried. If one of the possible resources is
  still assigned to the node, unassign it.
\item[undoAssignment()]%
  Unassign the resource of this pending assignment currently assigned to the
  node. Aborts with error if no resource in the set of resources of this
  pending assignment is currently assigned to the node.
\item[broker() : ResourceBroker\&]%
  Return the broker of this pending assignment.
\item[isAssignmentPossible() : bool]%
  Return true if, for the currently applied assignments, there exists at
  least one tentative assignment which has not been tried yet.
\end{description}

\subsection{Resource Build Director}
\label{ssec:ResourceBuildDirector-if}

\begin{description}
\item[ResourceBuildDirector()]%
  Constructor. Create an empty director.
\item[addBroker(broker : ResourceBroker\&)]%
  Add given broker to the list of brokers responsible for resource
  construction. The order in which brokers are added is irrelevant.
\item[build(machine : const Machine\&)]%
  Build a complete resource object model for given target processor.
\item[\texttilde{}ResourceBuildDirector()]%
  Destructor. Clean up any helper objects created during resource
  construction. The controlled brokers are not destroyed.
\end{description}

\subsection{Resource Mapper}
\label{ssec:ResourceMapper-if}

\begin{description}
\item[ResourceMapper()]%
  Constructor. Create an empty mapper.
\item[addResourceMap(broker : const ResourceBroker)]%
  Register \emph{broker} as one of the elements that contribute to mapping
  a subset of machine parts to resources.
\item[resourceOf(mp : const MachinePart, index = 0 : int) :
SchedulingResource\&]%
  Find the resource object that corresponds to machine part \emph{mp} with
  index (default 0). \footnote{There can be several resource objects
  corresponding to single machine part. Example: FU corresponds to
  InputFUResource, OutputFUResource and ExecutionPipelineResource.}

  Throw \emph{UnresolvedReference} if no resource in the mapper models
  \emph{mp}. Throw \emph{InvalidObject}
%
\note{DISCUSS: InvalidObject exception?}
%
  if the resource mapper has no map at all (it was not initialised).
\end{description}

\section{Implementation}

\subsection{Limitations of Nodes as Assignment Requests}
\label{ssec:nodes-assignment-requests}

The node is the primary abstraction used to represent assignment and
allocation requests inside the resource manager. A node, however, is too
generic to express specific assignment requests for a single type of
resource.
%
To overcome this problem, all resource-specific restrictions that apply to a
request must be encapsulated (hard-coded) in the receiver. For example, there
must be an object for handling assignment requests for operation inputs, and
another object for requests for operation outputs.

Common parts of the implementations can be refactored in a lower-level
object that can use a more specific representation of the assignment or
allocation request (for example, a node terminal).

The following table lists the type of resource requests associated with
nodes.
\begin{flushleft}
\begin{tabular}{|l|l|c|c|c|c|c|}
    \hline
    \emph{assignment} & \emph{node}  &
      \multicolumn{5}{c|}{\emph{resource}} \\
    \emph{request} & \emph{representation} &
      \emph{port} & \emph{FU} & \emph{ireg} & \emph{GPR} & \emph{slot} \\
    \hline

    operation input  & destination & x & x &   &   &   \\
    \hline
    operation output & source      & x & x &   &   &   \\
    \hline
    constant         & source      &   &   &   &   & x \\
    \hline
    constant         & source      & x &   & x &   &   \\
    \hline
    variable read    & destination & x &   &   & x &   \\
    \hline
    variable write   & source      & x &   &   & x &   \\
    \hline
  \end{tabular}
\end{flushleft}

A source or destination may require assignment of more than one scheduling
resource. For example, all types of units (FU, RF, IU) require to allocate
also a port (shown in column `port').
%
Two alternative sets of resource assignments are possible for constant
sources: in-line immediates need just a source slot resource; ``long''
immediates need an immediate register (`ireg') and a port.
%
The entire node (or a source, destination pair) is a suitable representation
of assignment requests for data transports, which involve buses and
segments.

Certain types or resources, such as instruction templates and
slots of long immediates, are handled in special ways. Instruction
templates, for example, could be allocated by means of a strategy broker
(see Section~\ref{ssec:strategy-broker} and 
Algorithm~\ref{alg:constant-broker}).
%
\note{EXTENSION: bridge allocation}

Sockets are a resource in the middle ground between node terminals and
transport resources, and are partially constrained by both, as exemplified
in Section~\ref{ssec:broker-allocation}.

\subsection{Allocation of Partially Pre-assigned Nodes}

During allocation or assignment resources for a node, the resource manager
temporarily marks tentatively assigned resources in-use, and assigns the
corresponding machine parts to the node.\footnote{
%
  This is not the only way to design resource allocation, but alternative
  designs are not considered in this document.}
%
When the input node is partially pre-assigned, allocation is more
problematic. The resource manager must ensure that all tentative assignments
are cleared up after the allocation is completed (or, when a request for
assignment fails). At the same time, pre-assigned resources should be kept.

From the point of view of single brokers, there is no difference between
resources that are pre-assigned to the input node and resources that are
tentatively assigned by another (previously invoked) broker.
%
It is a responsibility of a higher-level object (resource manager or broker
director) to remember which resources are busy because of a pre-assignment
to the node and which are temporarily assigned.

From the point of view of resource brokers, a (primary) resource can have
the following states (independent of the node being currently allocated or
not):
\begin{enumerate}
\item %
  \emph{Free and available}: the resource is free, the node has no assigned
  machine part corresponding to that resource type. If compatible with it,
  the resource could be assigned to the node.
\item %
  \emph{Assigned}: the resource is in use and the machine part corresponding
  to it is assigned to given node. No allocation of this resource type takes
  place.
\item %
  \emph{Not available}: the resource is in use, the node has no assigned
  machine part corresponding to that resource type. The resource, unless
  reusable, is unavailable for this node (it is assigned to another node).
\item %
  \emph{Ignored}: a machine part corresponding to a resource of the same
  type is already assigned to the node. Whether this resource is in use or
  not it is irrelevant, because the node has been already assigned. No
  allocation of this resource type takes place.
\item %
  \emph{Invalid}: the resource is free, but the corresponding machine part
  is assigned to the node. This state is invalid and results in an error
  condition, see Section~\ref{ssec:invalid-resource-state}.
\end{enumerate}

Notice that `assigned' and `ignored' states may come from a pre-assignment
or from a tentative assignment of a broker invoked before. A resource can be
assigned by a broker different from the one that normally manages it due to
a dependency. For example, when a broker that assigns a function unit to a
node terminal, it automatically assigns also the port-socket combination
(PSocket resource) even if this is not its primary resource, and it is
normally assigned by another broker. If, later, the input port-socket broker
is invoked, it will just detect that the node has already a valid assignment
for the type of resource it manages (all its resources will be in `ignored'
state except one, in `assigned' state).

\subsection{AssignmentPlan}
\label{ssec:AssignmentPlan-imp}

\paragraph{Pre-assignment optimisation.}

Before starting assignment or allocation proper, an \emph{AssignmentPlan}
should optimise itself for the given request. This occurs inside the
\emph{setRequest} method, which records the input node and the requested
cycle. The assignment plan can disable (remove from the tested sequence) the
brokers that are not needed for the given request. A broker is not needed if
not applicable to a node (broker's \emph{isApplicable} returns `false') or
is already assigned (broker's \emph{isAlreadyAssigned} returns `true').
%
This results in a shorter broker sequence and faster allocation or
assignment.

\subsection{Allocation Algorithm}
\label{ssec:allocation-algorithm}

\begin{algorithm}
  \caption{Test allocation of node \emph{n} in cycle \emph{c}}
  \label{alg:allocation-broker-director}
  \renewcommand{\algorithmiccomment}[1]{\hspace{4ex}// #1}
\begin{algorithmic}[1]
  \REQUIRE \emph{plan} assignment plan ready and reset
  \ENSURE  state of \emph{n} unchanged

  \STATE setRequest(\emph{n},\emph{c})
  \WHILE{not success}

    \IF{\emph{plan}.isTestedAssignmentPossible()}
      \IF{current \emph{plan} broker is the first one}
        \STATE \emph{plan}.resetAssignments()
        \STATE return false \COMMENT{no assignment found}
      \ELSE
        \STATE \emph{plan}.backtrack()
      \ENDIF

    \ELSIF{current \emph{plan} broker is the last one}
      \STATE \emph{plan}.resetAssignments()
             \COMMENT{make sure tentative assignments are cleaned up}
      \STATE success = true \COMMENT{assignment found}

    \ELSE
      \STATE \emph{plan}.tryNextAssignment()
      \STATE \emph{plan}.advance()
    \ENDIF
  \ENDWHILE
\end{algorithmic}
\end{algorithm}
%
Algorithm~\ref{alg:allocation-broker-director} tests whether there is a
complete set of available resources for the input node. Implemented inside
the \emph{canAssign} method of the broker director, it works in conjunction
with an internal copy of \emph{AssignmentPlan}.

After recording the input data and pruning the entries of the assignment
plan that contain brokers that are unnecessary for the given node type (1),
iterate through a loop (2--17) that scans all possible combinations of
resource assignments. The pending assignment currently evaluated is tested:
if there are no resources left to be tentatively assigned (3) it means that
the search has hit a ``blind alley''. There are two possibilities: if the
pending assignment that has exhausted its potential assignments is the first
one (4), then there are no untried combinations left, so clean up the last
assignment tried (5) and return with negative result (6); if there pending
assignment is not the first one, then backtrack to previous broker and
pending assignment (8). If there are valid resources in current pending
assignment, there are two possibilities: if the pending assignment is the
last one (10), then we have found a complete set of valid assignments for
the given node, so we clean up all the assignments (11) and report success
(12); if there are more pending assignments to evaluate, then apply a
tentative assignment for current pending assignment (14) and then advance to
the next broker and pending assignment (15).

Algorithm~\ref{alg:allocation-broker-director} is recursive, but unfolds
recursion into a two-state loop iteration. All state information is
efficiently stored in the \emph{PendingAssignment} objects of the
\emph{AssignmentPlan}. This algorithm, with minimal modifications, is a
suitable implementation for \emph{assign} method. The only difference is
that, once a complete combination of valid resource assignments is found,
the assignments are not cleaned up before returning success.

\begin{figure}[tb]
\centerline{\psfig{figure=eps/AssignTestSequence.eps,%
    clip,trim=0 320 0 20,scale=0.80}}
\caption{Example of sequence of messages that takes place when
  \emph{canAssign} method of a resource broker is called.}
  \label{fig:can-assign-sequence}
\end{figure}
%
Figure~\ref{fig:can-assign-sequence} shows a possible sequence diagram
involving \emph{BrokerDirector}, \emph{AssignmentPlan} and 3 instances of
\emph{PendingAssignment} (`p1', `p2', `p3'). The interaction between the
pending assignment instances and their brokers is not shown. The first time
a pending assignment is accessed, it is tested to see if, with the given
sequence of tentative assignments, there are available resources (steps
1--2, 7--8, 22--23). Because no set of potential assignments is yet
computed, the pending assignment must initialise itself with a set of all
possible assignments. This activity takes place in private method
\emph{computeAssignments}, which obtains the set of resources from the
broker by calling \emph{allAvailableResources}. When at least one resource
is available, the broker director applies a tentative assignment (steps
4--5, 13--14, 19--20) and then moves to next pending assignment with
\emph{advance}. When no possible resource is left for a tentative
assignment, the broker director backtracks (step 10) and return to previous
pending assignment. After backtracking, testing for available resources does
not trigger a call to \emph{computeAssignments}, because the resource set is
already computed (steps 11--12). On the contrary, when a pending assignment
is re-visited after the director backtracked from it,
\emph{computeAssignments} is called again, because this time the context
(the combination of tentative assignments from previous pending assignments)
is different, and the set of possible assignments can be different, too
(steps 16--18). Finally, when the last pending assignment is tested for
available resources, there is no need for tentative assignments, because
there is no other resource type to be tested for availability: it is obvious
that all resources in the set of possible assignments form, together with
the previous resource assignment, as many valid combinations of assignments
for the input node.

\subsection{AssignmentPlan and Allocation Efficiency}
\label{ssec:AssignmentPlan-imp}

In practice, the algorithm sketched in
Section~\ref{ssec:allocation-algorithm} is not deeply recursive. Assuming a
very simple assignment plan, consisting of the following sequence of
brokers: \emph{OutputFUBroker}, \emph{IUBroker},
\emph{OutputPSocketBroker}, \emph{InputFUBroker}, \emph{InputPSocketBroker},
\emph{BusBroker}, \emph{ITemplateBroker} no more than 5 of these 7 brokers are 
ever recursively visited, and usually just 3--4.

For example, if the node is a bypass (see definition in
Section~\ref{ssec:node-types}), the sequence of brokers invoked is
\emph{OutputFUBroker}, \emph{InputFUBroker}, \emph{BusBroker}, 
\emph{ITemplateBroker}. All other brokers are either not applicable 
(IU broker, for example) or superseded (input p-socket broker, 
for example, because the input FU broker assigns also the input p-socket).

\begin{figure}[tb]
\centerline{\psfig{figure=eps/BrokerDependencies.eps,scale=0.50}}
\caption{Dependencies between resource brokers in an assignment plan.}
  \label{fig:broker-dependencies}
\end{figure}
%
Figure~\ref{fig:broker-dependencies} shows the dependencies between the
brokers of the assignment plan (thin, directed arrows). The thick lines 
connect mutually exclusive brokers: whenever one
of the brokers is active for a given node, the other is not applicable. For
example, when the output FU broker is applicable (the source is an operation
output), it is obvious that the in-line immediate and the IU brokers are
useless.
%
Note that in-line and IU brokers are not mutually exclusive. To allocate a
constant, it may be necessary to try both. Trying only the IU broker would
be sufficient but inefficient, because we would lose any opportunities to
pack constants in (typically smaller) source fields.

\subsection{Brokers and Dependent or Related Resources}
\label{ssec:broker-dependent-resources}

Simple implementations can profit from the following restriction: If a
resource \emph{A} is the primary resource of a broker, then all other
brokers that manage a resource type that depends on \emph{A}'s resource type
do not assign it. They can test if \emph{A} can be assigned, but never
change the assignment state of it.

Certain scheduling resources may have no broker at all (that is, they are
not primary resources of any broker). These resources have to be allocated
and assigned by the broker of another resource type, a resource which
depends on the broker-less resource.
%
For example, the execution pipeline resource is a secondary resource
assigned by the \emph{FUInputsResource} whenever the requested port is
opcode-setting or triggering.

\subsection{Constraint Maps to Speed up Resource Allocation}
\label{ssec:broker-allocation}

A resource broker can speed up allocation when a resource related to its
primary resources is already assigned to the input node. This assignment is
an allocation constraint; it reduces the number of potential candidates for
resource assignment. However, testing the existence of the pre-assigned
resource in the set of related resources of each primary resource compatible
with the assignment is inefficient. The broker can set up associative
containers that map each instance of related resources (like the
pre-assigned resource) to a subset of the primary resources.

Sometimes the set of candidates for resource assignment can be constrained
by more than one pre-assigned resource. In this case, an associative
container mapping combinations of pre-assignments to (probably very
restricted) subsets of candidates is not an efficient solution.

\begin{figure}[tb]
  \small
  \begin{tabular}{ccc}
    \psfig{figure=eps/ResourceRelationConstrains.eps} &

    \begin{tabular}[b]{l}
      \textbf{Operation constraint map} \\
      OP1 $\rightarrow$ \{ FU1 \} \\
      OP2 $\rightarrow$ \{ FU2, FU3 \} \\
      OP3 $\rightarrow$ \{ FU2, FU3 \} \\
    \end{tabular} &

    \begin{tabular}[b]{l}
      \textbf{Bus constraint map} \\
      B1 $\rightarrow$ \{ FU1 \} \\
      B2 $\rightarrow$ \{ FU1, FU2, FU3 \} \\
      B3 $\rightarrow$ \{ FU1, FU3 \} \\
      B4 $\rightarrow$ \{ FU2, FU3 \} \\
    \end{tabular} \\
  \end{tabular}
  \caption{Associations between resources and related resources or other
    constraints (operations), and corresponding constraint maps.}
  \label{fig:allocation-speedup}
\end{figure}
%
When several constraints due to pre-assigned resources or node parts are
possible, a broker could set up a separate associative container for each
possible constraint, lookup a subset for each pre-assigned resource that
causes a constraint, and then compute the intersection of all subsets. With
the resource and constraint associations depicted in
Figure~\ref{fig:allocation-speedup}, for example, if the input node requires
operation `OP2' and the transport bus `B3' is pre-assigned to it, then the
operation constraint map and the bus constraint map, give, respectively,
subsets \mbox{\{FU2,FU3\}} and \mbox{\{FU1,FU3\}}. Their intersection gives
\{FU3\}: function unit `FU3' is the only valid assignment
possible.\footnote{
%
  Other constraints, such as the availability of the port and the socket,
  are not considered in this example for sake of simplicity.}

Computing the intersection of resource sets can be expensive. It can be
optimised by pairing each subset in the associative maps with a bit vector,
where each bit corresponds to one and one only primary resource. The
intersection subset can be re-created from the bit vector resulting from the
bitwise AND operations.

\subsection{BusBroker}
\label{ssec:BusBroker-imp}

The bus broker is an example of ``resource-resource'' broker (see
Section~\ref{ssec:ResourceBroker}): it does not depend on any property of
the unassigned node (described in Section~\ref{ssec:node-types}). This means
that, given a completely unassigned node, any bus is a valid candidate for
the assignment\footnote{Exception is guarded move, in such a case only buses
that supports given guard are candidates.}.

Bus assignment, as shown in Figure~\ref{fig:resource-graph}, is restricted
only by two types of resources: \emph{InputPSocket} and
\emph{OutputPSocket}. Typically, the bus broker will be invoked after input
and output p-socket of the given node have been (tentatively) assigned. To
efficiently find a candidate bus, the broker can implement two constraint
maps: one for the input p-sock, one for the output p-sock (see
Section~\ref{ssec:broker-allocation}).

Once a bus compatible with the given input and output socket is found, the
broker must check if it can be (re)used for the given node. The output and
input sockets define, respectively, the start and the end of a segment
chain. The broker must verify that all segments in the chain are
available.\footnote{
%
  The start segment could be reused as long as the end segment is different,
  but this is not even taken into account in the resource manager
  distributed with the toolset.}

Trying to assigning buses node by node, together with all other resources
needed by a node, may result in ineffective allocation, especially for
target architectures with highly constrained interconnection network.
%
When bus assignment fails, the resource manager could still find a valid
combination of bus assignments, if all nodes in the same cycle could be
considered at the same time. [[to do]]
%
\note{DISCUSS: possible extension --- sophisticated broker directors}

\subsection{InputFUBroker}
\label{ssec:InputFUBroker-imp}

The input FU broker is a complex ``action-resource'' broker (see
Section~\ref{ssec:ResourceBroker}). Assignment requests are defined by a
property (the operation) of a node part (the destination).
%
\begin{figure}[tb]
\centerline{\psfig{figure=eps/FUBrokerAllocation.eps,%
    clip,trim=0 160 0 40,scale=0.32}}
\caption{Allocation of a function unit to a node destination.}
  \label{fig:fu-broker-flowchart}
\end{figure}
%
Figure~\ref{fig:fu-broker-flowchart} depicts a simplified flowchart of the
activity that takes place to allocate a function unit to a node destination.

First of all, the broker must find a unit that supports the given operation.
This step can be efficiently implemented with an associative container
mapping operations to instances of \emph{FUInputsResource}.
%
The broker must then check if the compatible FU found is also available,
that is, can start the operation in the given cycle. The FU inputs resource
looks up the p-socket bound to given operation input. If the p-socket is in
use, then the FU cannot be assigned to the node destination, and another FU
must be tried.

If the p-socket is available and is not opcode-setting, then allocation ends
with success.

If the p-socket is opcode-setting, then the most complex part of the
allocation process takes place. The broker selects the dependent
\emph{PipelineResource} object, and asks \emph{canAssign} to it, with the
requested operation as input argument. The pipeline resource looks up the
resource utilisation profile for the given operation. Each operation
implementation in the FU has its resource utilisation profile.\footnote{
  %
  If several operations are implemented in the same pipeline and have
  identical usage profile, then they can share the same usage profile
  object. (This is just a memory optimisation.)}

The pipeline resource utilisation profile records, for a given operation,
which internal resources of the pipeline are used. The profile extends from
the cycle in which the operation starts (cycle 0) to next \emph{L-1} cycles,
where \emph{L} is the latency of the operation.
%
The \emph{PipelineResource} object checks whether the given profile requires
an internal pipeline resource that, in the cycle in which it is needed, is
already in use.

A typical implementation of utilisation profiles and pipeline resources
defines bit vectors for each cycle, where each bit corresponds to one
internal pipeline resource. Verification of pipeline conflicts is
implemented by means of a simple bitwise AND operation and a test against
zero.
%
\begin{figure}[tb]
\centerline{\psfig{figure=eps/FUResourceImplementation.eps,scale=0.80}}
\caption{Allocation of an operation pipeline of a function unit to a node
  destination.}
  \label{fig:fu-resource-imp}
\end{figure}
%
Figure~\ref{fig:fu-resource-imp} shows an example of this implementation.
The pipeline resource contains a map that associates operations to pipeline
utilisation profiles. Operation `OP1' and `OP3' share the same profile,
`profile1', for example. Operation `OP2' takes 4 cycles, so the utilisation
profile consists of 5 bit vectors. A `1' conventionally stands for a busy
resource. The first vector is for the cycle in which the operation is
started. For normally pipelined operations this bit vector is always zero,
but operation implementations where part (or all!) the computation takes
place in the start cycle will contains `1' bits. The pipeline resource
maintains the cycle-by-cycle utilisation state of all the pipeline resources
it contains by means of a sequence of bit vectors indexed by cycles of the
scheduling unit. In this example, the bit vectors corresponding to the code
region where the node is to be placed are shown. The bit vectors are
identical to those found in utilisation profiles. The `1' bits represent
resources already in use (assigned to other operations). In this case, the
requested operation can started in cycle 86, because the resources used
(shown as `x') are all available. Cycle 85, however, is not a valid start
cycle, because operation execution causes a resource conflict (shown as a
circled `x') in cycle 89.

An implementation similar to the one sketched above is suitable also for
assigning FU outputs, even if the output port sets and starts a new
operation (trigger on result).
%
If an opcode-setting FU port is bidirectional (trigger-on-result output
portand opcode-setting input port), then a nontrivial requirement arises.
The input and the output opcode-setting p-socket resources of, respectively,
the \emph{FUInputsResource} and \emph{FUOutputsResource} of the same
function unit model different directions of the same FU port, and must share
the same execution pipeline.

\subsection{Support for Triggering Operands}
\label{ssec:triggering-operands}

Whenever the move of an operation input is assigned to a triggering port,
the resource manager should test for pipeline conflicts with other
operations.

The usage profile applicable to a triggering input move that does not set
the opcode depends on the last operation scheduled on the same unit. Thus,
the previous operation code must be stored in the pipeline resource. It is
important to notice that this operation code is unrelated to the (pseudo)
operation code associated with the input move. The following schedule shows
this.
\begin{quote}
\begin{verbatim}
r.1 -> U.add.1 , r.2 -> U.add.2 ;
r.3 -> U.sub.2 , ... ;
r.4 -> U.sub.1 , ... ;
\end{verbatim}
\end{quote}
If the input `2' is mapped to a triggering port of unit `U' and input `1' is
mapped to the opcode-setting port, then the check for pipeline conflicts
necessary to schedule `\verb|r.3 -> sub.2|' must take into account the
resource usage of operation `add', not of `sub'.

If the previous operation scheduled on the same unit belongs to previous
basic blocks,
%
\note{not implemented in early versions}
%
there may be several different operations all potentially triggered again by
a triggering operand move. The resource manager should take into account a
\emph{union} of all the resource usage profiles, ignoring the apparent
conflicts.

In order to support triggering ports that do not set the operation code, the
resource model must be adjusted as follows:
\begin{enumerate}
\item %
  A pipeline resource keeps a record of the operation started in every cycle
  in which the opcode-setting port is written.
\item %
  When the FU resource is tested for availability with a triggering but not
  opcode-setting port as dependent resource, it delegates the lookup of the
  appropriate operation (and thus usage profile) to the pipeline resource.
  It simply asks \emph{canAssign} without the operation argument.
\end{enumerate}

(See also Section~\ref{ch:pending:triggering-operands} for related pending
issue.)

\subsection{Example: Resource Assignment}
\label{ssec:assignment-algorithm}

The following example demonstrates how the resource manager works
internally. An unassigned node reading a GPR and writing an operation input
is to be assigned suitable resources. In this example, it is assumed that
the first available resource of each type required by the node can be
assigned.

\begin{enumerate}
\item %
  The \emph{ResourceManager} receives an \emph{assign} request and forwards
  it to the \emph{BrokerDirector}.
\item %
  The \emph{BrokerDirector} records the node and the cycle of the request
  into its \emph{AssignmentPlan} by calling \emph{setRequest} method.
  Internally, the assignment plan may disable brokers that are not
  applicable to the given request, thereby optimising itself.
\item %
  The \emph{BrokerDirector} checks whether there is an available resource
  of the first required type. It calls \emph{AssignmentPlan}'s
  \emph{isTestedAssignmentPossible}.
\item %
  \emph{AssignmentPlan} forwards the request to the first
  \emph{PendingAssignment}. It calls \emph{isAssignmentPossible}.
\item %
  \emph{PendingAssignment} requests a list with all available resources for
  the given node, in given cycle to its broker. The broker, which manages FU
  inputs, receives the \emph{allAvailableResources} request.
\item %
  \emph{InputFUBroker} looks at the operation and the input index of the
  move held by the node.
\item %
  \emph{InputFUBroker} finds the subset of \emph{InputFUResource} instances
  that can support given operation. Not all of them, however, may be
  available.
\item %
  For each resource that supports the operation, \emph{InputFUBroker} tests
  whether it is available starting from given cycle. An
  \emph{InputFUResource} is available for a given request when the dependent
  \emph{PSocketResource} is available.
\item %
  \emph{InputFUBroker} looks up the dependent \emph{PSocketResource} of
  selected \emph{InputFUResource} using operation and input index as keys,
  and tests if it is available (\emph{isAvailable} method).
\item %
  If the port bound to operation's index is triggering, \emph{InputFUBroker}
  looks up the dependent \emph{PipelineResource} of the selected
  \emph{InputFUResource}.
\item %
  The broker asks \emph{canAssign} to the \emph{PipelineResource} with the
  requested operation as input argument. The pipeline resource is available,
  and returns true.
\item %
  The \emph{PendingAssignment} receives the list of candidate available
  resources from the broker. The list is not empty, so
  \emph{PendingAssignment} returns `true' to \emph{AssignmentPlan}, which in
  turn returns to \emph{BrokerDirector}.
\item %
  The \emph{BrokerDirector} sees that there are available assignments, so it
  tries one (\emph{tryNextAssignment}) on the \emph{AssignmentPlan}.
\item %
  \emph{AssignmentPlan} forwards \emph{tryNextAssignment} request to its
  first \emph{PendingAssignment}.
\item %
  \emph{PendingAssignment} picks the first available resource in the list of
  candidates found.
\item %
  \emph{PendingAssignment} performs a tentative assignment of the selected
  resource by passing it to the \emph{InputFUBroker} with an \emph{assign}
  request.
\item %
  \emph{InputFUBroker} sends the \emph{assign} request to the selected
  \emph{InputFUResource}.
\item %
  \emph{InputFUResource} marks the dependent resource busy. It sends an
  \emph{assign} request to \emph{PipelineResource} using the operation as
  input argument. After this, control returns from \emph{InputFUBroker} back
  to \emph{BrokerDirector}. (\emph{PipelineResource} pipeline) busy and
  assigns the corresponding processor component (function unit) to the
  destination terminals of the node's move.
\item %
  \emph{BrokerDirector} tells its \emph{AssignmentPlan} to \emph{advance} to
  next type of resource.
\item %
  \emph{AssignmentPlan} updates its current \emph{PendingAssignment} to the
  second one in the list.
\item %
  The \emph{BrokerDirector} checks if there are available resources of the
  required type. It calls second \emph{AssignmentPlan}'s
  \emph{isTestedAssignmentPossible}.
\item %
  \emph{AssignmentPlan} forwards the request (\emph{isAssignmentPossible})
  to the second \emph{PendingAssignment}.
\item %
  \emph{PendingAssignment} requests a list of all available resources for
  the given node to its broker. The broker, which manages input p-sockets,
  receives the \emph{allAvailableResources} request and the nodes.
\item %
  \emph{InputPSocketBroker} looks at operation, terminal index and function
  unit of the node's move.
\item %
  \emph{InputPSocketBroker} looks up the \emph{InputPSocketResource} that
  depends on given function unit and is bound to the given input of the
  operation. There is only one such p-socket resource.
\item %
  \emph{InputPSocketBroker} tests whether the p-socket is available.
\item %
  The \emph{PendingAssignment} receives the list of available resources from
  the broker, which contains one p-socket, and returns `true' to
  \emph{AssignmentPlan}, which in turn returns to \emph{BrokerDirector}.
\item %
  The \emph{BrokerDirector} sees that there are available assignments, so it
  tries one (\emph{tryNextAssignment}) on the \emph{AssignmentPlan}.
\item %
  \emph{AssignmentPlan} forwards \emph{tryNextAssignment} request to its
  second \emph{PendingAssignment}.
\item %
  \emph{PendingAssignment} picks the first (and only) available resource in
  the list of candidates.
\item %
  \emph{PendingAssignment} performs a tentative assignment of the selected
  resource by passing it to the \emph{InputPSocketBroker} with an
  \emph{assign} request.
\item %
  \emph{InputPSocketBroker} sends an \emph{assign} request to given resource
  and assigns the corresponding processor components (FU port, socket) to
  the destination of the node's move.
\item %
  Control returns to \emph{BrokerDirector}, which tells its
  \emph{AssignmentPlan} to \emph{advance} to next resource type.
\item %
  \emph{AssignmentPlan} updates its current \emph{PendingAssignment} to the
  third one in the list.
\item %
  The \emph{BrokerDirector} checks whether there are available resources of
  the required type. It calls third \emph{AssignmentPlan}'s
  \emph{isTestedAssignmentPossible}.
\item %
  \emph{AssignmentPlan} forwards the request to its third
  \emph{PendingAssignment}. It calls \emph{isAssignmentPossible}.
\item %
  \emph{PendingAssignment} requests a list with all available resources for
  the given node to its broker. The broker, which manages output p-sockets,
  receives the \emph{allAvailableResources} request and the node.
\item %
  \emph{OutputPSocketBroker} looks at the unit (register file) assigned to
  the node's move (by a register allocator).
\item %
  \emph{OutputPSocketBroker} looks for \emph{OutputPSocketResource}
  instances of output ports that read from the register file.
\item %
  For each applicable resource, \emph{OutputPSocketBroker} tests whether it
  is available. An \emph{OutputPSocketResource} is available for a given
  request when is is unused or it can be shared.
\item %
  The \emph{PendingAssignment} receives the list of candidate available
  resources from the broker, it sees it is not empty, and returns `true' to
  \emph{AssignmentPlan}, which in turn returns to \emph{BrokerDirector}.
\item %
  The \emph{BrokerDirector} sees that there are available assignments, so it
  tries one (\emph{tryNextAssignment}) on the \emph{AssignmentPlan}.
\item %
  \emph{AssignmentPlan} forwards \emph{tryNextAssignment} request to its
  third \emph{PendingAssignment}.
\item %
  \emph{PendingAssignment} picks the first available resource in the list of
  candidates found.
\item %
  \emph{PendingAssignment} tentatively assigns the selected resource by
  passing it to the \emph{OutputPSocketBroker}, with an \emph{assign}
  request.
\item %
  \emph{OutputPSocketBroker} sends an \emph{assign} request to given
  resource and assigns the corresponding processor components (RF port,
  socket) to the destination of the node's move.
\item %
  Control returns to \emph{BrokerDirector}, which tells its
  \emph{AssignmentPlan} to \emph{advance} to next resource type.
\item %
  \emph{AssignmentPlan} updates its current \emph{PendingAssignment} to the
  fourth (and last) one in the list.
\item %
  The \emph{BrokerDirector} checks whether there are available resources of
  the required type. It calls fourth \emph{AssignmentPlan}'s
  \emph{isTestedAssignmentPossible}.
\item %
  \emph{AssignmentPlan} forwards the request (\emph{isAssignmentPossible})
  to the first \emph{PendingAssignment}.
\item %
  \emph{PendingAssignment} requests a list of all available resources for
  the given node to its broker. The broker, which manages transport busses,
  receives the \emph{allAvailableResources} request and the node.
\item %
  \emph{BusBroker} retrieves the input and output sockets assigned to node's
  move.
\item %
  \emph{BusBroker} finds all the \emph{BusResource} instances that are
  connected to both sockets.
\item %
  For each applicable bus, \emph{BusBroker} tests whether it can be assigned
  to the node. A \emph{BusResource} can be assigned when the segments that
  connect the output socket to the input socket are all available.
\item %
  The \emph{PendingAssignment} receives the list of candidate available
  resources from the broker, it sees it is not empty, and returns `true' to
  \emph{AssignmentPlan}, which in turn returns to \emph{BrokerDirector}.
\item %
  The \emph{BrokerDirector} sees that there are available assignments, so it
  tries one (\emph{tryNextAssignment}) on the \emph{AssignmentPlan}.
\item %
  \emph{AssignmentPlan} forwards \emph{tryNextAssignment} request to its
  forth \emph{PendingAssignment}.
\item %
  \emph{PendingAssignment} picks the first available resource in the list of
  candidates found.
\item %
  \emph{PendingAssignment} tentatively assigns the \emph{BusResource} by
  passing it to the \emph{BusBroker} with an \emph{assign} request.
\item %
  \emph{BusBroker} sends an \emph{assign} request to the given resource and
  assigns the corresponding processor component (transport bus) to the
  node's move.
\item %
  Control returns to \emph{BrokerDirector}. There are no more pending
  assignments in the \emph{AssignmentPlan}, so the tentative resource
  assignments form a complete and valid combination of assignments for the
  input node. End.
\end{enumerate}

\subsection{Resource Construction}

The most challenging aspect of resource construction is setting up resource
links. The difficulties come from demanding requirements of each party
involved:
\begin{enumerate}
\item\label{itm:generic-director}%
  The build director holds every broker, but does not know anything about
  associations between resources (which are resource-specific). A build
  director must work with any resource broker.
\item\label{itm:local-broker-maps}%
  Single brokers hold information to map their primary resources to machine
  parts and vice versa, but do not know about how to map related resources.
\item\label{itm:multi-brokers}%
  Different brokers may map non-overlapping subsets of resources of the same
  type to machine parts.
\item\label{itm:no-broker-sharing}%
  Conversely, a broker can only map resources that correspond to machine
  parts of the same type. This means that even if two different types of
  machine parts can be modelled and allocated by the same entity, each
  requires a separate resource broker.
\item\label{itm:no-link-resource}%
  During construction of a resource, the resource objects corresponding to
  related or dependent resources may not even exist yet (one of the broker
  must start first!).
\end{enumerate}

Item (\ref{itm:generic-director}) implies that the build director must
delegate the search for a mapping between resources and machine parts to
brokers.
%
At the same time, item (\ref{itm:local-broker-maps}) implies that brokers
cannot directly solve the references to related or dependent resources: they
must delegate the director.
%
Item (\ref{itm:multi-brokers}) means that a one-to-one association between
the concrete type of machine part and the broker that handles it is not
possible: the resource mapper must scan all its brokers until it finds a
mapping.
%
Item (\ref{itm:no-link-resource}) implies that the broker cannot delegate
director immediately to find the related or dependent resources. A possible
solution is to split construction in two phases, as described in
Section~\ref{ssec:resource-construction}.

\begin{figure}[tb]
\centerline{\psfig{figure=eps/ResourceBuildPhase1.eps,%
    clip,trim=0 480 0 30,scale=0.70}}
\caption{First phase of resource construction.}
  \label{fig:resource-build1}
\end{figure}
%
Figure~\ref{fig:resource-build1} depicts a possible sequence of operations
that take place during the first phase of resource construction. For
simplicity, only the messages starting from the first two brokers are shown,
but the resource build director forwards the build request to each broker
(\emph{buildResources} message). Each broker --- in this example,
\emph{BusResource} and \emph{FUInputsResource} ---, in turn, constructs
resources of its type.

\begin{figure}[tb]
\centerline{\psfig{figure=eps/ResourceBuildPhase2.eps,%
    clip,trim=0 525 0 30,scale=0.75}}
\caption{Second phase of resource construction.}
  \label{fig:resource-build2}
\end{figure}
%
Figure~\ref{fig:resource-build2} depicts a possible sequence of operations
that take place during the second phase of resource construction. The build
director sends a \emph{setupResourceLinks} request to each broker with the
resource mapper (see Section~\ref{ssec:ResourceMapper-imp}) as input
argument.

For each resource that has at least one related or dependent resource, the
broker looks up the dependent resource (which always corresponds to a
machine part) by sending a \emph{resourceOf} request to the mapper. The
mapper, in turn, looks for the broker that knows about this association.
This is achieved by requesting each broker \emph{hasResourceOf} with the
given machine part as argument. Once found, the broker that maps the machine
part is requested find the mapping.

When the related resource is also a primary resource of the same broker, it
is then not necessary to forward the request to the resource mapper. Though
perfectly correct, this is inefficient: the mapping can be found within the
broker itself.

\subsection{ResourceMapper}
\label{ssec:ResourceMapper-imp}

Since each broker has all that it takes to map the set (or a subset) of
concrete machine parts to resource objects, the simplest implementation of
the resource mapper is a \emph{Faade}~\cite{DesignPatterns} that groups
together the brokers managed by the resource build director and dispatches
every mapping request to each broker, stopping when one of them returns the
resource.

When resource brokers perform link setup, the resource map is invoked a
large number of times. Resource mapping by simple delegation to brokers
could have serious efficiency problems. If the simple \emph{ResourceMapper}
faade described above is too slow, a practical solution is to implement a
caching system. Every resource broker does not send its mapping requests
directly to the shared mapper, but through a local caching adaptor. The
caching layer can be implemented so that is is generic, because its
interface can work with \emph{MachinePart} and \emph{SchedulingResource}
types, it does not need specific types.

If effective and general enough, caching of resource mapping for broker
method \emph{setupResourceLinks} could be built into the base
\emph{ResourceBroker} and called automatically (this requires a
\emph{Template Method} design for \emph{setupResourceLinks}).

\section{Error Handling}

\subsection{Invalid Pre-Assignment Request}

Class \emph{PreAssignment} throws exception \emph{InvalidOperation} if the
resource that the client requests to pre-assign is applicable to the node.
For example, a function unit output port cannot be applied to an in-line
immediate node.

\subsection{Invalid Assignment Request}
\label{ssec:invalid-ext-assignment}

The resource manager throws exception \emph{InvalidOperation} if it cannot
update the state of the controlled resource model with one of the assignment
specified by a node because the assigned resource is in use and cannot be
reused. Clients can avoid this error condition by testing the validity of an
external assignment before forcing the manager to update its state with it.

\subsection{Invalid Resource State}
\label{ssec:invalid-resource-state}

A resource appears free to the resource manager in a given cycle, but it is
assigned to the input node of a request. This situation occurs when a client
forced a resource assignment and forgot to ask the resource manager to
update its state.

If a pre-assigned resource appears free or assigned to another node
(for example, because the client forgot to notify the assignment to the
resource manager), the resource manager throws an \emph{InvalidAssignment}
exception with the (first) illegally assigned resource.

\subsection{Unavailable Resources}

If the resource manager is not able to find a complete set of resources to
assign a given a node in a given cycle, it throws an
\emph{ImpossibleResourceAssignment} exception. Even in this case, the
manager assigns as many resources as possible to the node.
%
\note{EXTENSION: failure-tolerant assignment}
%
Thus, a client catching the exception can determine which resources where
not available by testing unassigned parts of the node.

To avoid exceptions, clients must test for the availability of resources
before requesting assignment.

\subsection{No Possible Assignments}
\label{ssec:no-possible-assignments}

Internal error condition occurring inside broker director (or resource
manager) when a \emph{PendingAssignment} object is requested to try next
assignment, but the set of possible assignments is either empty or
completely evaluated.

\subsection{Trying to Unassign Unassigned Resource}
\label{ssec:impossible-unassign}

Internal error condition occurring inside broker director (or resource
manager) when a \emph{PendingAssignment} object is requested to unassign the
currently evaluated resource, but no resource of in the set of possible
assignments is currently assigned to the node.

\subsection{Unresolved Reference in Resource Handle}
\label{ssec:unresolved-resource}

Unresolved references in resource handles may seem like an internal logical
error of the resource manager, rather than an error condition to be
signalled by means of an exception.
%
However, the user is free to specify any sequence of resource brokers, so it
may specify a sequence which does not construct a required type of resource,
thereby leaving any reference to those resource objects unresolved. The
\emph{UnresolvedReference} should probably be caught by a client-level part
of the Scheduler and reported as erroneous or incomplete broker set.

\subsection{Resource Model not Ready}

The resource broker cannot accept any request related its resources until it
enters the ready state. No client should ever see a broker during
construction, since it's all hidden inside the resource manager.
%
\note{DISCUSS: if we want a fault-tolerant Scheduler that skips passes with
  any type of internal failure, then even these conditions should be treated
  with exceptions (at a higher level)}
%
The error condition resulting from an illegal request can be safely treated
as internal error of the resource manager module, which aborts the entire
program.



\chapter{Early Register Allocator}
\label{ch:EarlyRegisterAllocator}

Registers are by far the most complex resource to manage. Registers are
assigned to program variables (represented by ``virtual registers'' of the
program representation).
%
A simple register assignment algorithm is implemented as a
separate pass. Register assignment is thus separated from
the other resource assignments and from instruction scheduling proper
(see~\cite{Norris94} for possible algorithm).
%
\note{initial implementation: no support for bridges}

Register assignment takes place before scheduling. The resource manager core
module provided with the toolset has no register assignment capability and
simply does not expect unassigned program variables, but only GPR's of the
target architecture.

\section{Overview}
\section{Interfaces}
\section{Implementation}



\chapter{Scheduling Algorithm}

The Scheduling Algorithm is the main module of the scheduling framework that
is responsible for instruction scheduling proper. Its task is to just
schedule (assign cycles and processor resources to) TTA moves.

\section{Overview}

\subsection{Scheduling and Relative Addressing Modes}

The address of forward and backward jumps from sequential code is of no use.
Since the operations are packed to TTA instructions, the relative distance
between jump operation and target and also the absolute location of target
change from its original value in sequential code. In case of backwards
jumps it is easy to determine the correct value since the code is already
scheduled.

In case of forward jumps, situation is more complicated. The address (offset
or absolute) of jump depends on position of code not yet scheduled. That, in
turn, depends on instruction schedule between present operation and target
of jump.
%
To solve this, support for page relative (or PC relative) jumps requires
iterative approach to code generation and layout.

The scheduler will use only ``virtual'' addresses (equivalent to symbolic
labels) through scheduling.  After the whole scheduling is done, there will
be a pass that recomputes the addresses of absolute and relative jumps and
corrects the address values in the code. When the addresses do not fit into
available bits allocated for storing them (the schedule turns out to be too
compact, so to say), a complete reschedule is necessary.

\subsection{Pipeline-Related Scheduling Constraints}

The nodes that read or write FU ports must satisfy a number of special
scheduling constraints which depend on the FU pipeline resources (see
Section~\ref{ssec:InputFUBroker-imp}). Nevertheless, some of these
constraints should not be implemented by the resource manager, because:
\begin{enumerate}
\item %
  The information required to model the constraint, logically speaking, is
  not pertaining the resource, but the program semantics (dependencies).
\item %
  The constraint may or may not apply depending on the capabilities
  (aggressiveness, sophistication) of the scheduling algorithm.
\item %
  It is difficult or inefficient to model the constraint as a resource
  property (or a new resource object).
\end{enumerate}

The following special scheduling constraints apply to nodes that read or
write FU ports:
\begin{enumerate}
\item\label{itm:one-start}%
  No more than one operation per cycle can be initiated.
\item\label{itm:operands-ready}%
  An operation cannot start until its operands have all been written.
\item\label{itm:latency}%
  An  operation result cannot be read until one cycle after the pipeline has
  completed it written it to the output port.
\item\label{itm:write-concurrent}%
  Two operations cannot start if they will end up writing the output port in
  the same cycle(s).
\item\label{itm:write-before}%
  The result of an operation must be read before the result port is
  overwritten by next operation that writes it. More formally: if the result
  of an operation \emph{O} is live, then the node that reads it must be
  scheduled in a cycle \emph{c} such that $c' < c \leq c''$ where $c'$ is
  the cycle in which \emph{O} finishes writing the result, and $c''$ is the
  first cycle of the next operation that writes the same result port.
\item\label{itm:write-after}%
  The result of an operation must be written after the result of the
  previous operation, if live, has been read for the last time. More
  formally: if the result written by previous operation is read in cycle
  $c'$, then operation \emph{O} must begin to write the same result port in
  a cycle \emph{c} such that $c \ge c'$.
\end{enumerate}

Constraint (\ref{itm:one-start}) is trivially modelled by the resource that
represents the opcode-setting port (a p-socket, really).
%
Constraint (\ref{itm:operands-ready}) is best modelled by means of a
dependency of special type, an intra-operation dependency between the node
that writes the opcode-setting (and operation-starting) input and the nodes
that write the other inputs.
%
Constraint (\ref{itm:latency}) is another example of constraint modelled by
the scheduling algorithm by means of an intra-operation dependency. In this
case, however, the dependency carries a distance. Until the operation of the
nodes is assigned, the distance is undefined because it depends on the
function unit assigned. Once a FU is assigned to the nodes of an operation,
the scheduling algorithm must update the dependency between the
opcode-setting node and the nodes that read the results of the operation.
%
Constraint (\ref{itm:write-concurrent}) is an example of constraint that can
be modelled well by a resource object. The pipeline resource model just
needs to record write activity on the output port as a pipeline resource
usage.
%
\begin{figure}[tb]
  \centering
  \begin{tabular*}{.50\textwidth}{@{\extracolsep{\fill}}cc}
    \psfig{figure=eps/ReadNodeBeforeNextWrite.eps,scale=0.75} &
    \psfig{figure=eps/WriteNodeAfterPreviousRead.eps,scale=0.75} \\
   (a) & (b) \\
  \end{tabular*}
  \caption{Scheduling constraints due to pipeline conflicts: result move (a)
    and whole operation (b).}
  \label{fig:order-constraint}
\end{figure}
%
Constraints (\ref{itm:write-before}) and (\ref{itm:write-after}) ensure that
operations don't overwrite operation results that have not been read yet.
%
Figure~\ref{fig:order-constraint}(a) shows an example of the range of cycles
(6--9) in which the result node of an operation `OP2' can be scheduled
according to constraint (\ref{itm:write-before}) before the result of `OP1'
overwrites the result. (Whether `OP1' starts before or after `OP2' is
irrelevant.)
%
Figure~\ref{fig:order-constraint}(b) shows an example of the range of cycles
($\geq 6$) in which an operation can write the output port with its result
according to constraint (\ref{itm:write-after}). Both constraint arise from
the same condition, just seen from a different perspective (scheduling the
result node of an operation whose start cycle is already decided or
scheduling the start cycle of an operation).

These constraints are very awkward to model in resource manager, because
they depend on the schedule of different operations and the semantics of the
program (whether a result is used or is discarded).

\subsection{Constraints on Jump Delay Slots}

Operations that perform control transfers, in general, are followed by
several delay cycles (or delay slots).

Altough there is no restriction on the instructions that can appear in a
delay slot, practical implementations of the scheduling algorithm will not
handle other control transfer operations. See Section~\ref{ssec:delay-slots}
for details on how the default implementation of the scheduler framework
models this restriction in a general way.

\section{Interfaces}
\section{Implementation}



\chapter{Selector}

The Selector is the module responsible for returning nodes of the program
representation to the Scheduling Algorithm. The nodes returned are valid
candidates for scheduling, which means that, given the current state of the
scheduling process at the time the Selector was requested a candidate, they
can be scheduled.

\section{Overview}
\label{ssec:scope-overview}

\emph{NodeSelector} is the main class of the selector module. It defines a
basic interface that is expected to be implemented by selectors that work
within the scheduling framework.

The selector does not have memory of past requests. For any given request,
the result returned by the selector depends exclusively on the current state
of the program representation.

As a result, clients must modify something in the program representation
(scheduling, assigning, adding or removing nodes) before repeating exactly
the same selection request, otherwise the same result will be returned and
potentially infinite loops could occur in the code.
%
\note{DISCUSS: extension infinite loop prevention}

\subsection{Scope Mode}

The selector can work in two possible modes: inter-scope and intra-scope.
%
Inter-scope mode means that the scheduling algorithm can be totally unaware
of the scope division within the scheduling unit. The selector automatically
selects the next unscheduled scope when the nodes in current scope are
completely scheduled.
%
In intra-scope mode, the scheduling algorithm must take action and provide a
new scope to the selector once the nodes in current scope are all scheduled,
or exit the scheduling process (possibly, with the program only partially
scheduled).

When the selector replies with an empty group to a request for next
candidate, two conditions are possible:
\begin{enumerate}
\item %
  If the selector is in inter-scope mode, it means scheduling process
  (limited to the scheduling unit) is complete.
\item %
  If the selector is in intra-scope mode, it means that scheduling of the
  scope is completed.
\end{enumerate}

\section{Interfaces}
\label{sec:Selector-if}

The basic operation that must be implemented by any framework-complying
selector just returns the next group of nodes that are candidate for
scheduling:
\begin{description}
\item[getCandidates() : MoveNodeGroup]%
  Return a group of nodes which are suitable candidates for the next
  scheduling step. If invoked repeatedly on an unchanged scope, this
  operation keeps returning the same result.

  Return an empty group if the scope (or the entire scheduling unit) is
  completely scheduled.
\end{description}

The \emph{MoveNodeSelector} class provides also an interface for setting up the
selection process.
%
\begin{description}
\item[setInterScopeMode()]%
  Switch the selector to inter-scope mode. Nothing happens if the selector
  is already in inter-scope mode.

  Throw exception \emph{WrongObject}
%
  \note{WrongObject or specialised MissingCapability?}
%
  if the selector implementation cannot work in inter-scope mode.

\item[setIntraScopeMode()]%
  Switch the selector to intra-scope mode. Nothing happens if the selector
  is already in intra-scope mode.

  Throw exception \emph{WrongObject}
%
  \note{WrongObject or specialised MissingCapability?}
%
  if the selector implementation cannot work in intra-scope mode.

\item[registerScope(scope : Scope)]%
  Register a new scope into selector. The selector must currently have no
  scope under processing, or the scope must be completely scheduled.

  Throw exception \emph{ObjectAlreadyExists} if the selector is currently
  working on a scope.

\item[forgetScope()]%
  Forget current scope (even if only partially scheduled).
\end{description}

The \emph{MoveNodeSelector} class provides an interface for querying its
capabilities. This makes it possible for a client (a scheduling algorithm)
to adjust its working (if possible) to the selector.
\begin{description}
\item[canComputeCandidateList() : bool]%
  Return true if this selector can compute complete a prioritized list of
  candidates.
\item[canDoInterScopeMode() : bool]%
  Return true if this selector can automatically obtain the next scope when
  all nodes in current scope are scheduled (inter-scope mode).
\item[canDoIntraScopeMode() : bool]%
  Return true if this selector can work on a single scope and stop when all
  nodes in the current scope are scheduled (intra-scope mode).
\item[interScopeMode() : bool]%
  Return true if this selector automatically obtains the next scope when all
  nodes in current scope are scheduled.
\item[canComputeEarliestCycle() : bool]%
  Return true if this selector implementation will compute the earliest
  cycle of the leader node of each node group.
\item[canComputeLatestCycle() : bool]%
  Return true if this selector implementation will compute the latest cycle
  of the leader node of each node group.
\end{description}

In order to provide finer control of the selection process,
%
\note{PENDING: \ref{ch:pending:candidate-lists}}
%
the \emph{MoveNodeSelector} class provides the following interface:
\begin{description}
\item[getCandidateList(limit : const int) : NodeGroupList]%
  Compute and return an ordered list of candidates. Optionally, it is
  possible to specify an upper limit to the number of groups of candidates
  wanted. Calling this method with limit 1 is equivalent to invoking
  \emph{getCandidates}. The number of candidate groups in the list does not
  have to be the entire set of valid candidates. A selector implementation
  is free to limit the maximum number of groups considered.
\end{description}

\section{Implementation}



\chapter{Scheduler Front-End}

This chapter describes the fixed top-level component of the Scheduler.

\section{Overview}

The scheduler front-end is the top-level component of the Scheduler. The
clients of the Scheduler (such as user interfaces and controller modules
like the Explorer) use the front-end to setup and launch the scheduling
process.

The front-end loads and sets up the domain object models that
represent the target processor and the target TTA application (or
program). If required, the front-end also constructs the
scheduler-specific program representation
(Chapter~\ref{ch:ProgramRepresentation}). Which object models are
constructed depends on the command line options given to Scheduler and
on the passes listed in the configuration file. Only the object model
of the source program will always be constructed, the others are
optional.

The front-end is also responsible for loading and preparing the specified
modules and setting up the code transformation and scheduling chain taking
into account the command line options and the module-specific options.
Afterwards, the scheduling process may be started. An empty scheduling chain
is valid. If no configuration file is given, then the Scheduler simply
writes out an unchanged copy of the input program.

The actual setup of the scheduling chain is delegated to a specialised
helper class: \emph{SchedulingPlan}. This class takes a pre-parsed
object-tree representation of the configuration file and builds an ordered
list of pass modules from it. To build this list, it loads the modules from
dynamically linkable object files using the plug-in loader class (See
Section~\ref{ssec:plugin-loader}).

By normal operation, the scheduler front-end passes a reference to the
target program to each module. Each module is free to do anything with the
given program model. The scheduler is responsible for making a backup of the
original program before starting any module, should it be needed.

\subsection{Front-end Logging}

In addition to enabling logging in pass modules (see
Section~\ref{ssec:logging-imp}, the front-end is responsible for automatic
logging of fixed messages:
\begin{enumerate}
\item %
  Begin of a pass.
\item %
  End of a pass.
\item %
  Termination of a pass with error (exception).
\end{enumerate}

\subsection{Plug-in Loading}
\label{ssec:plugin-loader}

The scheduler front end uses a general facility provided by the Scheduler: a
portability layer for loading plug-in pass modules at run time. This layer
is implemented by class \emph{SchedulerPluginLoader} and is generally useful
for any pass module that need to load (helper) modules at run time.

Since the font end is the main client of the plug-in layer, the description
of \emph{SchedulerPluginLoader} interface is given in this chapter.

\section{Interfaces}

\subsection{SchedulerFrontend}
\label{ssec:SchedulerFrontend-if}

The scheduler front-end provides the following interface:

\begin{description}
\item[SchedulerFrontend()]
  Constructor. Create an empty, uninitialised front-end.

\item[schedule(options : SchedulerCmdLineOptions\&)]
  Schedule the scheduling chain according to the given options.

  Throw \emph{IOException} if an error occurs opening the source
  program, the target ADF or the configuration file.

  Throw \emph{IllegalSchedulingChain} if the configuration file
  contains errors (See Section~\ref{ssec:SchedulerFrontend-err}).

  Throw \emph{DynamicLibraryException} if an error occurs loading
  scheduler pass modules.

  Throw \emph{ModuleRunTimeError} If an run-time error occurs in scheduler
  module.

\item[schedule(source : const TTAProgram::Program\&,
  target : const TTAMachine::Machine\&,
  schedulingPlan : const SchedulingPlan\&)]
  Schedule the given sequential program against the given target
  machine.

  Throw \emph{IOException} If module needs target machine but it is not
  defined.

  Throw \emph{ModuleRunTimeError} If an run-time error occurs in scheduler
  module.

\end{description}

This is the minimum interface for the front-end to be usable. More
convenience methods for loading the input data files and setting
scheduler options will be added later.

\subsection{SchedulerCmdLineOptions}
\label{ssec:SchedulerCmdLineOptions-if}

\emph{SchedulerCmdLineOptions} class stores the command line arguments and
options given to the scheduler. These options are global and apply to the
scheduler front-end. Some do not affect modules, others affect all modules
in the same way.

\begin{description}

\item[sourceProgram() : string]
  Return the name of the source TPEF file.

\item[isTargetADFDefined() : bool]
  Return true if the target ADF was defined in the command line.

\item[targetADF() : string]
  Return the name of the target ADF file.

  Throw exception \emph{NotAvailable} if the target ADF was not defined.

\item[isConfigurationFileDefined() : bool]
  Return true if the configuration file was defined in the command line.

\item[configurationFile() : string]
  Return the name of the configuration file.

  Throw exception \emph{NotAvailable} if the configuration file was not
  defined.

\item[isOutputFileDefined() : bool]
  Return true if the output file was defined in the command line.

\item[outputFile() : string]
  Return the name of the output file.

  Throw \emph{NotAvailable} if the output file was not defined.

\item[verbosity() : int]
  Return the level of verbosity. Default is '0'.

\item[timeout() : int]
  Return the global time limit for the scheduling process. Default is
  '0' and means ``no limit''.

\item[showWarnings() : bool]
  Return true if the modules should display all warning
  messages. Default is ``false''.

\item[debugMode() : bool]
  Return true if the front-end should write out a copy of the program
  (in TPEF) after each pass in the code transformation and scheduling chain.
  \note {a better method name?}

\item[interactivityLevel() : int]
  Return the level of interactivity. Default is `0' which means ``no
  interactivity''.

\item[interactiveMode() : bool]
  Return true if the scheduler is in interactive mode. This method is a
  shortcut for test interactivity level equal to zero.

\end{description}

[[TODO: procedure selection]]

\subsection{SchedulerPluginLoader}
\label{ssec:SchedulerPluginLoader-if}

\emph{SchedulerPluginLoader} is a simple one-purpose class that hides the
complexity of loading and managing allocation of pass modules at run time.
%
Every pass module loaded is recorded and owned by the plug-in layer class,
which is responsible for its destruction. Singleton class.

\begin{description}
\item[instance() : static SchedulerPluginLoader\&]%
  Returns an instance of SchedulerPluginLoader class (singleton).

\item[loadModule(modName : const string\&, fileName : const string\&) :
  BaseSchedulerModule\&]%
  Load the scheduler pass module identified by name string \emph{modName}
  from file \emph{fileName} and return a reference to it.

  Throw \emph{DynamicLibraryException} if an error occurs loading the
  requested plugin.

\item[$\sim$SchedulerPluginLoader()]%
  Destructor. Manage deallocation of all loaded plug-in modules.
\end{description}

\subsection{SchedulingPlan}
\label{ssec:SchedulingPlan-if}

\emph{SchedulingPlan} constructs the scheduling chain
from an object tree representation of the scheduler configuration
file, pre-parsed by a \emph{SchedulerConfigurationSerializer}
object. It uses \emph{SchedulerPluginLoader} to load the modules from
dynamically linkable object files.

\begin{description}

\item[SchedulingPlan()]
  Constructs an empty scheduling plan.

\item[build(conf : ObjectState\&)]
  Constructs the scheduling chain from the given configuration.

  Throw \emph{ObjectStateLoadingException} if the configuration is
  invalid.

  Throw \emph{DynamicLibraryException} if an error occurs loading a
  pass module.

\item[passCount() : int]
  Return the number of passes in the scheduling chain.

\item[pass(index : int) : StartableSchedulerModule\&]
  Return the pass in the given index.

  Throw \emph{OutOfRange} if the index is negative, or equal to or
  greater than the number of passes in the scheduling chain.

\item[helperCount() : int]
  Return the number of helpers registered in the given main module.

\item[helper(index : int) : HelperSchedulerModule\&]
  Return the helper module of the given pass in the given index.

  Throw \emph{OutOfRange} if one index is negative or exceeds the
  number of passes/helpers - 1.

\item[loadFromFile(configurationFile : const std::string\&) :
  SchedulingPlan*]
  Loads a SchedulingPlan from the given configuration file.

  Throw \emph{Exception} in case some error occured. All exceptions
  are generated by SchedulerConfigurationSerializer.
\end{description}

\subsection{SchedulerConfigurationSerializer}

The scheduler front-end uses a \emph{SchedulerConfigurationSerializer}
instance to create the object tree representation of the configuration
file. It is a specialisation of the \emph{XMLSerializer} class of the
TCE toolkit (see \cite{ToolkitDesign} for details). It reimplements the
following method:

\begin{description}

\item[readState() : ObjectState*]
  Read the options from the XML file and create an object tree
  representation of it.

  Throw \emph{SerializerException} if an error occurs reading the
  file.

\item[readConfiguration() : SchedulinPlan*]
  Reads the current configuration file set and creates a
  SchedulingPlan according to it.

  Throw \emph{SerializerException} if an error occurs reading the
  configuration file.

  Throw \emph{ObjectStateLoadingException} if an error occurs while
  creating the SchedulingPlan.
\end{description}

\section{Implementation}

\subsection{Setup of Logging System}
\label{ssec:logging-imp}

When logging is enabled, the scheduler front-end is responsible for setting
up the server side of the logging system (see Chapter~\ref{ch:tracking} for
details on the client side).

First of all, it creates a logger server \emph{TextLogger}. Then, registers
the server to each module, including helper modules of the same multi-module
pass.

\emph{Example. Creation and setup of logger.} The following code shows how
the scheduler front-end should setup the logger server and register it into
each module.

\begin{verbatim}
  // generate logFileName if not defined by command line option
  TextLogger logger(logFileName);
  . . .
  // for each pass module 'm':
  m.setLogger(logger);
\end{verbatim}

\section{Error Handling}

\subsection{Scheduler Frontend}
\label{ssec:SchedulerFrontend-err}

\paragraph{Invalid Command Line}

The front end is given a command line that cannot be parsed correctly, the
it throws exception \emph{IllegalCommandLine}.

\paragraph{Failure Inside a Scheduling Pass}

When a scheduling pass fails and throws an exception, the front-end must
catch the exception, report any context data (at least the pass in which
error occurred) and then re-throw a \emph{ModuleRunTimeError} exception.

\paragraph{Multiple Startable Modules in One Pass}

In each pass, only one module (the main module of the pass) can be
startable. Throw \emph{IllegalSchedulingChain} if two or more modules of a
single pass are startable.

\paragraph{Pass without Startable Module}

In each pass, only one module (the main module of the pass) can be
startable. Throw \emph{IllegalSchedulingChain} if a pass does not include
any startable module.


\chapter{Generic Passes}

The scheduling process is implemented as a sequence of passes that analyse
and modify the target program. This chapter describes the common features
and the base interface of all passes.

{\bf Note:} There is a more fine grained interface for passing data
into and between scheduler passes, but this interface is not described
here. Please read the MSc thesis by Ari Mets\"ahalme, or look up the
\emph{SchedulerPass} class. If you plan to write a scheduler pass, you
should definitely do it instead of relying on the information here.

\section{Overview}

Usually, passes of the code transformation and scheduling chain perform some
analysis of the target program (either in its Program Object Model form or
in its Program Representation form) and modify it. All the passes conform to
a generic module interface.

Pass modules that accept parameters (options and arguments equivalent to the
command line options) are responsible for parsing and handling their
options. Client just have to provide the strings that define the parameters.

A pass module usually modifies the program object model (or program
representation) given to it. Changes to the program can occur in-place if
wanted. It is responsibility of the client to keep a copy of the original
program model if needed.

\subsection{Errors at Run Time}

All pass modules should signal errors that occur during execution by means
of \emph{ModuleRunTimeError}. See Section~\ref{ch:maintain:add-pass} for
suggestions on how to implement this.

\section{Interfaces}

Each module provides an external handle consisting of a main class that is a
specialisation of the \emph{BaseSchedulerModule} interface. It defines the
minimal set of services that are provided by all modules.

A module must also provide a factory function and a destructor function.
(These functions are defined automatically, see
Section~\ref{ssec:automatic-export}.) These are the only functions with
accessible symbol name, and the only functions that are linked directly by
the client (the scheduler front-end).

\subsection{BaseSchedulerModule}
\label{ssec:BaseSchedulerModule-if}

\begin{description}

\item[BaseSchedulerModule(arguments : string{[]})]%
  Create and initialise an instance of the main class of the module with the
  given list of parameters. These options are just like the command line
  options of an application.

\item[isStartable() : bool]
  Return true if this module can be run independently by means of the
  \emph{start} method. Startable does not mean that, if started, the module
  won't fail due to some of the reasons described in
  Section~\ref{ssec:generic-pass-errors}. This method is pure virtual.

\item[start()]
  Run the module. The module will complete all its operations and return
  control to the caller. This method is pure virtual.

  Throw \emph{WrongSubclass} if the module is not startable.

  Throw \emph{ObjectNotInitialized} if some of the required domain
  object models have not been registered to the module during
  initialisation.

  Throw \emph{ModuleRunTimeError} if an error occurs during execution.

\item[registerHelperModule(module : BaseSchedulerModule)]
  Register given module as a helper module. This method is normally invoked
  by the Scheduler front-end on a startable module, but it could be
  recursively invoked by a module on its helper modules.

\item[needsTarget() : bool]
  Return true if the module needs a machine object model of the target
  processor.

\item[setTarget(target : Machine\&)]
  Register the machine object model of the target processor to the module.

\item[needsProgram() : bool]
  Return true if the module needs the source Program Object Model.

\item[setProgram(source : Program\&)]
  Register the source Program Object Model to the module.

\item[needsProgramRepresentation() : bool]
  Return true if the module needs the source program in the
  scheduler-specific Program Representation.

\item[setProgramRepresentation(source : ProgramRepresentation\&)]
  Register the Program Representation to the module.

\item[needsPluginLoader() : bool]
  Return true if the module needs the plugin loader for loading its
  helper modules.

\item[setPluginLoader(loader : SchedulerPluginLoader\&)]
  Register the plugin loader to the module.

\item[setLogger(logger : TextLogger)]
  Register a reference to the logger server \emph{logger}, to be used to
  record messages.

\end{description}

\hyphenation{needsProgramRepresentation}
A module should need the source program in at least one of the two
provided forms, so either \emph{needsProgram} or
\emph{needsProgramRepresentation} (or both) should return true.

The base plug-in class provides a macro for exporting a given class as a
scheduler plug-in (see Section~\ref{ch:maintain:add-pass} for details on
adding a pass module):

\begin{quote}\tt
  \verb|SCHEDULER_PASS|(\parm{CLASS})
\end{quote}

\subsection{StartableSchedulerModule}

The \emph{StartableSchedulerModule} class defines operations common to all
startable modules.

\begin{description}
\item[StartableSchedulerModule(arguments : string{[]})]
  Constructor. Create a startable module with the given list of parameters.
  These options are just like the command line options of an
  application.

\item[isStartable() : bool]
  Return always true.

\end{description}

\subsection{HelperSchedulerModule}

The \emph{HelperSchedulerModule} class defines operations common to all
helper modules.

\begin{description}

\item[HelperSchedulerModule(arguments : string{[]})]%
  Constructor. Create a helper module with the given list of parameters.
  These options are just like the command line options of an application.

\item[isStartable() : bool]
  Return always false.

\item[start()]
  Throw \emph{WrongSubclass}. A helper module cannot be started.

\end{description}

\subsection{Factory and Destructor Functions}

Because modules are dynamically linked, they require a factory function and
a destructor function for reliable operation~\cite{James00}. These are
provided by two functions which are the sole symbols directly accessible by
clients.

\begin{description}
\item[createScheduler\_\emph{Module}(argv : string {[]})
  : BaseSchedulerModule*]
  Create an instance of scheduler pass module \emph{Module} with the given
  list of strings as input arguments and options.

\item[deleteScheduler\_\emph{Module}(target : BaseSchedulerModule*)]
  Destroy the given instance of scheduler pass module \emph{Module} and
  deallocate all the memory internally used. Note that the argument cannot
  be a concrete pass module type because the clients are unaware of concrete
  types.
\end{description}

\section{Implementation}

\subsection{Parameters for Pass Modules}

Every module that accepts options or arguments should implement, internally,
an option system based on the toolkit \emph{CmdLineOptions}
class~\cite{ToolkitDesign}. The target program and the (optional) target
processor are provided automatically by the scheduler framework as objects,
and need no parameter such as file name.

Thanks to this localised design, the scheduler front-end does not have any
concern about module-specific parameters.

\subsection{Automatic Definition of Factory Function and Destructor}
\label{ssec:automatic-export}

Factory function and destructor function are defined automatically by
\emph{SCHEDULER\_PASS} declaration, described in
Section~\ref{ssec:BaseSchedulerModule-if}.

\section{Error Handling}
\label{ssec:generic-pass-errors}

\subsection{Non-startable Module}

If method \emph{start} is invoked on a module that is not startable, the
exception \emph{WrongSubclass} is thrown. This exception could be safely
ignored by the scheduler front-end, perhaps providing some warning. This
behaviour could be controlled by a Scheduler command line option.

\subsection{Incomplete Module Group}

If method \emph{start} is invoked on a startable module that is just the
main module of a group of cooperating modules, but not all helper modules
have been registered into it, then it throws \emph{IncompleteModuleGroup}
exception. This exception could be safely ignored by the scheduler
front-end, perhaps providing some warning. This behaviour could be
controlled by a Scheduler command line option. Obviously, a standalone
module should never throw this exception.

\subsection{Unrecognised Module}

If a module (or the Scheduler front-end) tries to register an unexpected
helper module to another module, this module should throw a
\emph{UnrecognizedModule} exception. However, care should be taken that a
module only throw when all its helper modules have been registered, since
one of its helper modules could require the module to be registered.



\chapter{Tracking System}
\label{ch:tracking}

This chapter describes a set of design guidelines for implementing logging
of scheduling activity.

\section{Overview}

There are two parts to the Scheduler tracking system: one part is
responsible for logging proper, the other for preparing messages destined to
the log stream.
%
Logging proper is implemented by a project-wide toolkit facility: the text
logger. The preparation of messages, on the other hand, is inherently
client-specific and distributed across the system; it cannot be implemented
with a toolkit facility.
%
The rest of this chapter deals with this part of the tracking system. For an
in-depth description of the text logger, the reader should refer to the
Toolkit Design Document~\cite{ToolkitDesign}. See
Section~\ref{ssec:logging-imp} for a description of how the logging server
side should be instantiated and set up for the Scheduler.

Each pass module should report information about its activity in textual
form, and adjust the level of detail according to the value of \verb|--log|
global Scheduler option. In other words, each module should be a logging
client and make use of the facility provided by the server logger.
%
Class \emph{BaseSchedulerModule} provides a method to register the module to
a logging server (see Section~\ref{ssec:BaseSchedulerModule-if}).

The client-side of logging consists of the following actions (not
necessarily in the listed order):
\begin{enumerate}
\item %
  Collect input data necessary to create the message.
\item %
  Test whether the message to be logged is enabled by the current level of
  verbosity.
\item %
  Prepare and format the string message to log.
\item %
  Request the server logger to proceed with logging.
\end{enumerate}

This chapter defines a recommended design framework for implementing above
activities. Developers are free to improve on this design or ignore it
completely, but should at least use the logging server to make clients
report on their activity.

\subsection{Motivation}

The proposed design framework tries to minimise or avoid altogether the
following problems:
\begin{enumerate}
\item %
  Mixing of actual client code with code to log messages makes the
  implementations hard to maintain, more complex and less coherent.
\item %
  Minimising the overhead due to logging, especially when logging is
  completely disabled (verbosity level 0).
\end{enumerate}

The proposed design framework design offers the following advantages:
\begin{enumerate}
\item %
  Minimal ``intrusion'' of logging code inside the module implementation.
  The code is readable, logging points appear as calls to a method, possibly
  surrounded by an \emph{if} construct.
\item %
  Clearly separated implementation of logging code and actual client code in
  separate classes. The only direct responsibility left to the client module
  is construction of the logger client object.
\item %
  Reduced overhead when logging is completely disabled. The overhead can be
  reduced down to one invocation of an empty method or an \emph{if} test. In
  less optimised designs, the overhead is increased by the argument passing.
\item %
  Reduced overhead when logging is enabled. In the most efficient
  implementations, the overhead of testing the verbosity level is completely
  eliminated. The client logger class hard-codes the test at construction
  time. In less efficient implementations, still the client does not pass
  the verbosity level as parameter.
\item %
  Easy to maintain. To add new logging points and possibly new logging
  methods, the only necessary change to client code is insertion of method
  calls. The rest is hidden inside the logger client class (and possibly its
  interface).
\end{enumerate}

The only drawback that, in some cases, cannot be completely eliminated is
the overhead and the client code necessary to prepare and pass the input
parameters to the logging methods.

\subsection{Logger Client}
\label{ssec:LoggerClient}

The framework defines the interface \emph{LoggerClient} for clients that
need logging. Implementations of this interface should provide a centralised
place for most of the logging activities that take place in the client.

Every pass module should define an implementation of \emph{LoggerClient}. In
addition to the methods of the base interface, these implementations should
provide the methods necessary to carry out all specific logging requests
that the client can issue.

The following table summarises how logging activities can be distributed:

\begin{flushleft}
\begin{tabular}[h]{|p{0.20\textwidth}|p{0.70\textwidth}|}
  \hline
  \emph{activity} & \emph{who is responsible} \\
  \hline

  collecting data &
%
  Normally, the client module. Often, the logger client retrieves some of
  the data from the module instead of receiving it. If all data is accessed
  via the module's public interface, then the logger client can take over
  this task entirely.\\
  \hline

  testing verbosity level &
%
  Ideally, the test can be performed once and for all at the time the
  concrete logger client is instantiated. In simpler designs, the test can
  be performed by the logger client (less efficient) or by the client itself
  (code less clean).\\
  \hline

  message preparation &
%
  Logger client.\\
  \hline

  sending log request &
%
  Logger client.\\
  \hline
\end{tabular}
\end{flushleft}

In its most centralised implementations, the logger client performs all
activities related to logging. What remains inside the client module are
mere calls to methods of the logger client without any input arguments.

\section{Interfaces}

\subsection{LoggerClient}
\label{ssec:LoggerClient-if}

\emph{LoggerClient} is an abstract interface.
\begin{description}
\item[LoggerClient(logger : TextLogger\&)]%
  Constructor. Records the given logger server.
\item[server() : TextLogger\&]%
  Return the logger server used by this client.
\end{description}

\paragraph{Client-specific interface.}

Any concrete implementation of \emph{LoggerClient} should provide a full set
of logging methods. For example, a register allocator module could utilise a
logger client that defines a specific method \emph{logSpilledVariable} to
log the fact that a given program variable is not assigned to a register but
is spilled to memory instead. Anything about these client-side logging
methods is specialised: the name and the number and type of arguments. For
example, the \emph{logSpilledVariable} method could take as input argument
the node that defines the variable spilled to memory and a cost value
computed using a heuristic algorithm.

Normally, a string is not sufficient to generate a message. In general,
logging methods need input data to generate the message. There are two
choices: either the client passes the data as input arguments of the method
invocation, or the method is capable of retrieving the data from the
client's state, through its public interface.

When possible, it is better to avoid passing argument, because this improves
the readability of the client code and reduces the overhead when logging is
completely disabled.
%
This is seldom possible. Normally, the client has to pass arguments, because
the input data is context-dependent to the point that it changes at each
execution of the same logging point in the client code, and the client does
not store or does not provide access the input data as state.

\section{Implementation}

\subsection{LoggerClient}
\label{ssec:LoggerClient-imp}

Internally, all specific methods of a concrete logger client should end with
a request to the logger server (see~\cite{ToolkitDesign} for details) by
means of \emph{log} method. However, the framework cannot enforce this,
because the logging methods are client-specific and defined by the
developer, not by the framework.

\subsection{Construction and Optimisation of Logger Clients}
\label{ssec:construction-imp}

The most efficient implementation of a concrete logger client avoids the
testing of the verbosity level at run-time altogether. The developer must
define a base class for the concrete logger which defines all logging
methods as empty. Then, each group of logging methods enabled by the same
minimum verbosity level is defined in a separate sub-class, and every new
sub-class is derived from the previous, immediately lower verbosity level.

Taking advantages of these level-specific subclasses, the client can
hard-code the test of the verbosity level at construction time, as shown by
following example.
\begin{verbatim}
  switch verbosityLevel_ {
  case 0: logger_ = new SchedulerLogger(server); break;
  case 1: logger_ = new SchedulerLoggerLevel1(server); break;
  case 2: logger_ = new SchedulerLoggerLevel2(server); break;
  case 3: logger_ = new SchedulerLoggerLevel3(server); break;
  default: logger_ = new SchedulerLoggerLevel3(server); break;
  }
\end{verbatim}

A possible alternative, less efficient but just as ``clean'' from point of
view of client code and the invocations to logging methods, is to embed the
verbosity level inside the logger client at construction time:
\begin{verbatim}
  logger_ = new SchedulerLogger(server, verbosityLevel_);
\end{verbatim}

A solution that is lightly more efficient then the last one, but less than
the first and especially less ``clean'', is to make the logger client
completely unaware of the verbosity level, and just place the \emph{if}
construct in client code. This solution, however, does not eliminate the
overhead of the test evaluation when logging is completely disabled.



\chapter{REJECTED ALTERNATIVES}

% Rejected alternatives for (parts of) the design should be listed here with
% the reasoning and date the alternative was dumped. For future reference.

\begin{description}
\item[19.08.2005 --- Scheduling forward jump addresses in iterative mode.] %
  As alternative to complete re\-scheduling whenever a forward address does
  not fit the instruction slots assigned to it, the scheduler could iterate
  in each case the address target is not defined with certainty. When the
  scheduler reaches the target location referenced by the address, the
  address is known, and the scheduler can immediately set the correct value.
  However, this may change an already scheduled instruction so that the
  remaining part of schedule between relative jump and target would have to
  be rescheduled. After which the scheduler has to correct he jump address,
  which in turn may lead to another need to reschedule the part between jump
  and target. This process quickly converges to a stable solution and, at
  any rate, requires a finite number of iterations, on condition that the
  bit width reserved for encoding constant addresses (or offsets) is never
  decreased after the first iteration.
\item[05.09.2005 --- Keeping pre-assignments as local state.] %
  Instead of defining and passing around \emph{PreAssignment} objects, an
  alternative design to support pre-assignments is to let each broker store
  internally any pre-assignments to the given node before starting
  allocation. The downside of this design is that we introduce \emph{ad-hoc}
  state to brokers. Another problem is that local pre-assignment state may
  be insufficient: a broker might need to know which resources are
  pre-assigned not only among the resources it manages, but also among
  related resources.
\item[17.09.2005 --- Centralised resource builder.]%
  A centralised resource builder constructs resource objects instead of
  single resource brokers. This alternative suffers from two problems:
  \begin{enumerate}
  \item %
    Flexibility: A new builder would be required whenever a broker and its
    implementation of a resource type are replaced. For example, if each
    resource type had two compatible, alternative implementations, there
    would be $2^7$ combinations and as many concrete builder classes!
  \item %
    Maintenance: All existing builder classes would have to be adjusted
    whenever a new type of machine part and resource are introduced.
  \end{enumerate}
  A centralised resource builder would internally build instances of
  concrete resource types from specific machine parts with one of the
  following types of \emph{Factory Methods}:
  \begin{description}
  \item[build\emph{ResourceName}(MachinePart\&) : SchedulingResource\&]%
  \item[buildResource(\emph{ConcreteMachinePart}\&) : SchedulingResource\&]%
  \item[buildResource(MachinePart\&) : SchedulingResource\&]%
  \end{description}
  Each style of factory method has its own drawbacks, such as, for example:
  need for downcast, need for interface or implementation extension whenever
  a new machine part or a new concrete resource type is introduced, need for
  complex selection (if tree or associative map) of resource type based on
  the type of the machine part.

\item[07.11.2005] --- Explicit ordering of nodes in node groups.

  Either the selector or the node group class provides method
  \emph{isOrdered} to let clients test whether the order of nodes in a group
  reflects the sequential layour of code or the dependencies or not. This
  makes it possible to work on node groups with several nodes even when the
  program representation does not hold explicit dependencies between nodes.

  Rejected because scarcely useful and problematic. Clients that rely on a
  sequential ordering of nodes rather than explicit dependencies are likely
  to be primitive, toy algorithms. Second, interface is either error-prone
  and non-intuitive (if \emph{isOrdered} is provided by selector) or
  inefficient and inconvenient (if provided node group). In the latter case,
  clients that rely on the node order should test every node group before
  doing anything that depends on the order of the nodes in it.

\item[11.11.2005] --- Simpler specification of pass modules.

  Each pass module must be implemented in a single separate file. The name
  of the module is derived from the name of its file. Rejected because too
  restrictive.

\item[22.11.2005] --- Centralised API for program operations.

  As alternative, \emph{ProgramOperation} should provide access to each
  single node copy of a multi-node operation input or output. Consequences
  of this design are:
  \begin{enumerate}
  \item %
    The count methods must be duplicated (inputs and outputs).
  \item %
    The node access methods \emph{inputNode} and \emph{outputNode} are more
    complicated and have a default argument value.
  \item %
    Clients are encouraged to drag along program operations instead of
    single node sets for an operation input or output.
  \end{enumerate}
  For these reasons, the design has been rejected.

\item[27.03.2006]

  --- Inserting Cycles into Resource Manager.

  The resource manager does not provide any facility to insert cycles in the
  middle of a sequence of cycles.

  Motivation: the static, lock-step scheduling of TTA's makes inserting
  cycles (while preserving program's behaviour) almost impossible,
  especially if the schedule is compact.
%
  This is due to resource conflicts and pipeline overwrites of results.
%
  Conflicts may occur with resources whose assignment lifespan exceeds 1
  cycle.
%
  Testing resource conflicts is not enough. Also the scheduling algorithm is
  affected by cycle insertion.
%
  There is no solution to this problem without some form of backtracking and
  re-scheduling.

\end{description}



\chapter{IDEAS FOR FURTHER DEVELOPMENT}

% Ideas that are not part of the design yet but that might be added in the
% future are listed here. This is to have ideas written down somewhere.
% This list should contain the date of addition, the idea described briefly
% and the inventor of the idea.

\begin{description}
\item[05.09.2005] --- Register allocation inside resource manager.

  Register allocation and assignment could be integrated inside the resource
  manager. A possible solution is a register broker class that maps program
  variables (UM GPR's) to registers of the target register files. Such a
  broker would probably be similar to the register reservation vectors
  described in Janssen work~\cite{JJans01}.

\item[06.09.2005] --- Support for Multicasts.

  Rather than a resource, multicasts are a lack of a constraint, namely, the
  limit of one writable destination for each segment (multicast proper) or
  for each input socket (socket multicast). The source of the limitations
  are usually due to instruction encoding. So, unconstrained multicast
  support does not require much: just removal of reuse limitation to busses,
  segments and (possibly) input sockets. Limited multicast support, however,
  is more complicated. The limitations (perhaps due to instruction encoding)
  could be modelled as a resource. In some simple cases, the support could
  require just to define a limit to the number of destinations of a bus or
  input socket. See Section~\ref{ch:pending:multicast-support} for ideas
  about how to implement support for multicasts.

\item[06.09.2005] --- Support for Bridges.

  Bridges can be probably modelled as a fixed output socket always writing
  the first segment of a bus. Unlike for most resources, assigning bridges
  involves code restructuring (splitting one move in two separate moves in
  different cycles). Node splitting could be demanded to the resource
  manager itself or to its clients. Also, the decision whether to split a
  node or try assignment in a later cycle can rest on the resource manager
  or to its clients. In the latter case, clients (such as the scheduling
  algorithm) could perform all or part of node splitting upfront, as a
  pre-scheduling code transformation.

\item[06.09.2005] --- Support for TTA's that are not bus programmed.

  If a TTA processor is not programmed by means of bus slots, then something
  else must be used to encode long immediate bits. Thus, the optimisation of
  assigning directly bus resources when an instruction template is assigned
  must be given up. Some other resource must be defined. To keep resource
  allocation more general, an ``immediate slot'' resource could be defined.
  In bus-programmed TTA's, an immediate slot is dependent on a bus (and vice
  versa).
\item[08.09.2005] --- Failure-tolerant resource assignment.

  Clients of resource manager that want to work with partially failed
  assignments need to catch extensions. This is inefficient. Testing for the
  availability of resources before requesting assignment is of no use,
  because it does not give information about which resources are not
  available.

  To overcome this limitation, implementations of resource manager can
  optionally support failure-tolerant assignment. In this mode, (partial)
  failure of assignment requests simply do not rise exceptions. Clients that
  work with a resource manager in failure-tolerant mode should always test
  the nodes after an assignment request to verify if assignment of any
  needed resource failed.
%
  -- A.~Cilio
\item[23.09.2005] --- More sophisticated broker directors.

  Assigning all required resources to a node in a single attempt is not the
  most effective approach. For example, bus assignment can fail on one node
  due to previous bus assignments to nodes in the same cycle even if there
  exist a valid combination of bus-node assignments for all nodes in the
  considered cycle.

  In these cases, assignment of busses should proceed globally, for all
  nodes in the given cycle. One possible approach is the following. When the
  simple first-fit assignment fails, all nodes in the same cycle have their
  original bus assignment cancelled. Then, a more sophisticated algorithm is
  used to find bus assignments. Algorithms such as bipartite matching
  guarantee to find a bus for all nodes in a cycle if at least one
  combination of assignments exists.

\item[04.10.2005] --- Client control on module-specific parameters.

  It is foreseeable that certain clients (UI's, for example) of the
  scheduler framework want some control on module-specific options. If not
  for anything, just to let users browse them (inspect their value and
  obtain their description, and so on).
%
  -- A.~Cilio

\item[02.11.2005] --- Better immediate register allocation.

  Immediate registers could be allocated more aggressively:
  \begin{enumerate}
  \item %
    Definitions and uses could cross basic blocks and even scopes (this is
    particularly effective to move the constant definitions outside a loop).
  \item %
    The same definition could be reused by multiple immediate moves. This
    probably requires a new type of data dependency, but the definition
    point is an instruction template, not a node.
  \end{enumerate}

\item[13.02.2006] --- Built-in infinite loop prevention in selector.

  Add a counter to the selector. Whenever it receives a request, the
  selector checks if the returned result is identical to the last returned.
  If so, it increases the counter, and throws if a limit is reached, thus
  preventing infinite loops.

  A single counter is not sufficient, however. The selector can return
  different groups of nodes even if the program representation did not
  change simply because the working parameters (internal state) have been
  changed. If the client keeps sending the same requests alternated by the
  same state parameter changes, the counter is always reset. To solve this
  problem, the selector should keep the returned results for different
  combination of working parameters, by the input data of their request.
  However, one of the working parameters is the input scope, and there can
  be an unlimited number of scopes. Thus, the selector should need a cache
  of counters, with entries addressed by input scope and working parameters.
%
  -- A.~Cilio
\end{description}



\chapter{PENDING ISSUES}

This chapter documents all pending issues concerning this design, a list of
problems that need to be solved before the design is complete. When the
design is completed, this chapter should be empty.

\section{Support for Single Static Assignment Form}
\label{ch:pending:ssa}

The SSA form is very convenient for a number of dataflow-based code analysis
and code transformation passes (see~\cite{Cytron89},\cite{Cytron91}). For
this reason, it is foreseen that there will be a pass to transform the
internal program representation into SSA form (before analysis) and back
(after analysis, after or before code transformation).

SSA form is not suitable for all code transformations and analysis passes.
In case of arrays, pointers and structures, SSA transformation needs to deal
with modifying member of array as well as copy of whole array. Simple
conservative solution is to use \emph{access(A,i)} and \emph{update(A,j,X)}
functions, meaning we consider whole array as one variable.  Pointers,
specifically in C language, are not restricted to particular memory area, so
each write access through pointer may in theory change any possible data.
Structures are usually treated in same way as arrays.

This approach is rather ineffective. Better results can be achieved
with more information about what memory location is accessed or updated.
That is partially possible with careful alias analysis.
This needs to be investigated further before final decision on SSA is made.

Most if not all analysis passes that will be distributed with TCE toolset
will support either SSA-form or traditional dataflow with multiple
assignments. It seems a waste of effort to try to implement analysis passes
in both forms.

Also, SSA form is usually not suitable for code generation and
transformation in general, however there exist extension of SSA form called
\emph{gated static-single assignment} that puts selector into phi function
that indicates position to select according to path taken to joint point.
In case of TTA we have also interesting possibility to use predicated
execution and if-conversion to replace phi function instead of traditional
copying.

In classical SSA transformation, when translating back to non-SSA form, each
phi function is replaced by assignments in basic blocks leading to join
point. In case of TTA, these assignments result in register copies. When
register assignment cannot get rid of these copies altogether, an
alternative is to guarded the copy with same predicate denoting the
corresponding incoming path of the join point. This allows to move register
copies into the block where the original phi function was located. This
would be possible only if there is one boolean registers available for each
predicate sub-expression corresponding to one of the incoming paths.

\section{Fine Control of Candidate Selection}
\label{ch:pending:candidate-lists}

If the selector is not capable of returning a prioritised list, then there
is no simple way to allow a scheduling algorithm to reject a selection and
try a different candidate. For the time being, if selector can only return
one candidate group, then the scheduling algorithm can never reject it.

In other words, a scheduling algorithm that knows it can reject a node
should first test the selector with \emph{canComputeCandidateList}, and if
the answer is false, abort.

An alternative interface to let clients communicate rejection of candidates
to selector is probably unacceptable, because it introduces arbitrary state
and creates ambiguity. For example, what if more than one candidate group
is rejected? Should the selector return the first group again? Or keep
returning possible groups until all are rejected before returning again the
first candidate group?

\section{Limitations to External Resource Assignments}
\label{ch:pending:ext-assignment}

Due to limitations of the interface of assignment requests (a node), clients
can force resource assignments only upon completely unassigned nodes. Once
the node is partially assigned (either by resource manager or by an
externally forced (and validated) assignment, clients cannot force any
further resource assignments on the node. The rest of the assignments must
be carried out by the resource manager.

\emph{Example. Partial external resource assignment.}
A client can invoke
\begin{verbatim}
  node.src().setUnit(anFU);
  node.src().setPort(anFU->port(theIndex));
  if (validAssignments(c, node)) updateAssignments(c, node);
\end{verbatim}
only if \emph{node} is completely unassigned before \emph{anFU} is assigned
to its source. Once the resource manager has updated itself with the
external assignments, the client can only delegate assignment of remaining
resources to the manager, for example:
\begin{verbatim}
  if (canAssign(c, node))  assign(c, node);
\end{verbatim}

Overcoming this limitation requires a more complex interface, where the
client tells the resource manager which resources have to be considered
pre-assigned (and thus already updated) and which one assigned by client.

\section{Allocation of Long Immediates}
\label{ch:pending:long-immediates}

How to allocate the write action that encodes long immediates and the
corresponding instruction template? There are two possible approaches:
\begin{enumerate}
\item %
  Let resource managers treat instruction templates as a dependent resource
  of IU and assign it at once with the IU register.
\item %
  Let clients or a helper translate the code and split the long immediate
  write action into an entity separate from the node that reads the long
  immediate.
\end{enumerate}

Currently, a simplified version of the second approach is chosen. This could
work quite well when the scheduling scope is restricted and the resource
manager is not particularly optimised.

The first approach is problematic because instruction templates are a
complicated resource. A template may be assigned and thus define an
immediate register several cycles before the node which reads the register.
In reality, the template is not assigned, but rather the basic template (no
long immediates encoded) is ``converted'' into a template that encodes long
immediates. The choice of cycle is strictly limited only by dataflow
anti-dependence between template definition and an earlier immediate node
that reads the same IU register.

The problems with the second approach are at east two:
\begin{enumerate}
\item%
  Problematic interaction between clients and resource manager. Either
  clients perform a test and decide in advance which constants are destined
  to long immediates (and thus which nodes should be split), or we must
  support the possibility that the resource manager fail an assignment
  request (due to a constant that needs long immediates). Upon failure, the
  client must create a new pseudo-node to represent the immediate encoding
  and write action, and request assignment of this and the original node
  again.

  The first solution is likely to be suboptimal; the second is probably
  complicated (new type of node, new type of dependence).
\item%
  Need to define an entity subject of resource assignment (immediate write
  action). This entity could be modelled as a special kind of node. Even if
  this entity can be scheduled as a separate node, it is tightly linked to
  the original node, and should be scheduled immediately before it.
\end{enumerate}
The solution implemented in \emph{SimpleResourceManager} uses alternative set
of method for dealing with immediates.
When scheduler fails to schedule MoveNode with immediate source, scheduler
needs to call method for testing if machine \emph{canTransportImmediate}.
If transport is not possible, scheduler tests if it \emph{canAssignLongImmediate}.
Method \emph{assignLongImmediate}, assigns immediate write with correct instruction
template and modifies the MoveNode source to read correct immediate unit and register.

\section{Linked Resource Assignments}
\label{ch:pending:linked-assignments}

In some circumstances, assigning a resource to a given node generates, as
side-effect, assignment of the same resource to other nodes. This is
different from the well-behaved assignment of dependent resources, which
affect the same node and usually apply to the same cycle. For example, when
an operation is assigned to a function unit, other nodes that belong to the
same operation should be assigned, too.

The specular problem occurs when a resource is freed: all linked assignments
should be undone as well.

\section{Scheduling Triggering Operand Moves}
\label{ch:pending:triggering-operands}

From hardware's point of view, supporting operand moves that do not set the
operation code but still trigger new computation in the execution pipeline
is very convenient. The hardware is cheaper, the control is simpler and the
execution slightly faster.

From scheduler's point of view however, triggering operands are more
difficult to schedule than non-triggering operands.

\emph{Example.}
%
Let `mul' and `mulh' be fully pipelined operations of function unit `U' with
a 3-cycle latency between the opcode-setting input `1' and the only result,
`3'. Let's assume that the moves of `mulh' have been scheduled and the
scheduler is now trying to schedule the triggering operand move `mul.2'
after having scheduled the opcode-setting move `mul.1'. The following
schedule makes it hard to detect a conflict in resource manager alone.
\begin{verbatim}
1:  r1 -> U.mulh.1
2:  . . .
3:  . . .
4:  r2 -> U.mul.1     // mulh result ready!
5:  . . .
6:  U.mulh.3 -> r3    // mulh result overwritten by end of cycle
7:  U.mul.3 -> r4
\end{verbatim}
%
The port of `U' bound to `mul.2' operand is triggering, so the move that
writes `mul.2' cannot be scheduled outside cycle 4. From the point of view
of the resource allocation, cycles 2 and 3 can be valid choices because no
pipeline conflict occurs (since the operations are fully pipelined).
However, the program behaviour is corrupted. For example, scheduling the
move to `mul.2' in cycle 3 would destroy the result of `mulh' during cycle
5, so `mulh.3', read in cycle 6, would contain an invalid result.

The operand move`mul.2' can be scheduled in cycle 4, because the result
would change only during cycle 6. At the beginning of cycle 6,
`\verb|mulh.3 -> r3|' still reads the correct old value.

\paragraph{A crude solution} is to restrict scheduling of triggering
operands to the same cycle of the opcode-setting move. This, however, may be
impossible on some target architectures due to structural resource
constraints.

\paragraph{Another restrictive solution} is to force scheduling of the
result moves as soon as the result is available. This restriction simplifies
the scheduling algorithm, but also increases register pressure.

\paragraph{A more general solution.}
The example above seem to suggest that the scheduling algorithm could
restrict the cycle interval of triggering operands to the range $[r_{0} -
(l_{0}-1),t_{1}]$, where $r_{0}$ is the cycle in which a result of the
previous operation on the same unit is scheduled (in example above, 6),
$l_{0}$ is the operation latency for that result, and $t_{1}$ is the cycle
in which the operand of the considered operation is scheduled (4, in the
example).

Unfortunately, this solution works only if the pipeline writes the output
port \emph{only} in the last cycle of computation. For example, if `mul'
operation above in not fully pipelined and takes 2 cycles to write its
result, as shown in following pipeline diagram:
\begin{quote}
\begin{tabular}{|l|c|c|c|}
\hline
                & \multicolumn{3}{c|}{cycle} \\
\cline{2-4}
  \raisebox{1.5ex}[0ex]{operation i/o} & 0 & 1 & 2 \\
\hline
  mul.1         &  - & x & - \\
\hline
  mul.2         &  - & x & - \\
\hline
  mul.3         &  - & x & x \\
\hline
\end{tabular}
\end{quote}
then we have a conflict even if `mul.2' is scheduled in cycle 3, because the
result begins to be altered in cycle 3, and by the beginning of cycle 4 the
old result value is lost.

\paragraph{Conclusion.} This sort of conflicts require knowledge that is
inside the resource manager. The scheduler cannot figure it out alone.
%
The resource manager, however, does not know about dataflow. It knows when
an operation's result is ready, but does not know when and if it is read by
a result move. A resource manager can easily tell whether a too-early
triggering operand is going to create, for example, a (pipeline) write
conflict with another operation, but it cannot see any conflict when the
result of an operation is overwritten even if data-live and not yet read.

\section{Scheduling ``Sandwich'' Operations}
\label{ch:pending:sandwich}

Two operations assigned to the same function unit form a ``sandwich'' if
they are scheduled so that the operation that is started later writes its
output before the other operation.

If the two operations write the same output port and if the earlier
operation is scheduled first, then the result move of the second operation
cannot be scheduled after \emph{the first cycle}\footnote{
%
  An operation can take several cycles, if sub-pipelined or not pipelined at
  all, to write one of its results into the output port.}
%
in which the first operation writes the output port.

Consider the following piece of code:
\begin{verbatim}
1: r1 -> U.mul.1 ; // trigger, latency 5 cycles
2: . . . ;
3: r2 -> U.add.1 ; // trigger, latency 2 cycles
4: . . . ;         // output written with add result
5: U.add.3 -> r3 ; // output written with mul result
6: U.mul.3 -> r4 ;
\end{verbatim}
This schedule, assuming both operations are fully and independently
pipelined, is correct only if the result of `add' is read before the earlier
operation begins to write the output. Assuming that `mul' writes the output
in one cycle, 4 cycles after it is started (in this case, in cycle 5), the
schedule above is correct.
%
If `mul' takes two cycles to write the output, then the schedule above is
not conflict-free, because both `add' and `mul' write the same output port
in cycle 4. The resource manager detects this conflict.
%
The schedule is valid if `add' can be scheduled one cycle earlier
\begin{verbatim}
1: r1 -> U.mul.1 ; // trigger, latency 5 cycles
2: r2 -> U.add.1 ; // trigger, latency 2 cycles
3: . . . ;         // output written with add result
4: U.add.3 -> r3 ; // output written with mul result (begin)
5: . . . ;         // output written with mul result (end)
6: U.mul.3 -> r4 ;
\end{verbatim}

Let's consider a more problematic case. If the result of `add' is not
scheduled as early as possible, but in cycle 5, then the resource manager
detects no resource conflict. For the pure data flow model of the scheduler,
the result of `mul' is not yet (completely) written, so is would seem that
`add' result move can be scheduled. However, the output port has been
already altered (possibly corrupted with an unstable value) in cycle 4.

Thus, this scheduling restriction is not exactly modelled by the program
representation (and seen by the scheduler), nor directly captured by the
resource model.

A possible solution is a method that clients can use to obtain the answer to
the following question from the resource manager:
\begin{quote}
  ``What is the first cycle after triggering an operation \emph{O} on FU
  \emph{U} in which the value of the port bound to the output \emph{n} of
  \emph{O} is altered?''
\end{quote}

This question is equivalent to asking what is the latest cycle, after
triggering an operation, in which the result of previous operation can still
be read.
%
A scheduling algorithm would use the method to solve the problem in above
example as follows: the latest cycle in which the previous operation can be
read before `mul' overwrites it is $1+3$; therefore, `add.3' move must be
scheduled  in cycle 4 at latest.

The proposed method captures, in fact, a structural property of the
operation implementation on the target machine. As such, it could be
implemented in MOM, but it is perhaps too \emph{ad hoc}.

\section{Implementation of Segment Resource}
\label{ch:pending:segment-resource}

There are two possible implementations for segment resources. It could be a
completely internal resource (not even modelled by a class, possibly), much
in the style of registers of immediate units. Or, it could be modelled as a
public specialisation of \emph{SchedulingResource} that is linked (by
related associations) to other resource types (p-sockets).

If segment resources are only internal to busses, then the bus resource must
keep a mapping between p-sockets and segments in order to find which segment
chain is required for a given pair of input, output p-sockets.

If segment is a resource in its own right, then p-sockets can have a direct
link (dependent association) to segments, and bus resources just have to
maintain the sequential order of segments. However, in this case segment
resources are dependent on bus resource (are linked from it) and the bus
must scan all its segments in order to assign or allocate itself to a node.

\section{Support for Multicasts}
\label{ch:pending:multicast-support}

Multicasts can be supported in three forms:
\begin{enumerate}
\item %
  Unrestricted multicast support.
\item %
  Restricted multicast support (only certains destination groups).
\item %
  Individual segment programming.
\end{enumerate}

Individual segment programming makes it possible to multi-cast a single
source to several destinations using a single bus, as long as each
destination is connected to a different segment of the same bus. It is a
more regular form of restricted multicast.

Depending on multicast support and how segments are programmed, the
availability and the reusability conditions change for busses and segments.

\subsection{Availability of Resources}

With unrestricted multicasts, a segment is completely unavailable only when
its use count is $>$ 0 and all possible destinations connected to the
segment or its successors is already written. Such condition should not
occur in a correct program, so it can be well approximated with: always
false!

With independent segment programming, the condition is: use count $>$ 0 and
all segments past this segment are already in use.

With restricted multicasts, the condition is: use count $>$ 0 and the
destination of the move this segment is already assigned to does not belong
to a multicast that includes the destination of the given move. The second
condition can be extended for two or more assignments.

\subsection{Reusability of Resources}

In order to test for reusability, the segment resource object must record
the transport source. A segment is \emph{never} reusable if the source of
the given node and the source of the node (or nodes) this segment is already
assigned to are different.

With unrestricted multicasts, this is the only condition for reusability. In
theory, a segment would not be reusable if the the destination of the given
node is already written by another move that the segment is assigned to.
But this situation cannot occur in a correct program.

With individual segment programming, an additional condition for reusability
is that the destination is not written by a segment that is already assigned
to another node's destination.

With restricted multicasts, an additional condition for reusability is that
a multicast is available which includes the destination of the given node
and the destination of the nodes the segment is already assigned to.

\section{High-Level Design of Edges}
\label{ch:pending:edges}

It is necessary to organise all properties of edges between nodes of the
program representation (see Chapter~\ref{ch:ProgramRepresentation}).

The only property common to all edges of the program graph is that their
source and destination are nodes. All other properties depend on the type of
edge considered.

\begin{enumerate}
\item %
  (Cycle) Distance: minimum number of cycles that must separate the tail
  node and the head node. This property belongs, for example, to edges that
  link nodes of the same program operation. Data dependency edges have a
  fixed distance of 1 cycle. Control flow graphs also have a fixed distance,
  in this case the latency of the control transfer operations.
\item %
  Iteration distance: number of loop iterations that must occur between the
  tail node and the head node in order to have a dependency. This property
  belongs to edges that represent dependencies between operations that
  access memory. It the distance is zero, it means that the dependency is
  immediate (not loop-carried).
\item %
  Certainty: a dependency can be certain or just possible. The latter type
  of dependency applies to certain types of edges, such as memory
  dependency edges.
\item %
  Strictness: is distance rigid or is it ``elastic'' (more cycles of
  separation are also allowed).
\item %
  Direction: is the distance the minimum (usual definition) or the maximum
  allowed between the two nodes? Maximum distance is useful, for example,
  for certain intra-operation dependencies (such as the dependency between
  the operand move and the move that starts the operation).
\end{enumerate}

\paragraph{Negative cycle distances.}
Should it be possible to have edges with negative distances? A negative
distance simply represents an ordering constraint where the head should come
before the tail node. This is counter-intuitive. If not allowed, then two
possibilities exist: automatically normalise edges with negative distance by
swapping the direction (head-tail) or simply force positive distances (and
return error by negative distances).



\chapter{MAINTENANCE}

This chapter treats the problem of extending the design with new
capabilities that fit in the predefined scheduler framework.

\section{Adding a Pass Module}
\label{ch:maintain:add-pass}

A pass module of the scheduler framework has a sub-class of
\emph{StartableSchedulerModule} as root class, and must be located in a file
that can be linked at run time.
%
The toolset provides scripts and a makefile template to build new scheduler
passes so that they can be linked dynamically.

Except for a couple of conventions (see below), the code of scheduler passes
is unrestricted C++ code.
%
No restriction whatsoever applies to user-defined scheduler modules, as long
as the module root class implements \emph{StartableSchedulerModule}
interface. In principle, it is possible to use any programming language for
the source, as long as its objects can be linked and can inter-operate with
C++ objects.

\paragraph{Multi-module Passes.}

If a pass consists of two or more modules, then only one (the main module)
module class must be startable. All other module root classes \emph{must} be
implement helper modules and must be derived from
\emph{HelperSchedulerModule}.
%
Note that no module root class should ever be derived directly from
\emph{BaseSchedulerModule}.

\paragraph{Exporting a Module.}

A scheduler pass is declared using a special definition with the following
syntax:
\begin{quote}\tt
  \verb|SCHEDULER_PASS|(\parm{CLASS})
\end{quote}
where \emph{CLASS} stands for the name of the class. This declaration must
appear in one of the source files that contain the code of the pass module,
and makes it possible for the scheduler front-end to find and construct the
module main class.

\paragraph{Module Files.}

The organisation of module implementations into files is rather flexible.
The name of the file is unrestricted and bears no relation with the name of
single modules contained in the file.
%
The only restriction is that a pass module's implementation cannot be
distributed into several object files.
%
On the contrary, two or more pass modules can be built into a single object
file. It may be a good practice to group into the same file all modules of
the same multi-module pass.
%
In any case, common interfaces and declarations between modules of the same
pass can and should be shared in the same source file.

\paragraph{Module Names.}

The module names adhere to the same restrictions that apply to any valid C++
class name. In addition, there are a few project-wide guidelines about
naming that should be complied with. Below are the main restrictions.
\begin{enumerate}
\item The class name should not start with underscore `\verb|_|'.
\item The class name should begin with capital letter.
\end{enumerate}

\paragraph{Dealing with Exceptions.}

All error conditions that can occur inside a pass module during execution
and which are not due to internal errors of the implementation must be
signalled to clients by means of a \emph{ModuleRunTimeError} exception.

However, consistently throwing \emph{ModuleRunTimeError} inside the module
code is not advisable nor feasible.
%
Users may find it useful to internally define and handle other types of
exceptions. Modules can also invoke library objects with predefined
exceptions, on which they have no control.

A possible solution to let the reimplementation of \emph{start} method catch
all module-specific exceptions and convert them into
\emph{ModuleRunTimeError} as needed. A good idea would be to implement only
error and exception processing in \emph{start}, and define a private method,
for example \emph{startInternal}, for actual module activity:
\begin{quote}
\begin{verbatim}
StartableSchedulerModule::start() {
   try {

   } catch (SpecificExceptionA) {
       // do conversion and message construction
       throw ModuleRunTimeError(...);
   } catch (SpecificExceptionB) {
       // do conversion and message construction
       throw ModuleRunTimeError(...);
   } ... {
   } catch (Exception) {
       // add something about this case, stating that the
       // exception from project domain was unexpected
       throw ModuleRunTimeError(...);
   }
\end{verbatim}
\end{quote}

% ------------------------------------------------------------------------

%  References are generated with BibTeX from a bibtex file.
\bibliographystyle{alpha}
\cleardoublepage
%% Equivalent to a chapter in the table of contents
\addcontentsline{toc}{chapter}{BIBLIOGRAPHY}
\bibliography{Bibliography}



\end{document}

%%% Local Variables:
%%% mode: latex
%%% mode: auto-fill
%%% TeX-master: t
%%% End:
